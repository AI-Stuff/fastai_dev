{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.transform import *\n",
    "from local.data.core import *\n",
    "from local.data.source import *\n",
    "from local.data.external import *\n",
    "from local.data.pipeline import *\n",
    "from local.text.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp text.data\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data\n",
    "\n",
    "> Functions and transforms to help gather text data in a `DataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(count, min_freq=3, max_vocab=60000):\n",
    "    \"Create a vocab of `max_vocab` size from `Counter` `count` with items present more than `min_freq`\"\n",
    "    vocab = [o for o,c in count.most_common(max_vocab) if c >= min_freq]\n",
    "    for o in reversed(defaults.text_spec_tok): #Make sure all special tokens are in the vocab\n",
    "        if o in vocab: vocab.remove(o)\n",
    "        vocab.insert(0, o)\n",
    "    vocab = vocab[:max_vocab]\n",
    "    if len(vocab) < max_vocab and len(vocab)%8 != 0: \n",
    "        #Make sure vocab size is a multiple of 8 for fast mixed precision training\n",
    "        vocab += ['xxfake' for _ in range(0, 8-len(vocab)%8)]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'd'])\n",
    "test_eq(set(make_vocab(count)), set(defaults.text_spec_tok + 'a xxfake'.split()))\n",
    "test_eq(len(make_vocab(count))%8, 0)\n",
    "test_eq(set(make_vocab(count, min_freq=1)), set(defaults.text_spec_tok + 'a b c d xxfake'.split()))\n",
    "test_eq(set(make_vocab(count,max_vocab=12, min_freq=1)), set(defaults.text_spec_tok + 'a b c'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Numericalize(ItemTransform):\n",
    "    \"Reversible transform of tokenized texts to numericalized ids\"\n",
    "    def __init__(self, vocab=None, min_freq=3, max_vocab=60000, sep=None):\n",
    "        self.sep = sep or defaults.text_token_sep\n",
    "        self.vocab,self.min_freq,self.max_vocab = vocab,min_freq,max_vocab\n",
    "        self.o2i = None if vocab is None else defaultdict(int, {v:k for k,v in enumerate(vocab)})\n",
    "    \n",
    "    def setup(self, dsrc):\n",
    "        if dsrc is None: return\n",
    "        if self.vocab is None:\n",
    "            dsrc = getattr(dsrc,'train',dsrc)\n",
    "            count = Counter(p for o in dsrc for p in o.split(self.sep))\n",
    "            self.vocab = make_vocab(count, min_freq=self.min_freq, max_vocab=self.max_vocab)\n",
    "            self.o2i = defaultdict(int, {v:k for k,v in enumerate(self.vocab) if v != 'xxfake'})\n",
    "\n",
    "    def encodes(self, o):      return [self.o2i[o_] for o_ in o.split(self.sep)]\n",
    "    def decodes(self, o)->Str: return self.sep.join([self.vocab[o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=1, sep=' ')\n",
    "num.setup(L('This is an example of text', 'this is another text'))\n",
    "test_eq(set(num.vocab), set(defaults.text_spec_tok + 'This is an example of text this another xxfake'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "start = 'This is an example of text'\n",
    "t = num(start)\n",
    "test_eq(t, [11, 9, 12, 13, 14, 10])\n",
    "test_eq(num.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=2, sep=' ')\n",
    "num.setup(L('This is an example of text', 'this is another text'))\n",
    "test_eq(set(num.vocab), set(defaults.text_spec_tok + 'is text xxfake'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "t = num(start)\n",
    "test_eq(t, [0, 9, 0, 0, 0, 10])\n",
    "test_eq(num.decode(t), f'{UNK} is {UNK} {UNK} {UNK} text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMPreloader -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMCollate():\n",
    "    def __init__(self, bs=64, seq_len=72): self.bs,self.seq_len,self.offset = bs,seq_len,None\n",
    "    def __call__(self, samples):\n",
    "        #Samples has more than bs elements if more than one text is needed to make one of the batch\n",
    "        i,res,s_len,s_txt = 0,[],0,[]\n",
    "        for s in samples:\n",
    "            s = tensor(s).long()\n",
    "            l = self.seq_len-s_len\n",
    "            s_txt.append(s[0][self.offset[i]:self.offset[i]+l+1])\n",
    "            s_len += len(s_txt[-1])\n",
    "            self.offset[i] = self.offset[i]+l if self.offset[i]+l < len(s[0]) else 0\n",
    "            if s_len >= self.seq_len+1:\n",
    "                i += 1\n",
    "                res.append(torch.cat(s_txt))\n",
    "                s_len,s_txt = 0,[]\n",
    "        res = torch.stack(res, dim=0)\n",
    "        return res[:,:-1],res[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [(range(21),), (range(32),), (range(10),), (range(16),), (range(26),)]\n",
    "cumlen = tensor([len(t) for t in items]).cumsum(0)\n",
    "tst = LMCollate(bs=5, seq_len=10)\n",
    "tst.offset = [0,0,21,0,5]\n",
    "res = tst([items[0], items[1], items[1], items[3], items[4]])\n",
    "\n",
    "for i in [0,1,3]: \n",
    "    test_eq(res[0][i], tensor(range(10)))\n",
    "    test_eq(res[1][i], tensor(range(1,11)))\n",
    "test_eq(res[0][2], tensor(range(21,31)))\n",
    "test_eq(res[1][2], tensor(range(22,32)))\n",
    "test_eq(res[0][4], tensor(range(5,15)))\n",
    "test_eq(res[1][4], tensor(range(6,16)))\n",
    "test_eq(tst.offset, [10, 10, 31, 10, 15])\n",
    "\n",
    "res = tst([items[0], items[1], items[1], items[2], items[3], items[4], items[4]])\n",
    "for i in [0,1]: \n",
    "    test_eq(res[0][i], tensor(range(10,20)))\n",
    "    test_eq(res[1][i], tensor(range(11,21)))\n",
    "test_eq(res[0][2], torch.cat([tensor([31]), tensor(range(9))]))\n",
    "test_eq(res[1][2], tensor(range(10)))\n",
    "test_eq(res[0][3], torch.cat([tensor(range(10,16)), tensor(range(4))]))\n",
    "test_eq(res[1][3], torch.cat([tensor(range(11,16)), tensor(range(5))]))\n",
    "test_eq(res[0][4], tensor(range(15,25)))\n",
    "test_eq(res[1][4], tensor(range(16,26)))\n",
    "test_eq(tst.offset, [20, 20, 9, 4, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMSampler(BatchSampler):\n",
    "    def __init__(self, ds, cf, lengths=None, bs=64, seq_len=72, shuffle=False):\n",
    "        self.ds,self.cf,self.bs,self.seq_len,self.shuffle = ds,cf,bs,seq_len,shuffle\n",
    "        self.lengths = [len(o[0]) for o in ds] if lengths is None else lengths\n",
    "        self.n_batch = sum(self.lengths) // bs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.batchify()\n",
    "        for i in range(0, self.n_batch-1, self.seq_len):\n",
    "            idx = tensor(range(self.bs)) * self.n_batch + i + self.seq_len\n",
    "            end_idx = len(self.cumlen) - (self.cumlen[:,None] > idx[None]).sum(0)\n",
    "            s_idx = [list(range(i1,i2+1)) for (i1,i2) in zip(self.start_idx, end_idx)]\n",
    "            yield [self.idxs[i] for s in s_idx for i in s]\n",
    "            self.start_idx = end_idx\n",
    "        \n",
    "    def batchify(self):\n",
    "        self.idxs = torch.randperm(len(self.ds)) if self.shuffle else tensor(range(len(self.ds)))\n",
    "        self.cumlen = (tensor(self.lengths)[self.idxs] if self.shuffle else tensor(self.lengths)).cumsum(0)\n",
    "        idx = tensor(range(self.bs)) * self.n_batch\n",
    "        self.start_idx = len(self.cumlen) - (self.cumlen[:,None] > idx[None]).sum(0)\n",
    "        self.cf.offset = idx - torch.cat([tensor([0]), self.cumlen])[self.start_idx]\n",
    "        \n",
    "    def __len__(self): return (self.n_batch-1) // self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [(range(21),), (range(32),), (range(10),), (range(16),), (range(26),)]\n",
    "cf = LMCollate(bs=5, seq_len=10)\n",
    "s = LMSampler(items, cf, bs=5, seq_len=10)\n",
    "s.batchify()\n",
    "test_eq(cf.offset, tensor([0,0,21,0,5]))\n",
    "itr = iter(s)\n",
    "\n",
    "b1 = next(itr)\n",
    "test_eq(b1, [0, 1, 1, 3, 4])\n",
    "\n",
    "b2 = next(itr)\n",
    "test_eq(b2, [0, 1, 1, 2, 3, 4, 4])\n",
    "\n",
    "test_fail(lambda: next(itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make better\n",
    "cf = LMCollate(bs=5, seq_len=10)\n",
    "s = LMSampler(items, cf, bs=5, seq_len=10, shuffle=True)\n",
    "itr = iter(s)\n",
    "b1 = next(itr)\n",
    "b2 = next(itr)\n",
    "test_fail(lambda: next(itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other approach\n",
    "class LM_PreLoader(GetAttr):\n",
    "    \"An intermediate between a dataset with texts and a DataLoader\"\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds, lengths=None, bs=64, seq_len=70, shuffle=False):\n",
    "        self.ds,self.bs,self.seq_len,self.shuffle = ds,bs,seq_len,shuffle\n",
    "        self.lengths = [len(o[0]) for o in ds] if lengths is None else lengths\n",
    "        self.n_batch = sum(self.lengths) // bs\n",
    "        self.batchify()\n",
    "        self.default = self.ds\n",
    "    \n",
    "    def __len__(self): return ((self.n_batch-1) // self.seq_len) * self.bs\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        k = (i % self.bs) * self.n_batch + (i // self.bs) * self.seq_len\n",
    "        item_idx = (self.cumlen > k).nonzero().min().item()\n",
    "        offset = k if item_idx==0 else k-self.cumlen[item_idx-1]\n",
    "        text = self.ds[self.idxs[item_idx]][0][offset:]\n",
    "        while len(text) <= self.seq_len:\n",
    "            item_idx += 1\n",
    "            text += self.ds[self.idxs[item_idx]][0]\n",
    "        return tensor(text[:self.seq_len]),tensor(text[1:self.seq_len+1])\n",
    "    \n",
    "    def batchify(self):\n",
    "        self.idxs = torch.randperm(len(ds)) if self.shuffle else tensor(range(len(self.ds)))\n",
    "        self.cumlen = (tensor(self.lengths)[self.idxs] if self.shuffle else tensor(self.lengths)).cumsum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [10,7,19,23,5,42]\n",
    "ds = LM_PreLoader([(list(range(l)), 0) for l in lengths], lengths=lengths, bs=5, seq_len=4)\n",
    "x,y = ds[0]\n",
    "test_eq(x[1:], y[:-1])\n",
    "test_eq(x+1, y)\n",
    "#Going on the seq dimension reads the text in order\n",
    "test_eq(torch.cat([ds[5*i][0] for i in range(5)]), \n",
    "        tensor(list(range(10))+list(range(7))+list(range(3))))\n",
    "#3 is skipped for the next sample in the natch since it's the last target\n",
    "test_eq(torch.cat([ds[5*i+1][0] for i in range(5)]),\n",
    "        tensor(list(range(4,19))+list(range(5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok,count = tokenize_df(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁un▁-▁bleeping▁-▁believable▁!▁xxmaj...</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁this▁is▁a▁extremely▁well▁-▁made▁fi...</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁every▁once▁in▁a▁long▁while▁a▁movie...</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁name▁just▁says▁it▁all▁.▁i▁watched▁...</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁this▁movie▁succeeds▁at▁being▁one▁o...</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  is_valid                                               text  \\\n",
       "0  negative     False  xxbos▁xxmaj▁un▁-▁bleeping▁-▁believable▁!▁xxmaj...   \n",
       "1  positive     False  xxbos▁xxmaj▁this▁is▁a▁extremely▁well▁-▁made▁fi...   \n",
       "2  negative     False  xxbos▁xxmaj▁every▁once▁in▁a▁long▁while▁a▁movie...   \n",
       "3  positive     False  xxbos▁xxmaj▁name▁just▁says▁it▁all▁.▁i▁watched▁...   \n",
       "4  negative     False  xxbos▁xxmaj▁this▁movie▁succeeds▁at▁being▁one▁o...   \n",
       "\n",
       "   text_lengths  \n",
       "0         103.0  \n",
       "1         462.0  \n",
       "2         220.0  \n",
       "3         184.0  \n",
       "4         398.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts,lengths = df_tok['text'].values,df_tok['text_lengths'].map(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(L(t for t in texts))\n",
    "dsrc = DataSource(L(t for t in texts), type_tfms=[Numericalize(make_vocab(count))], filts=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"xxbos▁xxmaj▁un▁-▁xxunk▁-▁believable▁!▁xxmaj▁meg▁xxmaj▁ryan▁does▁n't▁even▁look▁her▁usual▁xxunk▁lovable▁self▁in▁this▁,▁which▁normally▁makes▁me▁forgive▁her▁shallow▁xxunk▁acting▁xxunk▁.▁xxmaj▁hard▁to▁believe▁she▁was▁the▁producer▁on▁this▁dog▁.▁xxmaj▁plus▁xxmaj▁kevin▁xxmaj▁kline▁:▁what▁kind▁of▁suicide▁trip▁has▁his▁career▁been▁on▁?▁xxmaj▁xxunk▁...▁xxmaj▁xxunk▁!▁!▁!▁xxmaj▁finally▁this▁was▁directed▁by▁the▁guy▁who▁did▁xxmaj▁big▁xxmaj▁xxunk▁?▁xxmaj▁must▁be▁a▁replay▁of▁xxmaj▁jonestown▁-▁hollywood▁style▁.▁xxmaj▁xxunk▁!\",)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.decode_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "cf = LMCollate(bs=bs)\n",
    "samp = LMSampler(dsrc.train, cf, lengths=lengths[splits[0]], bs=bs)\n",
    "tdl = TfmdDL(dsrc.train, bs=bs, num_workers=0, collate_fn=cf, batch_sampler=samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = tdl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [('xxbos▁xxmaj▁in▁xxmaj▁iran▁,▁women▁are▁not▁xxunk▁to▁attend▁men▁\\'s▁sporting▁events▁,▁apparently▁to▁\"▁xxunk▁\"▁them▁from▁all▁the▁xxunk▁and▁foul▁language▁they▁might▁hear▁xxunk▁from▁the▁male▁fans▁(▁so▁since▁men▁ca▁n\\'t▁xxunk▁or▁behave▁themselves▁,▁women▁are▁forced▁to▁suffer▁.▁xxmaj▁go▁figure▁.▁)▁.▁\"▁offside▁\"▁tells▁the▁tale▁of▁a▁half▁dozen▁or',),(\"in▁the▁end▁,▁i▁thought▁the▁film▁handled▁the▁concept▁well▁(▁even▁if▁some▁scenes▁were▁a▁little▁clichéd▁)▁.▁\\n\\n▁xxmaj▁the▁cast▁was▁quite▁good▁,▁and▁the▁two▁leads▁seemed▁to▁take▁their▁roles▁very▁seriously▁.▁i▁could▁n't▁help▁thinking▁,▁though▁,▁that▁xxmaj▁xxunk▁xxmaj▁turner▁is▁a▁bit▁of▁a▁xxmaj▁xxunk▁xxmaj▁davis▁look▁-▁a▁-▁like▁.▁xxmaj\",),('negative▁review▁of▁the▁movie▁:▁xxmaj▁if▁xxmaj▁neo▁could▁do▁the▁xxmaj▁superman▁thing▁,▁why▁bother▁to▁fight▁at▁all▁?▁xxmaj▁the▁answer▁,▁of▁course▁,▁is▁that▁\\'s▁what▁draws▁the▁young▁,▁male▁xxunk▁group▁into▁the▁theatre▁.▁)▁xxmaj▁then▁there▁is▁the▁\"▁redemption▁through▁love▁\"▁aspect▁.▁xxmaj▁that▁plot▁device▁was▁worn▁out▁by▁xxmaj▁richard▁xxmaj▁xxunk▁over',),('would▁make▁it▁into▁a▁movie▁about▁the▁\"▁evil▁xxmaj▁bush▁\"▁.▁xxmaj▁the▁new▁xxup▁dvd▁had▁mostly▁poor▁extras▁meet▁the▁stalkers▁being▁the▁only▁xxunk▁one▁.▁xxmaj▁some▁how▁the▁xxup▁xxunk▁managed▁to▁get▁some▁of▁there▁communism▁into▁the▁xxup▁dvd▁and▁is▁laughable▁garbage▁that▁should▁not▁be▁anywhere▁near▁an▁xxmaj▁arnold▁movie▁of▁all▁things▁.▁xxmaj▁xxunk▁!▁xxmaj▁overall',),(\"were▁disappointing▁.▁xxmaj▁with▁all▁the▁kids▁he▁xxunk▁in▁the▁1st▁3▁movies▁,▁you▁'d▁expect▁there▁to▁be▁more▁parents▁.▁xxmaj▁but▁oh▁well▁.▁\\n\\n▁xxmaj▁freddy▁is▁basically▁the▁narrator▁for▁the▁show▁.▁xxmaj▁he▁watches▁the▁actions▁of▁people▁in▁the▁real▁world▁sometimes▁getting▁involved▁somehow▁.▁xxmaj▁just▁like▁other▁anthology▁shows▁like▁xxmaj▁tales▁from▁the▁xxunk▁,▁there▁'s\",),(\"1922▁'▁\\n\\n▁xxmaj▁one▁thing▁more▁disappointing▁than▁the▁photography▁or▁editing▁or▁the▁direction▁is▁the▁acting▁,▁which▁is▁mostly▁flat▁and▁wooden▁.▁xxmaj▁when▁it▁is▁not▁,▁it▁is▁merely▁routine▁silent▁xxunk▁,▁rolling▁eye▁balls▁,▁xxunk▁eye▁xxunk▁and▁xxunk▁pointing▁and▁arm▁movements▁.▁xxmaj▁what▁would▁have▁been▁xxunk▁for▁modern▁viewers▁by▁xxunk▁and▁scene▁chewing▁of▁some▁of▁the\",),(\"sayuri▁'s▁geisha▁training▁.▁xxmaj▁in▁order▁to▁xxunk▁his▁xxunk▁the▁xxmaj▁chairman▁had▁xxmaj▁sayuri▁sold▁to▁xxmaj▁dr▁.▁xxmaj▁xxunk▁.▁xxmaj▁through▁xxmaj▁mameha▁the▁xxmaj▁chairman▁sold▁xxmaj▁sayuri▁'s▁sexual▁xxunk▁to▁that▁old▁xxunk▁so▁that▁the▁xxmaj▁chairman▁could▁make▁some▁money▁out▁of▁her▁.▁xxmaj▁the▁xxmaj▁chairman▁was▁n't▁her▁patron▁.▁xxmaj▁he▁was▁her▁pimp▁!▁xxmaj\",),('basic▁rule▁when▁it▁comes▁to▁movies▁is▁\"▁if▁it▁sucks▁at▁least▁it▁may▁have▁some▁xxunk▁xxunk▁\"▁,▁you▁know▁time▁xxunk▁stuff▁.▁\\n\\n▁xxmaj▁which▁leads▁me▁to▁the▁horrific▁scenes▁of▁xxmaj▁albert▁xxmaj▁brooks▁xxunk▁shirt▁.▁\\n\\n▁xxmaj▁the▁man▁is▁hair▁.▁xxmaj▁very▁hair▁.▁xxmaj▁like▁he▁\\'s▁wearing▁a▁black▁curly▁fur▁xxunk▁-▁hairy▁.▁xxmaj▁and▁what',),(\"warned▁.▁\\n\\n▁-▁xxmaj▁just▁to▁get▁it▁over▁with▁,▁xxmaj▁beowulf▁'s▁warriors▁wore▁xxunk▁xxunk▁.▁xxmaj▁xxunk▁issue▁compared▁to▁what▁came▁after▁.▁xxmaj▁it▁also▁appears▁that▁the▁xxunk▁were▁in▁a▁bin▁and▁handed▁to▁xxunk▁actor▁xxunk▁by▁next▁.▁xxmaj▁fit▁,▁appearance▁and▁function▁were▁apparently▁irrelevant▁.▁\\n\\n▁-▁xxmaj▁xxunk▁xxmaj▁xxunk▁had▁obviously▁been▁xxunk▁into▁doing▁the\",),(\"xxmaj▁law▁is▁made▁by▁the▁same▁directors▁of▁the▁rather▁curiously▁fascinating▁'▁divorce▁,▁xxmaj▁xxunk▁xxmaj▁style▁'▁which▁was▁as▁exactly▁as▁it▁stated▁,▁as▁we▁got▁a▁glimpse▁of▁xxmaj▁divorce▁court▁in▁xxmaj▁iran▁.▁xxmaj▁now▁they▁'ve▁turned▁their▁attention▁to▁the▁court▁system▁in▁xxmaj▁xxunk▁,▁xxmaj▁africa▁.▁xxmaj▁what▁'s▁great▁about▁this▁court▁is▁that▁2▁of▁the\",)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdl.decode_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "ds = LM_PreLoader(dsrc.train, lengths=lengths[splits[0]], bs=bs)\n",
    "dl = TfmdDL(ds, bs=bs, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [('xxbos▁xxmaj▁in▁xxmaj▁iran▁,▁women▁are▁not▁xxunk▁to▁attend▁men▁\\'s▁sporting▁events▁,▁apparently▁to▁\"▁xxunk▁\"▁them▁from▁all▁the▁xxunk▁and▁foul▁language▁they▁might▁hear▁xxunk▁from▁the▁male▁fans▁(▁so▁since▁men▁ca▁n\\'t▁xxunk▁or▁behave▁themselves▁,▁women▁are▁forced▁to▁suffer▁.▁xxmaj▁go▁figure▁.▁)▁.▁\"▁offside▁\"▁tells▁the▁tale▁of▁a▁half',),(\"in▁the▁end▁,▁i▁thought▁the▁film▁handled▁the▁concept▁well▁(▁even▁if▁some▁scenes▁were▁a▁little▁clichéd▁)▁.▁\\n\\n▁xxmaj▁the▁cast▁was▁quite▁good▁,▁and▁the▁two▁leads▁seemed▁to▁take▁their▁roles▁very▁seriously▁.▁i▁could▁n't▁help▁thinking▁,▁though▁,▁that▁xxmaj▁xxunk▁xxmaj▁turner▁is▁a▁bit▁of▁a▁xxmaj▁xxunk▁xxmaj▁davis▁look▁-▁a▁-▁like\",),('negative▁review▁of▁the▁movie▁:▁xxmaj▁if▁xxmaj▁neo▁could▁do▁the▁xxmaj▁superman▁thing▁,▁why▁bother▁to▁fight▁at▁all▁?▁xxmaj▁the▁answer▁,▁of▁course▁,▁is▁that▁\\'s▁what▁draws▁the▁young▁,▁male▁xxunk▁group▁into▁the▁theatre▁.▁)▁xxmaj▁then▁there▁is▁the▁\"▁redemption▁through▁love▁\"▁aspect▁.▁xxmaj▁that▁plot▁device▁was▁worn▁out▁by▁xxmaj▁richard▁xxmaj',),('would▁make▁it▁into▁a▁movie▁about▁the▁\"▁evil▁xxmaj▁bush▁\"▁.▁xxmaj▁the▁new▁xxup▁dvd▁had▁mostly▁poor▁extras▁meet▁the▁stalkers▁being▁the▁only▁xxunk▁one▁.▁xxmaj▁some▁how▁the▁xxup▁xxunk▁managed▁to▁get▁some▁of▁there▁communism▁into▁the▁xxup▁dvd▁and▁is▁laughable▁garbage▁that▁should▁not▁be▁anywhere▁near▁an▁xxmaj▁arnold▁movie▁of▁all▁things▁.▁xxmaj▁xxunk▁!',),(\"were▁disappointing▁.▁xxmaj▁with▁all▁the▁kids▁he▁xxunk▁in▁the▁1st▁3▁movies▁,▁you▁'d▁expect▁there▁to▁be▁more▁parents▁.▁xxmaj▁but▁oh▁well▁.▁\\n\\n▁xxmaj▁freddy▁is▁basically▁the▁narrator▁for▁the▁show▁.▁xxmaj▁he▁watches▁the▁actions▁of▁people▁in▁the▁real▁world▁sometimes▁getting▁involved▁somehow▁.▁xxmaj▁just▁like▁other▁anthology▁shows▁like▁xxmaj▁tales▁from▁the▁xxunk▁,\",),(\"1922▁'▁\\n\\n▁xxmaj▁one▁thing▁more▁disappointing▁than▁the▁photography▁or▁editing▁or▁the▁direction▁is▁the▁acting▁,▁which▁is▁mostly▁flat▁and▁wooden▁.▁xxmaj▁when▁it▁is▁not▁,▁it▁is▁merely▁routine▁silent▁xxunk▁,▁rolling▁eye▁balls▁,▁xxunk▁eye▁xxunk▁and▁xxunk▁pointing▁and▁arm▁movements▁.▁xxmaj▁what▁would▁have▁been▁xxunk▁for▁modern▁viewers▁by▁xxunk▁and▁scene▁chewing▁of▁some\",),(\"sayuri▁'s▁geisha▁training▁.▁xxmaj▁in▁order▁to▁xxunk▁his▁xxunk▁the▁xxmaj▁chairman▁had▁xxmaj▁sayuri▁sold▁to▁xxmaj▁dr▁.▁xxmaj▁xxunk▁.▁xxmaj▁through▁xxmaj▁mameha▁the▁xxmaj▁chairman▁sold▁xxmaj▁sayuri▁'s▁sexual▁xxunk▁to▁that▁old▁xxunk▁so▁that▁the▁xxmaj▁chairman▁could▁make▁some▁money▁out▁of▁her▁.▁xxmaj▁the▁xxmaj▁chairman▁was▁n't▁her▁patron▁.▁xxmaj▁he▁was▁her▁pimp\",),('basic▁rule▁when▁it▁comes▁to▁movies▁is▁\"▁if▁it▁sucks▁at▁least▁it▁may▁have▁some▁xxunk▁xxunk▁\"▁,▁you▁know▁time▁xxunk▁stuff▁.▁\\n\\n▁xxmaj▁which▁leads▁me▁to▁the▁horrific▁scenes▁of▁xxmaj▁albert▁xxmaj▁brooks▁xxunk▁shirt▁.▁\\n\\n▁xxmaj▁the▁man▁is▁hair▁.▁xxmaj▁very▁hair▁.▁xxmaj▁like▁he▁\\'s▁wearing▁a▁black▁curly▁fur▁xxunk▁-▁hairy▁.▁xxmaj',),(\"warned▁.▁\\n\\n▁-▁xxmaj▁just▁to▁get▁it▁over▁with▁,▁xxmaj▁beowulf▁'s▁warriors▁wore▁xxunk▁xxunk▁.▁xxmaj▁xxunk▁issue▁compared▁to▁what▁came▁after▁.▁xxmaj▁it▁also▁appears▁that▁the▁xxunk▁were▁in▁a▁bin▁and▁handed▁to▁xxunk▁actor▁xxunk▁by▁next▁.▁xxmaj▁fit▁,▁appearance▁and▁function▁were▁apparently▁irrelevant▁.▁\\n\\n▁-▁xxmaj▁xxunk▁xxmaj▁xxunk▁had▁obviously▁been▁xxunk▁into\",),(\"xxmaj▁law▁is▁made▁by▁the▁same▁directors▁of▁the▁rather▁curiously▁fascinating▁'▁divorce▁,▁xxmaj▁xxunk▁xxmaj▁style▁'▁which▁was▁as▁exactly▁as▁it▁stated▁,▁as▁we▁got▁a▁glimpse▁of▁xxmaj▁divorce▁court▁in▁xxmaj▁iran▁.▁xxmaj▁now▁they▁'ve▁turned▁their▁attention▁to▁the▁court▁system▁in▁xxmaj▁xxunk▁,▁xxmaj▁africa▁.▁xxmaj▁what▁'s▁great▁about▁this▁court▁is▁that▁2\",)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.decode_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xxbos▁xxmaj▁in▁xxmaj▁iran▁,▁women▁are▁not▁xxunk▁to▁attend▁men▁\\'s▁sporting▁events▁,▁apparently▁to▁\"▁xxunk▁\"▁them▁from▁all▁the▁xxunk▁and▁foul▁language▁they▁might▁hear▁xxunk▁from▁the▁male▁fans▁(▁so▁since▁men▁ca▁n\\'t▁xxunk▁or▁behave▁themselves▁,▁women▁are▁forced▁to▁suffer▁.▁xxmaj▁go▁figure▁.▁)▁.▁\"▁offside▁\"▁tells▁the▁tale▁of▁a▁half',)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.decode((x[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorTextBase(TensorBase):\n",
    "    def show(self, ctx=None, **kwargs):\n",
    "        return show_image(self, ctx=ctx, **{**self._show_args, **kwargs})\n",
    "    \n",
    "    def get_ctxs(self, max_samples=10, rows=None, cols=None, figsize=None, **kwargs):\n",
    "        n_samples = min(self.shape[0], max_samples)\n",
    "        rows = rows or int(np.ceil(math.sqrt(n_samples)))\n",
    "        cols = cols or int(np.ceil(math.sqrt(n_samples)))\n",
    "        figsize = (cols*3, rows*3) if figsize is None else figsize\n",
    "        _,axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "        return axs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = pd.Series({'a': None, 'b': None})\n",
    "row = fill_empty(row, 'tst')\n",
    "test_eq(row['a'], 'tst')\n",
    "assert row['b'] is None\n",
    "\n",
    "row = fill_empty(row, 'tst1')\n",
    "test_eq(row['a'], 'tst')\n",
    "test_eq(row['b'], 'tst1')\n",
    "\n",
    "row = fill_empty(row, 'tst2')\n",
    "test_eq(row['a'], 'tst')\n",
    "test_eq(row['b'], 'tst1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title1(o, ax=None, ctx=None):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    elif isinstance(ax, pd.Series): ax = fill_empty(ax, o)\n",
    "    else: ax.set_title(o)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show(self, ctx=None, **kwargs): return show_title1(str(self), ctx=ctx)\n",
    "Str.show = _show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sgugger/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({'index': range(5), 'text': [None for _ in range(5)]}, columns=['index', 'text'])\n",
    "tdl.show_batch(ctxs = [df.iloc[i] for i in range(5)])\n",
    "with pd.option_context('display.max_colwidth', -1):\n",
    "    display(HTML(df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
