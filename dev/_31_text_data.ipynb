{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.transform import *\n",
    "from local.data.core import *\n",
    "from local.data.source import *\n",
    "from local.data.external import *\n",
    "from local.data.pipeline import *\n",
    "from local.text.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp text.data\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data\n",
    "\n",
    "> Functions and transforms to help gather text data in a `DataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(count, min_freq=3, max_vocab=60000):\n",
    "    \"Create a vocab of `max_vocab` size from `Counter` `count` with items present more than `min_freq`\"\n",
    "    vocab = [o for o,c in count.most_common(max_vocab) if c >= min_freq]\n",
    "    for o in reversed(defaults.text_spec_tok): #Make sure all special tokens are in the vocab\n",
    "        if o in vocab: vocab.remove(o)\n",
    "        vocab.insert(0, o)\n",
    "    vocab = vocab[:max_vocab]\n",
    "    if len(vocab) < max_vocab and len(vocab)%8 != 0: \n",
    "        #Make sure vocab size is a multiple of 8 for fast mixed precision training\n",
    "        vocab += ['xxfake' for _ in range(0, 8-len(vocab)%8)]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'd'])\n",
    "test_eq(set(make_vocab(count)), set(defaults.text_spec_tok + 'a xxfake'.split()))\n",
    "test_eq(len(make_vocab(count))%8, 0)\n",
    "test_eq(set(make_vocab(count, min_freq=1)), set(defaults.text_spec_tok + 'a b c d xxfake'.split()))\n",
    "test_eq(set(make_vocab(count,max_vocab=12, min_freq=1)), set(defaults.text_spec_tok + 'a b c'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Numericalize(ItemTransform):\n",
    "    \"Reversible transform of tokenized texts to numericalized ids\"\n",
    "    def __init__(self, vocab=None, min_freq=3, max_vocab=60000, sep=None):\n",
    "        self.sep = sep or defaults.text_token_sep\n",
    "        self.vocab,self.min_freq,self.max_vocab = vocab,min_freq,max_vocab\n",
    "        self.o2i = None if vocab is None else defaultdict(int, {v:k for k,v in enumerate(vocab)})\n",
    "    \n",
    "    def setup(self, dsrc):\n",
    "        if dsrc is None: return\n",
    "        if self.vocab is None:\n",
    "            dsrc = getattr(dsrc,'train',dsrc)\n",
    "            count = Counter(p for o in dsrc for p in o.split(self.sep))\n",
    "            self.vocab = make_vocab(count, min_freq=self.min_freq, max_vocab=self.max_vocab)\n",
    "            self.o2i = defaultdict(int, {v:k for k,v in enumerate(self.vocab) if v != 'xxfake'})\n",
    "\n",
    "    def encodes(self, o):      return [self.o2i[o_] for o_ in o.split(self.sep)]\n",
    "    def decodes(self, o)->Str: return self.sep.join([self.vocab[o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=1, sep=' ')\n",
    "num.setup(L('This is an example of text', 'this is another text'))\n",
    "test_eq(set(num.vocab), set(defaults.text_spec_tok + 'This is an example of text this another xxfake'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "start = 'This is an example of text'\n",
    "t = num(start)\n",
    "test_eq(t, [11, 9, 12, 13, 14, 10])\n",
    "test_eq(num.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=2, sep=' ')\n",
    "num.setup(L('This is an example of text', 'this is another text'))\n",
    "test_eq(set(num.vocab), set(defaults.text_spec_tok + 'is text xxfake'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "t = num(start)\n",
    "test_eq(t, [0, 9, 0, 0, 0, 10])\n",
    "test_eq(num.decode(t), f'{UNK} is {UNK} {UNK} {UNK} text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMPreloader -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMSampler(Sampler):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LM_PreLoader(GetAttr):\n",
    "    \"An intermediate between a dataset with texts and a DataLoader\"\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds, lengths=None, bs=64, seq_len=70, shuffle=False):\n",
    "        self.ds,self.bs,self.seq_len,self.shuffle = ds,bs,seq_len,shuffle\n",
    "        self.lengths = [len(o[0]) for o in ds] if lengths is None else lengths\n",
    "        self.n_batch = sum(self.lengths) // bs\n",
    "        self.batchify()\n",
    "        self.default = self.ds\n",
    "    \n",
    "    def __len__(self): return ((self.n_batch-1) // self.seq_len) * self.bs\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        k = (i % self.bs) * self.n_batch + (i // self.bs) * self.seq_len\n",
    "        item_idx = (self.cumlen > k).nonzero().min().item()\n",
    "        offset = k if item_idx==0 else k-self.cumlen[item_idx-1]\n",
    "        text = self.ds[item_idx][0][offset:]\n",
    "        while len(text) <= self.seq_len:\n",
    "            item_idx += 1\n",
    "            text += self.ds[item_idx][0]\n",
    "        return tensor(text[:self.seq_len]),tensor(text[1:self.seq_len+1])\n",
    "    \n",
    "    def batchify(self):\n",
    "        self.idxs = torch.randperm(len(ds)) if self.shuffle else tensor(range(len(self.ds)))\n",
    "        self.cumlen = (tensor(self.lengths)[idxs] if self.shuffle else tensor(self.lengths)).cumsum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [10,7,19,23,5,42]\n",
    "ds = LM_PreLoader([(list(range(l)), 0) for l in lengths], lengths=lengths, bs=5, seq_len=4)\n",
    "x,y = ds[0]\n",
    "test_eq(x[1:], y[:-1])\n",
    "test_eq(x+1, y)\n",
    "#Going on the seq dimension reads the text in order\n",
    "test_eq(torch.cat([ds[5*i][0] for i in range(5)]), \n",
    "        tensor(list(range(10))+list(range(7))+list(range(3))))\n",
    "#3 is skipped for the next sample in the natch since it's the last target\n",
    "test_eq(torch.cat([ds[5*i+1][0] for i in range(5)]),\n",
    "        tensor(list(range(4,19))+list(range(5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok,count = tokenize_df(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁un▁-▁bleeping▁-▁believable▁!▁xxmaj...</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁this▁is▁a▁extremely▁well▁-▁made▁fi...</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁every▁once▁in▁a▁long▁while▁a▁movie...</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁name▁just▁says▁it▁all▁.▁i▁watched▁...</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁this▁movie▁succeeds▁at▁being▁one▁o...</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  is_valid                                               text  \\\n",
       "0  negative     False  xxbos▁xxmaj▁un▁-▁bleeping▁-▁believable▁!▁xxmaj...   \n",
       "1  positive     False  xxbos▁xxmaj▁this▁is▁a▁extremely▁well▁-▁made▁fi...   \n",
       "2  negative     False  xxbos▁xxmaj▁every▁once▁in▁a▁long▁while▁a▁movie...   \n",
       "3  positive     False  xxbos▁xxmaj▁name▁just▁says▁it▁all▁.▁i▁watched▁...   \n",
       "4  negative     False  xxbos▁xxmaj▁this▁movie▁succeeds▁at▁being▁one▁o...   \n",
       "\n",
       "   text_lengths  \n",
       "0         103.0  \n",
       "1         462.0  \n",
       "2         220.0  \n",
       "3         184.0  \n",
       "4         398.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts,lengths = df_tok['text'].values,df_tok['text_lengths'].map(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(L(t for t in texts))\n",
    "dsrc = DataSource(L(t for t in texts), type_tfms=[Numericalize(make_vocab(count))], filts=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"xxbos▁xxmaj▁un▁-▁xxunk▁-▁believable▁!▁xxmaj▁meg▁xxmaj▁ryan▁does▁n't▁even▁look▁her▁usual▁xxunk▁lovable▁self▁in▁this▁,▁which▁normally▁makes▁me▁forgive▁her▁shallow▁xxunk▁acting▁xxunk▁.▁xxmaj▁hard▁to▁believe▁she▁was▁the▁producer▁on▁this▁dog▁.▁xxmaj▁plus▁xxmaj▁kevin▁xxmaj▁kline▁:▁what▁kind▁of▁suicide▁trip▁has▁his▁career▁been▁on▁?▁xxmaj▁xxunk▁...▁xxmaj▁xxunk▁!▁!▁!▁xxmaj▁finally▁this▁was▁directed▁by▁the▁guy▁who▁did▁xxmaj▁big▁xxmaj▁xxunk▁?▁xxmaj▁must▁be▁a▁replay▁of▁xxmaj▁jonestown▁-▁hollywood▁style▁.▁xxmaj▁xxunk▁!\",)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.decode_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "ds = LM_PreLoader(dsrc.train, lengths=lengths[splits[0]], bs=bs)\n",
    "dl = TfmdDL(ds, bs=bs, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [('xxbos▁xxmaj▁rosie▁wasted▁a▁lot▁of▁xxup▁tv▁time▁talking▁about▁the▁xxmaj▁xxunk▁as▁if▁they▁were▁super▁xxunk▁in▁the▁xxunk▁of▁the▁modern▁day▁xxmaj▁puerto▁xxmaj▁xxunk▁.▁xxmaj▁they▁were▁not▁.▁xxmaj▁the▁truth▁is▁that▁the▁xxmaj▁africans▁and▁the▁xxmaj▁spanish▁were▁and▁she▁knows▁it▁.▁xxmaj▁what▁kills▁me▁is▁that▁she▁is▁standing▁on▁the▁screen▁looking▁like',),('it▁and▁\"▁office▁xxmaj▁space▁\"▁.▁xxmaj▁blockbuster▁and▁xxup▁imdb▁even▁had▁it▁as▁an▁\"▁also▁recommended▁\"▁selection▁if▁you▁liked▁\"▁office▁xxmaj▁space▁\"▁.▁\\n\\n▁xxmaj▁now▁,▁xxmaj▁i▁\\'ve▁seen▁xxmaj▁office▁xxmaj▁space▁probably▁15▁or▁20▁times▁.▁i▁love▁it▁.▁xxmaj▁it▁\\'s▁probably▁one▁of▁my▁10▁favorite▁movies▁.▁xxmaj▁witty▁,▁humorous▁,',),('be▁the▁xxmaj▁ed▁xxmaj▁wood▁of▁xxmaj▁asia▁,▁made▁two▁unfortunate▁decisions▁involving▁sound▁.▁xxmaj▁first▁,▁he▁choose▁to▁use▁a▁soundtrack▁only▁when▁someone▁is▁about▁to▁be▁killed▁.▁xxmaj▁this▁is▁an▁excellent▁xxunk▁for▁xxunk▁any▁suspense▁because▁the▁audience▁gets▁a▁two▁minute▁warning▁to▁xxunk▁for▁another▁miserably▁predictable▁murder▁.▁xxmaj▁second▁,▁he▁gave▁the▁ghosts▁a▁bizarre',),('popular▁film▁from▁xxmaj▁xxunk▁called▁\"▁xxunk▁xxunk▁xxunk▁\"▁,▁a▁brilliant▁adaptation▁of▁this▁xxunk▁(▁an▁old▁man▁give▁his▁soul▁to▁the▁devil▁to▁get▁back▁his▁youth▁)▁xxbos▁seriously▁i▁loved▁this▁film▁..▁i▁had▁started▁to▁read▁the▁book▁and▁i▁loved▁it▁...▁the▁way▁everything▁was▁set▁up▁and▁everything▁had▁a▁purpose▁...▁i▁think▁this▁film▁did',),(\",▁xxmaj▁i▁'ll▁live▁with▁it▁,▁as▁long▁as▁i▁never▁have▁to▁watch▁another▁show▁again▁!▁xxmaj▁the▁xxunk▁(▁and▁the▁xxup▁only▁one▁)▁of▁the▁show▁was▁when▁xxmaj▁woody▁xxmaj▁allen▁made▁his▁first▁appearance▁ever▁to▁the▁award▁show▁.▁xxmaj▁that▁will▁go▁down▁as▁one▁of▁the▁greatest▁moments▁in▁he▁history▁of▁the▁show▁.▁xxbos▁a▁police\",),(\"steve▁xxmaj▁biko▁before▁i▁seen▁this▁film▁,▁as▁the▁events▁in▁this▁film▁were▁really▁before▁my▁time▁.▁xxmaj▁but▁it▁'s▁more▁about▁the▁story▁of▁xxmaj▁donald▁xxmaj▁woods▁and▁his▁journey▁across▁the▁border▁into▁xxmaj▁xxunk▁as▁he▁tried▁to▁xxunk▁the▁xxmaj▁south▁xxmaj▁african▁xxunk▁.▁xxmaj▁woods▁was▁put▁on▁a▁five▁year▁type▁house▁xxunk▁after▁xxmaj▁steve▁xxmaj\",),('the▁genre▁that▁they▁are▁running▁out▁of▁originality▁.▁xxmaj▁overall▁,▁a▁few▁xxunk▁moments▁but▁a▁horrible▁movie▁in▁terms▁of▁xxunk▁for▁xxmaj▁xxunk▁)▁and▁subject▁.▁*▁out▁of▁xxrep▁5▁*▁xxbos▁xxmaj▁if▁somebody▁wants▁to▁make▁a▁really▁,▁xxup▁really▁bad▁movie▁,▁\"▁xxunk▁of▁the▁xxmaj▁lost▁xxmaj▁kingdom▁\"▁really▁sets▁a▁xxunk▁by▁which▁to▁measure',),(\"farce▁in▁my▁eyes▁.▁xxmaj▁there▁are▁so▁many▁clichés▁in▁that▁flick▁,▁the▁women▁'s▁hair▁is▁just▁awful▁and▁most▁of▁the▁scenes▁are▁more▁than▁unrealistic▁or▁seem▁fake▁.▁xxmaj▁there▁'s▁no▁real▁passion▁in▁this▁movie▁but▁a▁bunch▁of▁actors▁over▁-▁acting▁over▁any▁limits▁that▁it▁hurts▁.▁xxmaj▁it▁'s▁not▁funny▁enough▁to▁be▁a▁comedy▁,\",),(\"of▁his▁life▁,▁the▁only▁problem▁being▁that▁the▁letter▁is▁n't▁signed▁.▁xxmaj▁so▁xxmaj▁leon▁needs▁to▁track▁down▁all▁the▁women▁he▁'s▁been▁with▁to▁find▁the▁woman▁of▁his▁dreams▁.▁xxmaj▁but▁sometimes▁,▁as▁xxmaj▁billy▁xxmaj▁dee▁xxmaj▁williams▁says▁in▁the▁film▁,▁the▁woman▁of▁your▁dreams▁is▁standing▁right▁in▁front▁of▁you▁.▁xxmaj▁there▁is\",),('leader▁.▁xxmaj▁leachman▁gives▁the▁character▁an▁obnoxious▁xxunk▁that▁\\'s▁nearly▁always▁xxunk▁.▁xxmaj▁it▁\\'s▁so▁bad▁it▁nearly▁ruins▁the▁film▁!▁xxmaj▁jim▁xxmaj▁xxunk▁is▁an▁effective▁voice▁-▁over▁actor▁,▁but▁he▁\\'s▁miscast▁as▁the▁general▁.▁\\n\\n▁i▁would▁definitely▁recommend▁seeing▁\"▁castle▁in▁the▁xxmaj▁sky▁.▁\"▁xxmaj▁i▁\\'ll▁probably▁end▁up▁buying▁it▁myself',)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.decode_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xxbos▁xxmaj▁rosie▁wasted▁a▁lot▁of▁xxup▁tv▁time▁talking▁about▁the▁xxmaj▁xxunk▁as▁if▁they▁were▁super▁xxunk▁in▁the▁xxunk▁of▁the▁modern▁day▁xxmaj▁puerto▁xxmaj▁xxunk▁.▁xxmaj▁they▁were▁not▁.▁xxmaj▁the▁truth▁is▁that▁the▁xxmaj▁africans▁and▁the▁xxmaj▁spanish▁were▁and▁she▁knows▁it▁.▁xxmaj▁what▁kills▁me▁is▁that▁she▁is▁standing▁on▁the▁screen▁looking▁like',)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.decode((x[0],))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
