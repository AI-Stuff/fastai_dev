{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.transform import *\n",
    "from local.data.core import *\n",
    "from local.data.source import *\n",
    "from local.data.external import *\n",
    "from local.data.pipeline import *\n",
    "from local.text.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp text.data\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data\n",
    "\n",
    "> Functions and transforms to help gather text data in a `DataSource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vocab(count, min_freq=3, max_vocab=60000):\n",
    "    \"Create a vocab of `max_vocab` size from `Counter` `count` with items present more than `min_freq`\"\n",
    "    vocab = [o for o,c in count.most_common(max_vocab) if c >= min_freq]\n",
    "    for o in reversed(defaults.text_spec_tok): #Make sure all special tokens are in the vocab\n",
    "        if o in vocab: vocab.remove(o)\n",
    "        vocab.insert(0, o)\n",
    "    vocab = vocab[:max_vocab]\n",
    "    if len(vocab) < max_vocab and len(vocab)%8 != 0: \n",
    "        #Make sure vocab size is a multiple of 8 for fast mixed precision training\n",
    "        vocab += ['xxfake' for _ in range(0, 8-len(vocab)%8)]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'd'])\n",
    "test_eq(set(make_vocab(count)), set(defaults.text_spec_tok + 'a xxfake'.split()))\n",
    "test_eq(len(make_vocab(count))%8, 0)\n",
    "test_eq(set(make_vocab(count, min_freq=1)), set(defaults.text_spec_tok + 'a b c d xxfake'.split()))\n",
    "test_eq(set(make_vocab(count,max_vocab=12, min_freq=1)), set(defaults.text_spec_tok + 'a b c'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Numericalize(ItemTransform):\n",
    "    \"Reversible transform of tokenized texts to numericalized ids\"\n",
    "    def __init__(self, vocab=None, min_freq=3, max_vocab=60000, sep=None):\n",
    "        self.sep = sep or defaults.text_token_sep\n",
    "        self.vocab,self.min_freq,self.max_vocab = vocab,min_freq,max_vocab\n",
    "        self.o2i = None if vocab is None else defaultdict(int, {v:k for k,v in enumerate(vocab)})\n",
    "    \n",
    "    def setup(self, dsrc):\n",
    "        if dsrc is None: return\n",
    "        if self.vocab is None:\n",
    "            dsrc = getattr(dsrc,'train',dsrc)\n",
    "            count = Counter(p for o in dsrc for p in o.split(self.sep))\n",
    "            self.vocab = make_vocab(count, min_freq=self.min_freq, max_vocab=self.max_vocab)\n",
    "            self.o2i = defaultdict(int, {v:k for k,v in enumerate(self.vocab) if v != 'xxfake'})\n",
    "\n",
    "    def encodes(self, o):      return [self.o2i[o_] for o_ in o.split(self.sep)]\n",
    "    def decodes(self, o)->Str: return self.sep.join([self.vocab[o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=1, sep=' ')\n",
    "num.setup(L('This is an example of text', 'this is another text'))\n",
    "test_eq(set(num.vocab), set(defaults.text_spec_tok + 'This is an example of text this another xxfake'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "start = 'This is an example of text'\n",
    "t = num(start)\n",
    "test_eq(t, [11, 9, 12, 13, 14, 10])\n",
    "test_eq(num.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=2, sep=' ')\n",
    "num.setup(L('This is an example of text', 'this is another text'))\n",
    "test_eq(set(num.vocab), set(defaults.text_spec_tok + 'is text xxfake'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "t = num(start)\n",
    "test_eq(t, [0, 9, 0, 0, 0, 10])\n",
    "test_eq(num.decode(t), f'{UNK} is {UNK} {UNK} {UNK} text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LMPreloader -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMCollate():\n",
    "    def __init__(self, bs=64, seq_len=72): self.bs,self.seq_len,self.offset = bs,seq_len,None\n",
    "    def __call__(self, samples):\n",
    "        #Samples has more than bs elements if more than one text is needed to make one of the batch\n",
    "        i,res,s_len,s_txt = 0,[],0,[]\n",
    "        for s in samples:\n",
    "            s = tensor(s).long()\n",
    "            l = self.seq_len-s_len\n",
    "            s_txt.append(s[0][self.offset[i]:self.offset[i]+l+1])\n",
    "            s_len += len(s_txt[-1])\n",
    "            self.offset[i] = self.offset[i]+l if self.offset[i]+l < len(s[0]) else 0\n",
    "            if s_len >= self.seq_len+1:\n",
    "                i += 1\n",
    "                res.append(torch.cat(s_txt))\n",
    "                s_len,s_txt = 0,[]\n",
    "        res = torch.stack(res, dim=0)\n",
    "        return res[:,:-1],res[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [(range(21),), (range(32),), (range(10),), (range(16),), (range(26),)]\n",
    "cumlen = tensor([len(t) for t in items]).cumsum(0)\n",
    "tst = LMCollate(bs=5, seq_len=10)\n",
    "tst.offset = [0,0,21,0,5]\n",
    "res = tst([items[0], items[1], items[1], items[3], items[4]])\n",
    "\n",
    "for i in [0,1,3]: \n",
    "    test_eq(res[0][i], tensor(range(10)))\n",
    "    test_eq(res[1][i], tensor(range(1,11)))\n",
    "test_eq(res[0][2], tensor(range(21,31)))\n",
    "test_eq(res[1][2], tensor(range(22,32)))\n",
    "test_eq(res[0][4], tensor(range(5,15)))\n",
    "test_eq(res[1][4], tensor(range(6,16)))\n",
    "test_eq(tst.offset, [10, 10, 31, 10, 15])\n",
    "\n",
    "res = tst([items[0], items[1], items[1], items[2], items[3], items[4], items[4]])\n",
    "for i in [0,1]: \n",
    "    test_eq(res[0][i], tensor(range(10,20)))\n",
    "    test_eq(res[1][i], tensor(range(11,21)))\n",
    "test_eq(res[0][2], torch.cat([tensor([31]), tensor(range(9))]))\n",
    "test_eq(res[1][2], tensor(range(10)))\n",
    "test_eq(res[0][3], torch.cat([tensor(range(10,16)), tensor(range(4))]))\n",
    "test_eq(res[1][3], torch.cat([tensor(range(11,16)), tensor(range(5))]))\n",
    "test_eq(res[0][4], tensor(range(15,25)))\n",
    "test_eq(res[1][4], tensor(range(16,26)))\n",
    "test_eq(tst.offset, [20, 20, 9, 4, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMSampler(BatchSampler):\n",
    "    def __init__(self, ds, cf, lengths=None, bs=64, seq_len=72, shuffle=False):\n",
    "        self.ds,self.cf,self.bs,self.seq_len,self.shuffle = ds,cf,bs,seq_len,shuffle\n",
    "        self.lengths = [len(o[0]) for o in ds] if lengths is None else lengths\n",
    "        self.n_batch = sum(self.lengths) // bs\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.batchify()\n",
    "        for i in range(0, self.n_batch-1, self.seq_len):\n",
    "            idx = tensor(range(self.bs)) * self.n_batch + i + self.seq_len\n",
    "            end_idx = len(self.cumlen) - (self.cumlen[:,None] > idx[None]).sum(0)\n",
    "            s_idx = [list(range(i1,i2+1)) for (i1,i2) in zip(self.start_idx, end_idx)]\n",
    "            yield [self.idxs[i] for s in s_idx for i in s]\n",
    "            self.start_idx = end_idx\n",
    "        \n",
    "    def batchify(self):\n",
    "        self.idxs = torch.randperm(len(self.ds)) if self.shuffle else tensor(range(len(self.ds)))\n",
    "        self.cumlen = (tensor(self.lengths)[self.idxs] if self.shuffle else tensor(self.lengths)).cumsum(0)\n",
    "        idx = tensor(range(self.bs)) * self.n_batch\n",
    "        self.start_idx = len(self.cumlen) - (self.cumlen[:,None] > idx[None]).sum(0)\n",
    "        self.cf.offset = idx - torch.cat([tensor([0]), self.cumlen])[self.start_idx]\n",
    "        \n",
    "    def __len__(self): return (self.n_batch-1) // self.seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [(range(21),), (range(32),), (range(10),), (range(16),), (range(26),)]\n",
    "cf = LMCollate(bs=5, seq_len=10)\n",
    "s = LMSampler(items, cf, bs=5, seq_len=10)\n",
    "s.batchify()\n",
    "test_eq(cf.offset, tensor([0,0,21,0,5]))\n",
    "itr = iter(s)\n",
    "\n",
    "b1 = next(itr)\n",
    "test_eq(b1, [0, 1, 1, 3, 4])\n",
    "\n",
    "b2 = next(itr)\n",
    "test_eq(b2, [0, 1, 1, 2, 3, 4, 4])\n",
    "\n",
    "test_fail(lambda: next(itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make better\n",
    "cf = LMCollate(bs=5, seq_len=10)\n",
    "s = LMSampler(items, cf, bs=5, seq_len=10, shuffle=True)\n",
    "itr = iter(s)\n",
    "b1 = next(itr)\n",
    "b2 = next(itr)\n",
    "test_fail(lambda: next(itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "class TensorTextBase(TensorBase):\n",
    "    \n",
    "    def get_ctxs(self, max_samples=10, **kwargs):\n",
    "        n_samples = min(self.shape[0], max_samples)\n",
    "        df = pd.DataFrame({'index': range(n_samples)})\n",
    "        return [df.iloc[i] for i in range(n_samples)]\n",
    "    \n",
    "    def display(self, ctxs):\n",
    "        df = pd.DataFrame(ctxs)\n",
    "        with pd.option_context('display.max_colwidth', -1): \n",
    "            display(HTML(df.to_html(index=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Other approach\n",
    "class LM_PreLoader(GetAttr):\n",
    "    \"An intermediate between a dataset with texts and a DataLoader\"\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds, lengths=None, bs=64, seq_len=70, shuffle=False):\n",
    "        self.ds,self.bs,self.seq_len,self.shuffle = ds,bs,seq_len,shuffle\n",
    "        self.lengths = [len(o[0]) for o in ds] if lengths is None else lengths\n",
    "        self.n_batch = sum(self.lengths) // bs\n",
    "        self.batchify()\n",
    "        self.default = self.ds\n",
    "    \n",
    "    def __len__(self): return ((self.n_batch-1) // self.seq_len) * self.bs\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        k = (i % self.bs) * self.n_batch + (i // self.bs) * self.seq_len\n",
    "        item_idx = (self.cumlen > k).nonzero().min().item()\n",
    "        offset = k if item_idx==0 else k-self.cumlen[item_idx-1]\n",
    "        text = self.ds[self.idxs[item_idx]][0][offset:]\n",
    "        while len(text) <= self.seq_len:\n",
    "            item_idx += 1\n",
    "            text += self.ds[self.idxs[item_idx]][0]\n",
    "        return TensorTextBase(tensor(text[:self.seq_len])),TensorTextBase(tensor(text[1:self.seq_len+1]))\n",
    "    \n",
    "    def batchify(self):\n",
    "        self.idxs = torch.randperm(len(ds)) if self.shuffle else tensor(range(len(self.ds)))\n",
    "        self.cumlen = (tensor(self.lengths)[self.idxs] if self.shuffle else tensor(self.lengths)).cumsum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [10,7,19,23,5,42]\n",
    "ds = LM_PreLoader([(list(range(l)), 0) for l in lengths], lengths=lengths, bs=5, seq_len=4)\n",
    "x,y = ds[0]\n",
    "test_eq(x[1:], y[:-1])\n",
    "test_eq(x+1, y)\n",
    "#Going on the seq dimension reads the text in order\n",
    "test_eq(torch.cat([ds[5*i][0] for i in range(5)]), \n",
    "        tensor(list(range(10))+list(range(7))+list(range(3))))\n",
    "#3 is skipped for the next sample in the natch since it's the last target\n",
    "test_eq(torch.cat([ds[5*i+1][0] for i in range(5)]),\n",
    "        tensor(list(range(4,19))+list(range(5))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "df = pd.read_csv(path/'texts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>Every once in a long while a movie will come a...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>Name just says it all. I watched this movie wi...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>This movie succeeds at being one of the most u...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  is_valid\n",
       "0  negative  Un-bleeping-believable! Meg Ryan doesn't even ...     False\n",
       "1  positive  This is a extremely well-made film. The acting...     False\n",
       "2  negative  Every once in a long while a movie will come a...     False\n",
       "3  positive  Name just says it all. I watched this movie wi...     False\n",
       "4  negative  This movie succeeds at being one of the most u...     False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok,count = tokenize_df(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text</th>\n",
       "      <th>text_lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁un▁-▁bleeping▁-▁believable▁!▁xxmaj...</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁this▁is▁a▁extremely▁well▁-▁made▁fi...</td>\n",
       "      <td>462.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁every▁once▁in▁a▁long▁while▁a▁movie...</td>\n",
       "      <td>220.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁name▁just▁says▁it▁all▁.▁i▁watched▁...</td>\n",
       "      <td>184.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>xxbos▁xxmaj▁this▁movie▁succeeds▁at▁being▁one▁o...</td>\n",
       "      <td>398.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  is_valid                                               text  \\\n",
       "0  negative     False  xxbos▁xxmaj▁un▁-▁bleeping▁-▁believable▁!▁xxmaj...   \n",
       "1  positive     False  xxbos▁xxmaj▁this▁is▁a▁extremely▁well▁-▁made▁fi...   \n",
       "2  negative     False  xxbos▁xxmaj▁every▁once▁in▁a▁long▁while▁a▁movie...   \n",
       "3  positive     False  xxbos▁xxmaj▁name▁just▁says▁it▁all▁.▁i▁watched▁...   \n",
       "4  negative     False  xxbos▁xxmaj▁this▁movie▁succeeds▁at▁being▁one▁o...   \n",
       "\n",
       "   text_lengths  \n",
       "0         103.0  \n",
       "1         462.0  \n",
       "2         220.0  \n",
       "3         184.0  \n",
       "4         398.0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts,lengths = df_tok['text'].values,df_tok['text_lengths'].map(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(L(t for t in texts))\n",
    "dsrc = DataSource(L(t for t in texts), type_tfms=[Numericalize(make_vocab(count))], filts=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"xxbos▁xxmaj▁un▁-▁xxunk▁-▁believable▁!▁xxmaj▁meg▁xxmaj▁ryan▁does▁n't▁even▁look▁her▁usual▁xxunk▁lovable▁self▁in▁this▁,▁which▁normally▁makes▁me▁forgive▁her▁shallow▁xxunk▁acting▁xxunk▁.▁xxmaj▁hard▁to▁believe▁she▁was▁the▁producer▁on▁this▁dog▁.▁xxmaj▁plus▁xxmaj▁kevin▁xxmaj▁kline▁:▁what▁kind▁of▁suicide▁trip▁has▁his▁career▁been▁on▁?▁xxmaj▁xxunk▁...▁xxmaj▁xxunk▁!▁!▁!▁xxmaj▁finally▁this▁was▁directed▁by▁the▁guy▁who▁did▁xxmaj▁big▁xxmaj▁xxunk▁?▁xxmaj▁must▁be▁a▁replay▁of▁xxmaj▁jonestown▁-▁hollywood▁style▁.▁xxmaj▁xxunk▁!\",)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.decode_at(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "ds = LM_PreLoader(dsrc.train, lengths=lengths[splits[0]], bs=bs)\n",
    "dl = TfmdDL(ds, bs=bs, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dl.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [('xxbos▁xxmaj▁i▁\\'m▁fond▁of▁this▁film▁and▁it▁xxunk▁me▁that▁so▁many▁\"▁reviewers▁\"▁rank▁it▁below▁the▁xxmaj▁peter▁xxmaj▁jackson▁trilogy▁.▁a▁filmed▁novel▁is▁always▁xxunk▁;▁in▁particular▁an▁animated▁film▁relies▁on▁the▁artist▁\\'s▁vision▁and▁should▁be▁xxunk▁on▁its▁own▁terms▁.▁xxmaj▁speaking▁as▁a▁xxunk▁,▁this▁is▁a▁xxunk▁homage▁to▁xxmaj▁tolkien▁than',),('one▁of▁the▁best▁xxmaj▁hong▁xxmaj▁kong▁(▁action▁)▁films▁around▁and▁it▁has▁a▁tense▁and▁exciting▁storyline▁as▁well▁as▁great▁fight▁scenes▁.▁xxmaj▁this▁xxmaj▁xxunk▁film▁has▁it▁all▁,▁xxmaj▁romance▁,▁xxmaj▁drama▁,▁xxmaj▁excitement▁and▁a▁great▁hero▁as▁well▁.▁xxmaj▁it▁is▁the▁only▁martial▁arts▁film▁that▁got▁me▁interested▁in▁the▁plot▁rather▁than▁just',),(\"a▁part▁of▁their▁xxunk▁military▁service▁.▁xxmaj▁even▁most▁of▁the▁men▁going▁into▁the▁stadium▁do▁n't▁seem▁particularly▁xxunk▁at▁the▁thought▁of▁these▁women▁being▁allowed▁in▁.▁xxmaj▁still▁the▁prohibition▁xxunk▁.▁xxmaj▁yet▁,▁how▁can▁one▁not▁be▁impressed▁by▁the▁very▁real▁courage▁and▁xxunk▁displayed▁by▁these▁women▁as▁they▁go▁up▁against▁a▁system▁that▁continues▁to▁xxunk\",),('photography▁is▁by▁the▁great▁xxmaj▁xxunk▁xxmaj▁hall▁.▁xxbos▁xxmaj▁america▁.▁a▁land▁of▁freedom▁,▁of▁hope▁and▁of▁dreams▁.▁xxmaj▁this▁is▁the▁nation▁that▁,▁since▁its▁independence▁,▁has▁xxunk▁to▁bring▁xxunk▁,▁xxunk▁,▁and▁peace▁to▁the▁entire▁world▁,▁for▁the▁good▁of▁all▁mankind▁.▁xxmaj▁there▁are▁times▁,▁however▁,▁when▁one▁can▁not▁help',),(\"so▁do▁n't▁worry▁about▁that▁,▁the▁special▁effects▁on▁the▁blob▁itself▁are▁n't▁too▁bad▁considering▁but▁it▁barely▁has▁any▁screen▁time▁&▁moves▁very▁slowly▁,▁a▁bit▁like▁the▁film▁in▁general▁actually▁.▁xxmaj▁the▁acting▁is▁terrible▁,▁mcqueen▁is▁supposed▁to▁be▁a▁teenager▁when▁in▁reality▁he▁was▁28▁years▁old▁&▁it▁shows▁,▁he▁looks▁old▁enough▁to\",),(\"not▁do▁their▁acting▁performances▁any▁justice▁.▁xxmaj▁if▁the▁script▁would▁have▁come▁close▁to▁xxunk▁a▁halfway▁decent▁story▁,▁it▁would▁be▁worth▁watching▁.▁xxmaj▁instead▁,▁xxmaj▁robert▁duvall▁'s▁and▁xxmaj▁james▁xxmaj▁earl▁xxmaj▁jones▁'▁performances▁are▁completely▁wasted▁on▁a▁god▁awful▁storyline▁...▁or▁lack▁thereof▁.▁xxmaj▁not▁only▁was▁i▁left▁waiting▁throughout▁the▁movie▁for▁something\",),('menace▁\"▁,▁is▁that▁it▁will▁likely▁blow▁\"▁titanic▁\"▁out▁of▁the▁water▁,▁if▁you▁\\'ll▁pardon▁the▁pun▁,▁when▁it▁comes▁to▁sheer▁devastating▁box▁office▁xxunk▁,▁and▁xxunk▁knock▁it▁out▁of▁the▁number▁one▁spot▁.▁xxmaj▁every▁time▁i▁hear▁someone▁declare▁\"▁titanic▁\"▁is▁the▁greatest▁film▁they▁\\'ve▁ever▁seen▁,▁i▁think▁to▁myself▁,▁\"',),('attack▁on▁xxup▁u.s▁.▁soil▁.▁xxmaj▁the▁aftermath▁of▁this▁disaster▁is▁xxunk▁from▁many▁different▁countries▁and▁perspectives▁.▁i▁believe▁that▁this▁film▁should▁be▁more▁widely▁distributed▁for▁this▁point▁.▁xxmaj▁it▁also▁helps▁in▁the▁the▁healing▁process▁to▁finally▁see▁something▁other▁than▁news▁reports▁on▁the▁terrorist▁attacks▁.▁xxmaj▁and▁some▁of▁the▁pieces▁are▁actually▁funny▁,▁but▁not',),('thomas▁)▁he▁played▁in▁this▁film▁.▁xxmaj▁you▁will▁find▁yourself▁feeling▁his▁pain▁and▁anger▁,▁the▁xxunk▁over▁his▁love▁for▁xxmaj▁emily▁,▁played▁by▁xxmaj▁rosario▁xxmaj▁dawson▁,▁who▁by▁the▁way▁was▁xxmaj▁fantastic▁as▁usual▁.▁i▁found▁myself▁falling▁in▁love▁with▁the▁fact▁their▁characters▁were▁falling▁in▁love▁.▁xxmaj▁woody▁xxmaj▁xxunk▁also▁stars▁in▁this▁xxmaj',),(\"and▁one▁that▁'s▁strangely▁under▁-▁appreciated▁.▁xxmaj▁the▁mix▁of▁fantasy▁kung▁-▁fu▁with▁a▁more▁realistic▁depiction▁of▁swords▁and▁xxunk▁being▁driven▁thru▁bodies▁is▁xxunk▁especially▁during▁the▁first▁ten▁minutes▁.▁a▁xxunk▁rider▁get▁xxunk▁in▁two▁and▁his▁xxunk▁and▁legs▁keep▁riding▁the▁horse▁.▁xxmaj▁several▁horses▁get▁xxunk▁up▁.▁xxmaj▁it▁'s▁very▁unexpected▁.▁\\n\\n\",)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.decode_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xxbos▁xxmaj▁i▁\\'m▁fond▁of▁this▁film▁and▁it▁xxunk▁me▁that▁so▁many▁\"▁reviewers▁\"▁rank▁it▁below▁the▁xxmaj▁peter▁xxmaj▁jackson▁trilogy▁.▁a▁filmed▁novel▁is▁always▁xxunk▁;▁in▁particular▁an▁animated▁film▁relies▁on▁the▁artist▁\\'s▁vision▁and▁should▁be▁xxunk▁on▁its▁own▁terms▁.▁xxmaj▁speaking▁as▁a▁xxunk▁,▁this▁is▁a▁xxunk▁homage▁to▁xxmaj▁tolkien▁than',)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.decode((x[0],))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ToTensor\n",
    "def encodes(x: Str) -> TensorTextBase: return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title1(o, ax=None, ctx=None):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    elif isinstance(ax, pd.Series): ax = ax.append(pd.Series({'text': o}))\n",
    "    else: ax.set_title(o)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show(self, ctx=None, **kwargs): return show_title1(str(self), ctx=ctx)\n",
    "Str.show = _show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(L(t for t in texts), type_tfms=[Numericalize(make_vocab(count))], filts=splits)\n",
    "bs = 16\n",
    "ds = LM_PreLoader(dsrc.train, lengths=lengths[splits[0]], bs=bs)\n",
    "dl = TfmdDL(ds, bs=bs, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title1(o, ax=None, ctx=None):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    elif isinstance(ax, pd.Series): ax = ax.append(pd.Series({'text': o}))\n",
    "    else: ax.set_title(o)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _show(self, ctx=None, **kwargs): return show_title1(str(self), ctx=ctx)\n",
    "Str.show = _show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxbos▁xxmaj▁i▁'m▁fond▁of▁this▁film▁and▁it▁xxunk▁me▁that▁so▁many▁\"▁reviewers▁\"▁rank▁it▁below▁the▁xxmaj▁peter▁xxmaj▁jackson▁trilogy▁.▁a▁filmed▁novel▁is▁always▁xxunk▁;▁in▁particular▁an▁animated▁film▁relies▁on▁the▁artist▁'s▁vision▁and▁should▁be▁xxunk▁on▁its▁own▁terms▁.▁xxmaj▁speaking▁as▁a▁xxunk▁,▁this▁is▁a▁xxunk▁homage▁to▁xxmaj▁tolkien▁than</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>one▁of▁the▁best▁xxmaj▁hong▁xxmaj▁kong▁(▁action▁)▁films▁around▁and▁it▁has▁a▁tense▁and▁exciting▁storyline▁as▁well▁as▁great▁fight▁scenes▁.▁xxmaj▁this▁xxmaj▁xxunk▁film▁has▁it▁all▁,▁xxmaj▁romance▁,▁xxmaj▁drama▁,▁xxmaj▁excitement▁and▁a▁great▁hero▁as▁well▁.▁xxmaj▁it▁is▁the▁only▁martial▁arts▁film▁that▁got▁me▁interested▁in▁the▁plot▁rather▁than▁just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>a▁part▁of▁their▁xxunk▁military▁service▁.▁xxmaj▁even▁most▁of▁the▁men▁going▁into▁the▁stadium▁do▁n't▁seem▁particularly▁xxunk▁at▁the▁thought▁of▁these▁women▁being▁allowed▁in▁.▁xxmaj▁still▁the▁prohibition▁xxunk▁.▁xxmaj▁yet▁,▁how▁can▁one▁not▁be▁impressed▁by▁the▁very▁real▁courage▁and▁xxunk▁displayed▁by▁these▁women▁as▁they▁go▁up▁against▁a▁system▁that▁continues▁to▁xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>photography▁is▁by▁the▁great▁xxmaj▁xxunk▁xxmaj▁hall▁.▁xxbos▁xxmaj▁america▁.▁a▁land▁of▁freedom▁,▁of▁hope▁and▁of▁dreams▁.▁xxmaj▁this▁is▁the▁nation▁that▁,▁since▁its▁independence▁,▁has▁xxunk▁to▁bring▁xxunk▁,▁xxunk▁,▁and▁peace▁to▁the▁entire▁world▁,▁for▁the▁good▁of▁all▁mankind▁.▁xxmaj▁there▁are▁times▁,▁however▁,▁when▁one▁can▁not▁help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>so▁do▁n't▁worry▁about▁that▁,▁the▁special▁effects▁on▁the▁blob▁itself▁are▁n't▁too▁bad▁considering▁but▁it▁barely▁has▁any▁screen▁time▁&amp;▁moves▁very▁slowly▁,▁a▁bit▁like▁the▁film▁in▁general▁actually▁.▁xxmaj▁the▁acting▁is▁terrible▁,▁mcqueen▁is▁supposed▁to▁be▁a▁teenager▁when▁in▁reality▁he▁was▁28▁years▁old▁&amp;▁it▁shows▁,▁he▁looks▁old▁enough▁to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>not▁do▁their▁acting▁performances▁any▁justice▁.▁xxmaj▁if▁the▁script▁would▁have▁come▁close▁to▁xxunk▁a▁halfway▁decent▁story▁,▁it▁would▁be▁worth▁watching▁.▁xxmaj▁instead▁,▁xxmaj▁robert▁duvall▁'s▁and▁xxmaj▁james▁xxmaj▁earl▁xxmaj▁jones▁'▁performances▁are▁completely▁wasted▁on▁a▁god▁awful▁storyline▁...▁or▁lack▁thereof▁.▁xxmaj▁not▁only▁was▁i▁left▁waiting▁throughout▁the▁movie▁for▁something</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>menace▁\"▁,▁is▁that▁it▁will▁likely▁blow▁\"▁titanic▁\"▁out▁of▁the▁water▁,▁if▁you▁'ll▁pardon▁the▁pun▁,▁when▁it▁comes▁to▁sheer▁devastating▁box▁office▁xxunk▁,▁and▁xxunk▁knock▁it▁out▁of▁the▁number▁one▁spot▁.▁xxmaj▁every▁time▁i▁hear▁someone▁declare▁\"▁titanic▁\"▁is▁the▁greatest▁film▁they▁'ve▁ever▁seen▁,▁i▁think▁to▁myself▁,▁\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>attack▁on▁xxup▁u.s▁.▁soil▁.▁xxmaj▁the▁aftermath▁of▁this▁disaster▁is▁xxunk▁from▁many▁different▁countries▁and▁perspectives▁.▁i▁believe▁that▁this▁film▁should▁be▁more▁widely▁distributed▁for▁this▁point▁.▁xxmaj▁it▁also▁helps▁in▁the▁the▁healing▁process▁to▁finally▁see▁something▁other▁than▁news▁reports▁on▁the▁terrorist▁attacks▁.▁xxmaj▁and▁some▁of▁the▁pieces▁are▁actually▁funny▁,▁but▁not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>thomas▁)▁he▁played▁in▁this▁film▁.▁xxmaj▁you▁will▁find▁yourself▁feeling▁his▁pain▁and▁anger▁,▁the▁xxunk▁over▁his▁love▁for▁xxmaj▁emily▁,▁played▁by▁xxmaj▁rosario▁xxmaj▁dawson▁,▁who▁by▁the▁way▁was▁xxmaj▁fantastic▁as▁usual▁.▁i▁found▁myself▁falling▁in▁love▁with▁the▁fact▁their▁characters▁were▁falling▁in▁love▁.▁xxmaj▁woody▁xxmaj▁xxunk▁also▁stars▁in▁this▁xxmaj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>and▁one▁that▁'s▁strangely▁under▁-▁appreciated▁.▁xxmaj▁the▁mix▁of▁fantasy▁kung▁-▁fu▁with▁a▁more▁realistic▁depiction▁of▁swords▁and▁xxunk▁being▁driven▁thru▁bodies▁is▁xxunk▁especially▁during▁the▁first▁ten▁minutes▁.▁a▁xxunk▁rider▁get▁xxunk▁in▁two▁and▁his▁xxunk▁and▁legs▁keep▁riding▁the▁horse▁.▁xxmaj▁several▁horses▁get▁xxunk▁up▁.▁xxmaj▁it▁'s▁very▁unexpected▁.▁\\n\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dl.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
