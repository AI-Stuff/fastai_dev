{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` is created with an `encodes` and potentially `decodes` function. \n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title(o, ax=None, ctx=None):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    else: ax.set_title(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: show_title(\"title\"), \"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms, data augmentation in particular, are built in fastai around patching some types. For instance a `TensorImage` object isn't flipped the same way as a `TensorPoints` or a `TensorBBox` object, so we will want to access the `flip` attribute of each of those classes. The following class allows us to create a generic object associated to that `flip` name that will then look for this attribute in the type (or list of types) we feed it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Sig</code>\" class=\"doc_header\"><code>Sig</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sig</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfFunc():\n",
    "    \"Search for `name` attribute and call it with `args` and `kwargs` on any object it's passed.\"\n",
    "    def __init__(self, nm, *args, **kwargs): self.nm,self.args,self.kwargs = nm,args,kwargs\n",
    "    def __repr__(self): return f'self: {self.nm}({self.args}, {self.kwargs})'\n",
    "    def __call__(self, o):\n",
    "        if not is_listy(o): return getattr(o,self.nm)(*self.args, **self.kwargs)\n",
    "        else: return [getattr(o_,self.nm)(*self.args, **self.kwargs) for o_ in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `Func` and `SelfFunc` is that `Func` will generate a function when you call it on a type. On the other hand, `SelfFunc` is already a function and each time you call it on an object it looks for the `name` attribute and call it on `args` and `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SelfFunc('sqrt')\n",
    "x = torch.tensor([4.])\n",
    "test_eq(tst(x), torch.tensor([2.]))\n",
    "assert isinstance(tst(x), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SelfFunc():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return SelfFunc(k, *args, **kwargs)\n",
    "        return _inner\n",
    "    \n",
    "Self = _SelfFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Self</code>\" class=\"doc_header\"><code>Self</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L3\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Self</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Self, name=\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Self` is just syntax sugar to create a `SelfFunc` object more easily with the syntax `Self.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sqrt()\n",
    "x = torch.tensor([4.])\n",
    "test_eq(f(x), torch.tensor([2.]))\n",
    "assert isinstance(f(x), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _filter_with_type(f, t):\n",
    "    if is_listy(f): return f\n",
    "    sig = inspect.signature(f)\n",
    "    t_in = [p.annotation if p.annotation != inspect._empty else None \n",
    "            for p in sig.parameters.values() if p.default == inspect._empty and p.kind != inspect._VAR_KEYWORD]\n",
    "    if len(t_in) > 1: return f\n",
    "    return [f if t_ is None or t_in[0] is None or t_==t_in[0] else noop for t_ in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform(PrePostInit):\n",
    "    \"A function that `encodes` if `filt` matches, and optionally `decodes`\"\n",
    "    order,filt = 0,None\n",
    "    def __init__(self,encodes=None,decodes=None):\n",
    "        if encodes is not None: self.encodes = encodes\n",
    "        if decodes is not None: self.decodes = decodes\n",
    "    \n",
    "    def _filt_match(self, filt): return self.filt is None or self.filt==filt\n",
    "    def _apply(self, fs, x, filt):\n",
    "        if not self._filt_match(filt): return x\n",
    "        if is_listy(fs): return tuple(f(x_) for f,x_ in zip(fs,x))\n",
    "        return fs(*L(x))\n",
    "    \n",
    "    def __call__(self, x, filt=None): return self._apply(self.encodes, x, filt)\n",
    "    def decode  (self, x, filt=None): return self._apply(self.decodes, x, filt)\n",
    "    def __getitem__(self, x): return self(x) # So it can be used as a `Dataset`\n",
    "\n",
    "    def _filter_with_type(self, t):\n",
    "        if self.encodes is None: self.encodes = noop\n",
    "        if self.decodes is None: self.encodes = noop\n",
    "        if is_listy(t): self.encodes = _filter_with_type(self.encodes, t)\n",
    "        if is_listy(t): self.decodes = _filter_with_type(self.decodes, t)\n",
    "            \n",
    "add_docs(Transform,\n",
    "         __call__=\"Call `self.encodes` unless `filt` is passed and it doesn't match `self.filt`\",\n",
    "         decode  =\"Call `self.decodes` unless `filt` is passed and it doesn't match `self.filt`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a transformation pipeline some steps need to be reversible - for instance, if you turn a string (such as *dog*) into an int (such as *1*) for modeling, then for display purposes you'll want to turn it back to a string again (e.g. when you have a prediction). In addition, you may wish to only run the transformation for a particular data subset, such as the training set.\n",
    "\n",
    "`Transform` provides all this functionality. `filt` is some dataset index (e.g. provided by `DataSource`), and you provide `encodes` and optional `decodes` functions for your code. You can pass `encodes` and `decodes` functions directly to the constructor for quickly creating simple transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Transform(operator.neg, decodes=operator.neg)\n",
    "start = 4\n",
    "t = tfm(start)\n",
    "test_eq(t, -4)\n",
    "test_eq(t, tfm[start]) #You can use a transform as a dataset\n",
    "test_eq(tfm.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "test_eq(addt(start,filt=1), 5)\n",
    "test_eq(addt(start,filt=0), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point in the data-collection pipeline, your objects will be tuples (usually input,label). There are then different behaviors you might want your `Transform` to adopt such as:\n",
    "- being applied to the tuple and returning a new tuple\n",
    "- being applied to each part of the tuple\n",
    "- being applied to some parts of the tuple but not all\n",
    "\n",
    "You can control which behavior will be used with the signature of your `encodes` function. If it accepts several arguments (without defaults), then the transform will be applied on the tuple and expected to return a tuple. If your `encodes` function only accepts one argument, it will be applied on every part of the tuple. You can even control which part of the tuples with a type annotation: the tranform will only be applied to the items in the tuple that correspond to that type.\n",
    "\n",
    "All of this is enabled the private method `_filter_with_type` that is called in the setup of a `Pipeline` (so out of the blue your transform object won't have this behavior). The `Pipeline` will analyze the type of objects (as given by the return annotation of any transform) and pass them along, wich tells the transform it will receive a given type (or a tuple of given types)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on the tuple as a whole\n",
    "class _Add(Transform):\n",
    "    def encodes(self, x, y): return (x+y,y)\n",
    "    def decodes(self, x, y): return (x-y,y)\n",
    "\n",
    "addt = _Add()\n",
    "addt._filter_with_type([float,float])\n",
    "t = addt([1,2])\n",
    "test_eq(t, (3,2))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply on all part of the tuple\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt._filter_with_type([float,float])\n",
    "t = addt([1,2])\n",
    "test_eq(t, (2,3))\n",
    "test_eq(addt.decode(t), (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "#Apply on all float of the tuple\n",
    "#Also note that your tuples can have more than two elements\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:float): return x+1\n",
    "    def decodes(self, x:float): return x-1\n",
    "\n",
    "addt = _AddOne()\n",
    "addt._filter_with_type([int,float, float])\n",
    "t = addt([1,2,3])\n",
    "test_eq(t, (1,3,4))\n",
    "test_eq(addt.decode(t), (1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_func(f, t):\n",
    "    \"Make `f` a function with type `t`\"\n",
    "    if isinstance(f,str ): f = Func(f)\n",
    "    if isinstance(f,Func): f = f(t)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_tfm(f,t):\n",
    "    \"Make `f` a transform with type `t`\"\n",
    "    if not is_listy(f): f = (f,None)\n",
    "    return Transform(mk_func(f[0],t), mk_func(f[1],t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_tfms(x, tfms, func_nm='encode', reverse=False):\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for tfm in tfms: x = getattr(tfm,func_nm,noop)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _get_ret(func):\n",
    "    ann = getattr(func,'__annotations__', None)\n",
    "    if not ann: return None\n",
    "    return ann.get('return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline():\n",
    "    def __init__(self, funcs):\n",
    "        self.raw_fs = funcs\n",
    "        \n",
    "    def setup(self, t=None):\n",
    "        self.fs,self.t_show = [],None\n",
    "        if len(self.raw_fs) == 0: self.final_t = t\n",
    "        else:\n",
    "            for i,f in enumerate(self.raw_fs):\n",
    "                if not isinstance(f,Transform): f = mk_tfm(f, t)\n",
    "                f._filter_with_type(t)\n",
    "                self.fs.append(f)\n",
    "                if hasattr(t, 'show') and self.t_show is None:\n",
    "                    self.t_idx,self.t_show = i,t\n",
    "                t = _get_ret(f.encodes) or t\n",
    "            if hasattr(t, 'show') and self.t_show is None:\n",
    "                self.t_idx,self.t_show = i+1,t\n",
    "            self.final_t = t\n",
    "                \n",
    "    def __call__(self, o): return compose_tfms(o, self.fs)\n",
    "    def decode  (self, i): return compose_tfms(i, self.fs, func_nm='decode', reverse=True)\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        if self.t_show is None: return self.decode(o)\n",
    "        o = compose_tfms(o, self.fs[self.t_idx:], func_nm='decode', reverse=True)\n",
    "        return self.t_show.show(o, ctx=ctx, **kwargs)\n",
    "    \n",
    "\n",
    "    #def __call__(self, x, **kwargs): return self.composed(x, **kwargs)\n",
    "    #def __getitem__(self, x): return self(x)\n",
    "    #def decode_at(self, idx): return self.decode(self[idx])\n",
    "    #def show_at(self, idx): return self.show(self[idx])\n",
    "    #def __repr__(self): return str(self.tfms)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         \"A pipeline of composed (for encode/decode) transforms, setup one at a time\",\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `x`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `x`\",\n",
    "         decode_at=\"Decoded item at `idx`\",\n",
    "         show_at=\"Show item at `idx`\",\n",
    "         show=\"Show item\",\n",
    "         delete=\"Delete transform `idx` from pipeline\",\n",
    "         remove=\"Remove `tfm` from pipeline\",\n",
    "         set_tupled=\"Set any `MappedTransform`s in `tfms` to tupled mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of transforms are often applied in a particular order, and decoded by applying in the reverse order. `Pipeline` provides this functionality, and also ensures that any `setup` methods are called, without including later transforms in those calls. NB: `setup` must be run before encoding/decoding.\n",
    "\n",
    "Here's some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipelines are a noop\n",
    "pipe = Pipeline()\n",
    "pipe.setup()\n",
    "test_eq(pipe(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a standard pipeline\n",
    "pipe = Pipeline([negtfm(),floattfm()])\n",
    "pipe.setup()\n",
    "\n",
    "start = 2\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(t, pipe[2])\n",
    "test_eq(pipe.decode(t), start)\n",
    "# `show` is on `tfloat` so `show_at` decodes that tfm only\n",
    "test_stdout(lambda:pipe.show_at(1), '-1')\n",
    "test_eq(pipe.assoc, Item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([floattfm(),negtfm()])\n",
    "pipe.setup()\n",
    "\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "# `show` is on `tfloat` so needs to decode negtfm first\n",
    "test_stdout(lambda:pipe.show_at(1), '1')\n",
    "test_eq(pipe.assoc, Item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`x`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `x`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`x`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `decode` of all `tfms` on `x`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.delete</code>\" class=\"doc_header\"><code>Pipeline.delete</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.delete</code>(**`idx`**)\n",
       "\n",
       "Delete transform `idx` from pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.remove</code>\" class=\"doc_header\"><code>Pipeline.remove</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.remove</code>(**`tfm`**)\n",
       "\n",
       "Remove `tfm` from pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.add</code>\" class=\"doc_header\"><code>Pipeline.add</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.add</code>(**`tfms`**, **`items`**=*`None`*)\n",
       "\n",
       "Call `setup` on all `tfms` and append them to this pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.show_at</code>\" class=\"doc_header\"><code>Pipeline.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode_at</code>\" class=\"doc_header\"><code>Pipeline.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode_at</code>(**`idx`**)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_tfm(tfm):\n",
    "    \"Create a `Pipeline` (if `tfm` is listy) or a `Transform` otherwise\"\n",
    "    if isinstance(tfm,Pipeline): return tfm\n",
    "    return Pipeline(tfm) if is_listy(tfm) else Transform.create(tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdList(GetAttr):\n",
    "    \"A transform applied to a collection of `items`\"\n",
    "    _xtra = 'decode __call__ show assoc'.split()\n",
    "    \n",
    "    def __init__(self, items, tfm, do_setup=True):\n",
    "        self.items = L(items)\n",
    "        self.default = self.tfm = make_tfm(tfm)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        return its.mapped(self.tfm) if is_iter(i) else self.tfm(its)\n",
    "\n",
    "    def decode_batch(self, b, **kwargs):\n",
    "        \"Decode `b`, a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        transp = L(zip(*L(b)))\n",
    "        return transp.mapped(self.decode, **kwargs).zipped()\n",
    "\n",
    "    def setup(self): getattr(self.tfm,'setup',noop)(self)\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tfm, do_setup=False)\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx): return self.show(self[idx])\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfm}\"\n",
    "    \n",
    "    _docs = dict(setup=\"Transform setup with self\",\n",
    "                 decode_at=\"Decoded item at `idx`\",\n",
    "                 show_at=\"Show item at `idx`\",\n",
    "                 subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#3) [1,2,3]\n",
       "tfms - [<class 'local.core.negtfm'>, <class 'local.core.floattfm'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([negtfm(),floattfm()])\n",
    "pipe.setup()\n",
    "\n",
    "tl = TfmdList([1,2,3], pipe)\n",
    "t = tl[1]\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq(tl.decode(t), 2)\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1.,-3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - [<function _lbl at 0x7f7cfab74158>, <class '__main__._Cat'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _Cat(Transform):\n",
    "    assoc,order=Item,1\n",
    "    def encodes(self, o): return self.o2i[o] if self._done_setup else o\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setups(self, items): self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o): return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq([1,0,0,0,1], tl)\n",
    "test_eq(1, tl[-1])\n",
    "test_eq([1,0], tl[0,1])\n",
    "t = list(tl)\n",
    "test_eq([1,0,0,0,1], t)\n",
    "test_eq(['dog','cat','cat','cat','dog'], map(tl.decode,t))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.__getitem__</code>\" class=\"doc_header\"><code>TfmdList.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.__getitem__</code>(**`i`**)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.decode(tl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "tl.show_at(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmOver -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmOver(Transform):\n",
    "    \"Create tuple containing each of `tfms` applied to each of `o`\"\n",
    "    def __init__(self, tfms=None):\n",
    "        if tfms is None: tfms = [None]\n",
    "        self.activ,self.tfms = None,L(tfms).mapped(Pipeline)\n",
    "\n",
    "    def __call__(self, o, *args, **kwargs):\n",
    "        \"List of output of each of `tfms` on `o`\"\n",
    "        if self.activ is not None: return self.tfms[self.activ](o[self.activ], *args, **kwargs)\n",
    "        return [t(p, *args, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        \"Show result of `show` from each of `tfms`\"\n",
    "        for p,t in zip(o,self.tfms): ctx = t.show(p, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    def decode(self, o, **kwargs): return [t.decode(p, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    def __repr__(self): return f'TfmOver({self.tfms})'\n",
    "\n",
    "    def setups(self, o=None):\n",
    "        \"Setup each of `tfms` independently\"\n",
    "        for i,tfm in enumerate(self.tfms):\n",
    "            self.activ = i\n",
    "            tfm.setup(o)\n",
    "        self.activ=None\n",
    "    \n",
    "    @property\n",
    "    def assoc(self): return self.tfms.attrgot('assoc')\n",
    "    \n",
    "    @classmethod\n",
    "    def piped(cls, tfms=None, final_tfms=None):\n",
    "        \"`Pipeline` that duplicates input, then maps `TfmOver` over `tfms`, optionally followed by any `final_tfms`\"\n",
    "        tfms = L(ifnone(tfms,[None]))\n",
    "        init_tfm = partial(replicate,match=tfms)\n",
    "        return Pipeline([init_tfm,cls(tfms)] + _set_tupled(final_tfms))\n",
    "\n",
    "    xt,yt = add_props(lambda i,x:x.tfms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TNorm(Transform):\n",
    "    assoc=Item\n",
    "    def __init__(self): self.m,self.s = 0,1\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setup(self, items):\n",
    "        its = tensor(items)\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tl = TfmdList(items, TfmOver.piped([negtfm(), [negtfm(),_TNorm()]]))\n",
    "x,y = zip(*tl)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, [-1,-2,-3,-4])\n",
    "test_stdout(lambda:tl.show_at(1), 'tensor(-2.)')\n",
    "test_eq(tl.tfm.assoc, [None,Item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b  [(-1, -2, -3, -4), (tensor(1.1619), tensor(0.3873), tensor(-0.3873), tensor(-1.1619))]\n",
      "bd (#2) [(#4) [1,2,3,4],(#4) [tensor(1.),tensor(2.),tensor(3.),tensor(4.)]]\n"
     ]
    }
   ],
   "source": [
    "# Create a \"batch\"\n",
    "b = list(zip(*tl))\n",
    "bd = tl.decode_batch(b)\n",
    "\n",
    "test_eq(len(bd),2)\n",
    "test_eq(bd[0],items)\n",
    "test_eq(bd[1],items)\n",
    "test_eq(type(bd[1][0]),Tensor)\n",
    "print('b ',b)\n",
    "print('bd',bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty tuplify\n",
    "tp = TfmOver()\n",
    "tp.setup()\n",
    "test_eq(tp([1]), [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-oo.ipynb.\n",
      "Converted 07_pets_tutorial-oo1.ipynb.\n",
      "Converted 07_pets_tutorial-oo2-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_augmentation.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n",
      "Converted tmp_tensor_inherit.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
