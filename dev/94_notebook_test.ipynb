{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from local.imports import *\n",
    "from local.notebook.core import *\n",
    "from local.notebook.export import *\n",
    "import nbformat,inspect\n",
    "from nbformat.sign import NotebookNotary\n",
    "from nbconvert.preprocessors import ExecutePreprocessor\n",
    "from local.test import *\n",
    "from local.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp notebook.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting tests from notebooks\n",
    "\n",
    "> The functions that grab the cells containing tests (filtering with potential flags) and execute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_re_all_flag = re.compile(\"\"\"\n",
    "# Matches any line with #all_something and catches that something in a group:\n",
    "^         # beginning of line (since re.MULTILINE is passed)\n",
    "\\s*       # any number of whitespace\n",
    "\\#\\s*     # # then any number of whitespace\n",
    "all_(\\S+) # all_ followed by a group with any non-whitespace chars\n",
    "\\s*       # any number of whitespace\n",
    "$         # end of line (since re.MULTILINE is passed)\n",
    "\"\"\", re.IGNORECASE | re.MULTILINE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def check_all_flag(cells):\n",
    "    for cell in cells:\n",
    "        if check_re(cell, _re_all_flag): return check_re(cell, _re_all_flag).groups()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = read_nb(\"35_tutorial_wikitext.ipynb\")\n",
    "test_eq(check_all_flag(nb['cells']), 'slow')\n",
    "nb = read_nb(\"91_notebook_export.ipynb\")\n",
    "assert check_all_flag(nb['cells']) is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_re_flags = re.compile(\"\"\"\n",
    "# Matches any line with a test flad and catches it in a group:\n",
    "^               # beginning of line (since re.MULTILINE is passed)\n",
    "\\s*             # any number of whitespace\n",
    "\\#\\s*           # # then any number of whitespace\n",
    "(slow|cuda|cpp) # all test flags\n",
    "\\s*             # any number of whitespace\n",
    "$               # end of line (since re.MULTILINE is passed)\n",
    "\"\"\", re.IGNORECASE | re.MULTILINE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cell_flags(cell):\n",
    "    if cell['cell_type'] != 'code': return []\n",
    "    return _re_flags.findall(cell['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_cell_flags({'cell_type': 'code', 'source': \"#hide\\n# slow\\n\"}), ['slow'])\n",
    "test_eq(get_cell_flags({'cell_type': 'code', 'source': \"#hide\\n# slow\\n # cuda\"}), ['slow', 'cuda'])\n",
    "test_eq(get_cell_flags({'cell_type': 'markdown', 'source': \"#hide\\n# slow\\n # cuda\"}), [])\n",
    "test_eq(get_cell_flags({'cell_type': 'code', 'source': \"#hide\\n\"}), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _add_import_cell(mod):\n",
    "    \"Return an import cell for `mod`\"\n",
    "    return {'cell_type': 'code',\n",
    "            'execution_count': None,\n",
    "            'metadata': {'hide_input': True},\n",
    "            'outputs': [],\n",
    "            'source': f\"\\nfrom local.{mod} import *\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_re_is_export = re.compile(r\"\"\"\n",
    "# Matches any text with #export or #exports flag:\n",
    "^         # beginning of line (since re.MULTILINE is passed)\n",
    "\\s*       # any number of whitespace\n",
    "\\#\\s*     # # then any number of whitespace\n",
    "exports?  # export or exports\n",
    "\\s*       # any number of whitespace\n",
    "\"\"\", re.IGNORECASE | re.MULTILINE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_re_has_import = re.compile(r\"\"\"\n",
    "# Matches any text with import statement:\n",
    "^         # beginning of line (since re.MULTILINE is passed)\n",
    "\\s*       # any number of whitespace\n",
    "import    # # then any number of whitespace\n",
    "\\s+  \n",
    "|\n",
    "\\s*\n",
    "from\n",
    "\\s+\\S+\\s+\n",
    "import\n",
    "\\s+\n",
    "\"\"\", re.IGNORECASE | re.MULTILINE | re.VERBOSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class NoExportPreprocessor(ExecutePreprocessor):\n",
    "    \"An `ExecutePreprocessor` that executes not exported cells\"\n",
    "    @delegates(ExecutePreprocessor.__init__)\n",
    "    def __init__(self, flags, **kwargs):\n",
    "        self.flags = flags\n",
    "        super().__init__(**kwargs)\n",
    "        \n",
    "    def preprocess_cell(self, cell, resources, index):\n",
    "        if 'source' not in cell or cell['cell_type'] != \"code\": return cell, resources\n",
    "        if _re_is_export.search(cell['source']) and not _re_has_import.search(cell['source']): \n",
    "            return cell, resources\n",
    "        for f in get_cell_flags(cell):\n",
    "            if f not in self.flags:  return cell, resources\n",
    "        print(cell[\"source\"])\n",
    "        return super().preprocess_cell(cell, resources, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_nb(nb, flags=None, mod=None, name=None):\n",
    "    \"Execute `nb` (or only the `show_doc` cells) with `metadata`\"\n",
    "    mod = find_default_export(nb['cells'])\n",
    "    if mod is not None: nb['cells'].insert(0, _add_import_cell(mod))\n",
    "    ep = NoExportPreprocessor(L(flags), timeout=600, kernel_name='python3')\n",
    "    pnb = nbformat.from_dict(nb)\n",
    "    ep.preprocess(pnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "from local.callback.fp16 import *\n",
      "#export\n",
      "from local.torch_basics import *\n",
      "from local.test import *\n",
      "from local.layers import *\n",
      "from local.data.all import *\n",
      "from local.notebook.showdoc import show_doc\n",
      "from local.optimizer import *\n",
      "from local.learner import *\n",
      "from local.callback.progress import *\n",
      "#default_exp callback.fp16\n",
      "#hide\n",
      "from local.utils.test import *\n",
      "# export \n",
      "from local.utils.fp16_utils import convert_network, model_grads_to_master_grads, master_params_to_model_params\n",
      "model = nn.Sequential(nn.Linear(10,30), nn.BatchNorm1d(30), nn.Linear(30,2)).cuda()\n",
      "model = convert_network(model, torch.float16)\n",
      "\n",
      "for i,t in enumerate([torch.float16, torch.float32, torch.float16]):\n",
      "    test_eq(model[i].weight.dtype, t)\n",
      "    test_eq(model[i].bias.dtype,   t)\n",
      "    \n",
      "model = nn.Sequential(nn.Linear(10,30), BatchNorm(30, ndim=1), nn.Linear(30,2)).cuda()\n",
      "model = convert_network(model, torch.float16)\n",
      "\n",
      "for i,t in enumerate([torch.float16, torch.float32, torch.float16]):\n",
      "    test_eq(model[i].weight.dtype, t)\n",
      "    test_eq(model[i].bias.dtype,   t)\n",
      "#export\n",
      "from torch.nn.utils import parameters_to_vector\n",
      "\n",
      "def get_master(opt, flat_master=False):\n",
      "    model_params = [[param for param in pg if param.requires_grad] for pg in opt.param_groups]\n",
      "    if flat_master:\n",
      "        master_params = []\n",
      "        for pg in model_params:\n",
      "            mp = parameters_to_vector([param.data.float() for param in pg])\n",
      "            mp = torch.nn.Parameter(mp, requires_grad=True)\n",
      "            if mp.grad is None: mp.grad = mp.new(*mp.size())\n",
      "            master_params.append([mp])\n",
      "    else:\n",
      "        master_params = [[param.clone().float().detach() for param in pg] for pg in model_params]\n",
      "        for pg in master_params:\n",
      "            for param in pg: param.requires_grad_(True)\n",
      "    return model_params, master_params\n",
      "#hide\n",
      "#cuda\n",
      "learn = synth_learner()\n",
      "learn.model = convert_network(nn.Sequential(nn.Linear(1,1), nn.Linear(1,1)), torch.float16).cuda()\n",
      "learn.splitter = lambda m: [list(m[0].parameters()), list(m[1].parameters())]\n",
      "learn.opt = learn.opt_func(learn.splitter(learn.model), learn.lr)\n",
      "model_p,master_p = get_master(learn.opt)\n",
      "test_eq(len(model_p), 2)   #2 pqrqm groups\n",
      "test_eq(len(master_p), 2)\n",
      "for pg1,pg2 in zip(model_p,master_p):\n",
      "    test_eq([p.float() for p in pg1], pg2) #Same values but different types\n",
      "    for p in pg1: assert p.dtype == torch.float16\n",
      "#hide\n",
      "#cuda\n",
      "#Flattened version\n",
      "model_pf,master_pf = get_master(learn.opt, flat_master=True)\n",
      "test_eq(len(model_pf), 2)   #2 pqrqm groups\n",
      "test_eq(len(master_pf), 2)\n",
      "for pg1,pg2 in zip(model_pf,master_pf):\n",
      "    test_eq(len(pg2), 1) #One flattened tensor\n",
      "    test_eq([p.float().squeeze() for p in pg1], [p for p in pg2[0]]) #Same values but different types\n",
      "    for p in pg1: assert p.dtype == torch.float16\n",
      "#hide\n",
      "#cuda\n",
      "xb,yb = learn.dbunch.one_batch()\n",
      "pred = learn.model.cuda()(xb.cuda().half())\n",
      "loss = F.mse_loss(pred, yb.cuda().half())\n",
      "loss.backward()\n",
      "to_master_grads(model_p, master_p)\n",
      "to_master_grads(model_pf, master_pf, flat_master=True)\n",
      "test_eq([[p.grad.float() for p in pg] for pg in model_p],\n",
      "        [[p.grad for p in pg] for pg in master_p])\n",
      "test_eq([[p.grad.float().squeeze() for p in pg] for pg in model_pf], \n",
      "        [[p for p in pg[0].grad] for pg in master_pf])\n",
      "xb.shape\n",
      "#hide\n",
      "#cuda\n",
      "learn.opt.param_groups = master_p\n",
      "learn.opt.step()\n",
      "to_model_params(model_p, master_p)\n",
      "test_close([[p.float() for p in pg] for pg in model_p], [[p for p in pg] for pg in master_p], eps=1e-3)\n",
      "#hide\n",
      "#cuda\n",
      "learn.opt.param_groups = master_pf\n",
      "learn.opt.step()\n",
      "to_model_params(model_pf, master_pf, flat_master=True)\n",
      "test_close([[p.float().squeeze() for p in pg] for pg in model_pf], [[p for p in pg[0]] for pg in master_pf], eps=1e-3)\n",
      "x = torch.randn(3,4)\n",
      "assert not test_overflow(x)\n",
      "x[1,2] = float('inf')\n",
      "assert test_overflow(x)\n",
      "#hide\n",
      "#cuda\n",
      "assert not grad_overflow(model_p)\n",
      "assert not grad_overflow(model_pf)\n",
      "model_p[1][0].grad.data[0,0] = float('inf')\n",
      "model_pf[0][1].grad.data[0] = float('inf')\n",
      "assert grad_overflow(model_p)\n",
      "assert grad_overflow(model_pf)\n",
      "#hide\n",
      "class TestBeforeMixedPrecision(Callback):\n",
      "    run_before=MixedPrecision\n",
      "    def begin_fit(self): test_eq(next(iter(self.model.parameters())).dtype, torch.float32)\n",
      "    def begin_batch(self): test_eq(self.x.dtype, torch.float32)\n",
      "    def after_pred(self): test_eq(self.pred.dtype, torch.float16)\n",
      "    def after_loss(self): self.loss = self.learn.loss.detach().clone()\n",
      "    def after_backward(self):\n",
      "        self.has_overflown = grad_overflow(self.mixed_precision.model_pgs)\n",
      "        self.grads = [p.grad.data.clone() for p in self.model.parameters()]\n",
      "        self.old_params = [p.data.clone() for p in self.model.parameters()]\n",
      "    def after_step(self): assert not self.has_overflown\n",
      "    def after_cancel_batch(self): assert self.has_overflown\n",
      "        \n",
      "class TestAfterMixedPrecision(Callback):\n",
      "    run_after=MixedPrecision\n",
      "    def begin_fit(self): test_eq(next(iter(self.model.parameters())).dtype, torch.float16)\n",
      "    def after_fit(self): test_eq(next(iter(self.model.parameters())).dtype, torch.float32)\n",
      "    def begin_batch(self): test_eq(self.x.dtype, torch.float16)\n",
      "    def after_pred(self): test_eq(self.pred.dtype, torch.float32)\n",
      "    def after_loss(self):\n",
      "        loss_scale = self.mixed_precision.loss_scale if self.training else 1.\n",
      "        test_eq(self.loss, self.test_before_mixed_precision.loss * loss_scale) \n",
      "    def after_backward(self):\n",
      "        tbmp = self.test_before_mixed_precision\n",
      "        test_eq(self.loss, tbmp.loss)\n",
      "        #Test gradients have been copied and scaled back\n",
      "        test_close(sum([[p.grad.data for p in pg] for pg in self.mixed_precision.master_pgs], []),\n",
      "                   [g.float()/self.mixed_precision.loss_scale for g in tbmp.grads])\n",
      "    def after_step(self):\n",
      "        tbmp,mp =self.test_before_mixed_precision,self.mixed_precision\n",
      "        #Test master params have been copied to model\n",
      "        test_close(sum([[p.data for p in pg] for pg in mp.master_pgs], []),\n",
      "                   [p.data.float() for p in self.model.parameters()], eps=1e-3)\n",
      "        #Test update has been done properly\n",
      "        for p,g,op in zip(self.model.parameters(), tbmp.grads, tbmp.old_params):\n",
      "            test_close(p.data.float(), op.float() - self.lr*g.float()/self.mixed_precision.loss_scale, eps=1e-3)\n",
      "#hide\n",
      "#cuda\n",
      "learn = synth_learner(cbs=MixedPrecision(), cuda=True)\n",
      "learn.model = nn.Sequential(nn.Linear(1,1), nn.Linear(1,1)).cuda()\n",
      "learn.opt_func = partial(SGD, mom=0.)\n",
      "learn.splitter = lambda m: [list(m[0].parameters()), list(m[1].parameters())]\n",
      "learn.fit(3, cbs=[TestAfterMixedPrecision(), TestBeforeMixedPrecision()])\n",
      "#Check loss scale did change\n",
      "assert 1 < learn.mixed_precision.loss_scale < 2**24\n",
      "#Check the model did train\n",
      "for v1,v2 in zip(learn.recorder.values[0], learn.recorder.values[-1]): assert v2<v1\n",
      "#hide\n",
      "#cuda\n",
      "learn = synth_learner(cbs=MixedPrecision(dynamic=False), cuda=True)\n",
      "learn.model = nn.Sequential(nn.Linear(1,1), nn.Linear(1,1)).cuda()\n",
      "learn.opt_func = partial(SGD, mom=0.)\n",
      "learn.splitter = lambda m: [list(m[0].parameters()), list(m[1].parameters())]\n",
      "learn.fit(3, cbs=[TestAfterMixedPrecision(), TestBeforeMixedPrecision()])\n",
      "#Check loss scale did mot change\n",
      "test_eq(learn.mixed_precision.loss_scale,512)\n",
      "#Check the model did train\n",
      "for v1,v2 in zip(learn.recorder.values[0], learn.recorder.values[-1]): assert v2<v1\n",
      "learn = synth_learner(cuda=True)\n",
      "learn.model = nn.Sequential(nn.Linear(1,1), nn.Linear(1,1)).cuda()\n",
      "learn.opt_func = partial(SGD, mom=0.)\n",
      "learn.splitter = lambda m: [list(m[0].parameters()), list(m[1].parameters())]\n",
      "learn.to_fp16()\n",
      "learn.fit(3, cbs=[TestAfterMixedPrecision(), TestBeforeMixedPrecision()])\n",
      "#Check the model did train\n",
      "for v1,v2 in zip(learn.recorder.values[0], learn.recorder.values[-1]): assert v2<v1\n",
      "#hide\n",
      "from local.notebook.export import *\n",
      "notebook2script(all_fs=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = read_nb(\"18_callback_fp16.ipynb\")\n",
    "_test_nb(nb, flags=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
