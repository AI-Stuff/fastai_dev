{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.pipeline import *\n",
    "from local.data.core import *\n",
    "from local.data.external import *\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_all_ = ['Image']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core vision\n",
    "> Basic image opening/processing functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/sgugger/git/fastai_docs/dev/data/mnist_tiny/train/3/8055.png')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "fns = get_image_files(path)\n",
    "fn = fns[0]; fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class PILImage():\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): return show_image(o, ctx=ctx, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Imagify(Transform):\n",
    "    \"Open an `Image` from path `fn`\"\n",
    "    def __init__(self, func=Image.open):  self.func = func\n",
    "    def encodes(self, fn)->PILImage: return self.func(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4ElEQVR4nMWRsQ4BQRRFr41ESaKgYgqJdnUKke2U+AF8gU7hA3Si0GkU+v0ExNaiobSRiEpEFBLFzcsqlhA7qxO3mnln3rv3ZYD/Ke14I7vV0kOLQpLziooGoVoKSQrZ1rQmpycfXl0rEcQVm/5sKeutS+OViOeGpR6Qcm36l49spp0BEMtq2oqTI0nKLh5ktcsjUDfIlIh4IrLQZVEk5batp0Jh/71ivI6HIYC90vUBMHsULpOvgr+ncjtnABHDQMGpbjV2j1/hRuf5VP4DHnKzkBwAgHTjOXbd+Pbu57oDyUZ5YLf9a8QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F469A05B908>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timg = Imagify()\n",
    "img = timg(fn)\n",
    "test_eq(img.size, (28,28))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Mask(PILImage):\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, cmap='tab20', alpha=0.5, vmin=1, vmax=30, **kwargs): \n",
    "        return show_image(o, ctx=ctx, cmap=cmap, alpha=alpha, vmin=vmin, vmax=vmax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Maskify(Transform):\n",
    "    \"Open an `Image` from path `fn`\"\n",
    "    def __init__(self, func=Image.open): self.func = func\n",
    "    def encodes(self, fn)->Mask: return self.func(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4ElEQVR4nMWRsQ4BQRRFr41ESaKgYgqJdnUKke2U+AF8gU7hA3Si0GkU+v0ExNaiobSRiEpEFBLFzcsqlhA7qxO3mnln3rv3ZYD/Ke14I7vV0kOLQpLziooGoVoKSQrZ1rQmpycfXl0rEcQVm/5sKeutS+OViOeGpR6Qcm36l49spp0BEMtq2oqTI0nKLh5ktcsjUDfIlIh4IrLQZVEk5batp0Jh/71ivI6HIYC90vUBMHsULpOvgr+ncjtnABHDQMGpbjV2j1/hRuf5VP4DHnKzkBwAgHTjOXbd+Pbu57oDyUZ5YLf9a8QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F4699FFB320>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmask = Maskify(func=lambda fn: Image.open(fn)/255)\n",
    "mask = timg(fn)\n",
    "test_eq(mask.size, (28,28))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.PngImagePlugin.PngImageFile"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageConverter(Transform):\n",
    "    \"Convert `img` to `mode`\"\n",
    "    def __init__(self, mode='RGB', mask_mode='L'): self.modes = (mode,mask_mode)\n",
    "    def encodes(self, o:PILImage): return o.convert(self.modes[0])\n",
    "    def encodes(self, o:Mask):     return o.convert(self.modes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ImageConverter('RGB')\n",
    "f.accept_types(PILImage)\n",
    "test_eq(f(img).mode, 'RGB')\n",
    "f.accept_types(Mask)\n",
    "test_eq(f(mask).mode, 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def image_resize(img, size, resample=Image.BILINEAR):\n",
    "    \"Resize image to `size` using `resample\"\n",
    "    return img.resize(size, resample=resample)\n",
    "image_resize.order=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageResizer(Transform):\n",
    "    \"Resize image to `size` using `resample\"\n",
    "    def __init__(self, size, resample=Image.BILINEAR):\n",
    "        if not is_listy(size): size=(size,size)\n",
    "        self.size,self.resample = size,resample\n",
    "\n",
    "    def encodes(self, o:PILImage): return image_resize(o, size=self.size, resample=self.resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ImageResizer(14)\n",
    "f.accept_types(PILImage)\n",
    "test_eq(f(img).size, (14,14))\n",
    "f.accept_types(Mask)\n",
    "test_eq(f(mask).size, (14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def image2byte(img):\n",
    "    \"Transform image to byte tensor in `c*h*w` dim order.\"\n",
    "    res = torch.ByteTensor(torch.ByteStorage.from_buffer(img.tobytes()))\n",
    "    w,h = img.size\n",
    "    return res.view(h,w,-1).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageToByteTensor(Transform):\n",
    "    \"Transform image to byte tensor in `c*h*w` dim order.\"\n",
    "    order = 15\n",
    "    def encodes(self, o:PILImage)->TensorImage: return image2byte(o)\n",
    "    def encodes(self, o:Mask)    ->TensorMask:  return image2byte(o)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = ImageToByteTensor()\n",
    "tfm.accept_types(PILImage)\n",
    "test_eq(tfm(img).shape, (1,28,28))\n",
    "tfm.accept_types(Mask)\n",
    "test_eq(tfm(mask).shape, (28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm we can pipeline this with `Imagify`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA4BJREFUeJzt2r8rfXEcx/EnfcuPQSImoqQUg8wMfpSJUgalzP4BkfKjLGYmm0FRDBgMRmWQRQx+pEwWSeoqSl3f4dvn3u91neN+D96fe+739VjPOZ1Pr17efc7nKnp7e0N+VrHvBfwPFLIBhWxAIRtQyAYUsgGFbEAhG/hl/L5C/vIpCrqgJhtQyAYUsgGFbEAhG1DIBhSyAet9ciRPT08AjI6OArC7uwvA9PQ0AHd3dwCMjIyknunt7bVcYig12UCR8c9PkV52eXkJQFtbGwDJZBKA4uLgjgwODgIwPz8PQH19PQAVFRWfPhuRvvh8ikWTHx8fARgaGgLg4OAACG9jUNvX19cBGB4ejrKUMGqyT7FosvP8/AzA2NgYkG70w8ND1r1BTS4tLQWgrq4OgO3tbQAaGhoyrkegJvsUqya/d3Z2BsDS0hIAq6urqWu57ED+vu/i4gKA5ubmqMtRk32KdZPDXF9fA7CysgLA0dERAIeHhxn3uSa3tLQAcH5+HvWVarJPBdtkx517LC8vAzA7O5tx3TW5vLwcgJ2dHQB6enr+9VVqsk+xOIWL4vb2FoC+vj4gPaODvLy8AHB1dQVEanIgNdlAQc3km5sb4M++eWNjA4D7+/vQZ9xMbmpqAuD09BSI9OWnmexTQczk4+NjAPr7+wFIJBI5f/E5U1NTwJfOLgLFely4I9Dq6uqsa5+FPDAwAKQPiL6BxoVPBTEuwkZCSUkJAI2NjUD6EKm1tfWnl5WiJhsoiCaHmZubA2ByctLbGtRkA7Fusvt5f2FhAYCZmZmse9xHhtuJVFZWGq0uTU02EOt9suMOgzY3NwGYmJjI2id3dnYCsLe3B0BZWdl3L0P7ZJ/ycia//5JbW1sDoLa2NvQ591eZTCZTTXbcvw90dXUBsL+/D0BVVdU3rTqYmmwgL2eya3JNTc2H13M5/Pnsnvb2diB9uPQNNJN9ysuZbOHk5MTsXWqygbycyW6eJhIJAMbHxwHY2trKuP6Vmey8vr7msqRcaCb7lJdNfs/9g4rbCbif+aM0uaOjA4DFxUUAuru7oyzpI2qyT7FockyoyT4pZAMK2YBCNqCQDShkAwrZgPUpXOBespCpyQYUsgGFbEAhG1DIBhSyAYVsQCEbUMgGFLIBhWxAIRtQyAYUsgGFbEAhG1DIBhSyAYVsQCEbUMgGFLIBhWzgN2DhGcF3EMK+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe = Pipeline([Imagify(), ImageToByteTensor()])\n",
    "img = pipe(fn)\n",
    "test_eq(img.shape, (1,28,28))\n",
    "pipe.show(img, cmap=\"Greys\", figsize=(1,1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform(ByteToFloatTensor)\n",
    "def decodes(self, o:TensorMask): return o\n",
    "def decodes(self, o:TensorMask): return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@docs\n",
    "class ByteToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order=20 #Need to run after CUDA if on the GPU\n",
    "    def __init__(self, div=True): self.div = div\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(255.) if self.div else o.float()\n",
    "    def decodes(self, o:TensorImage): return o.clamp(0., 1.) if self.div else o\n",
    "    \n",
    "    _docs=dict(encodes=\"Convert items matching `mask` to float and optionally divide by 255\",\n",
    "               decodes=\"Clamp to (0,1) items matching `mask`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial-oo.ipynb.\n",
      "Converted 07_pets_tutorial-oo1.ipynb.\n",
      "Converted 07_pets_tutorial-oo2-meta.ipynb.\n",
      "This cell doesn't have an export destination and was ignored:\n",
      " \n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_augmentation.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
