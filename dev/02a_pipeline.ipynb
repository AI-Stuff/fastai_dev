{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.transform import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` is created with an `encodes` and potentially `decodes` function. \n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items.\n",
    "- `Tuplify` is a special `Trannsform` that takes a list of list of transforms or a list of `Pipeline`s, then aapplies them to the element it receives to return a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms, are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the `multimethod` module and type-annotation in `Transofrm`, but you can also use the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Sig</code>\" class=\"doc_header\"><code>Sig</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sig</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SelfFunc():\n",
    "    \"Search for `name` attribute and call it with `args` and `kwargs` on any object it's passed.\"\n",
    "    def __init__(self, nm, *args, **kwargs): self.nm,self.args,self.kwargs = nm,args,kwargs\n",
    "    def __repr__(self): return f'self: {self.nm}({self.args}, {self.kwargs})'\n",
    "    def __call__(self, o):\n",
    "        if not is_listy(o): return getattr(o,self.nm)(*self.args, **self.kwargs)\n",
    "        else: return [getattr(o_,self.nm)(*self.args, **self.kwargs) for o_ in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `Func` and `SelfFunc` is that `Func` will generate a function when you call it on a type. On the other hand, `SelfFunc` is already a function and each time you call it on an object it looks for the `name` attribute and call it on `args` and `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SelfFunc('sqrt')\n",
    "x = torch.tensor([4.])\n",
    "test_eq(tst(x), torch.tensor([2.]))\n",
    "assert isinstance(tst(x), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _SelfFunc():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return SelfFunc(k, *args, **kwargs)\n",
    "        return _inner\n",
    "    \n",
    "Self = _SelfFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Self</code>\" class=\"doc_header\"><code>Self</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Self</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Self, name=\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Self` is just syntax sugar to create a `SelfFunc` object more easily with the syntax `Self.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sqrt()\n",
    "x = torch.tensor([4.])\n",
    "test_eq(f(x), torch.tensor([2.]))\n",
    "assert isinstance(f(x), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_tfms(x, tfms, is_enc=True, reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    for f in tfms:\n",
    "        if not is_enc: f = f.decode\n",
    "        x = f(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_int  (x)->Int  : return x\n",
    "def to_float(x)->Float: return x\n",
    "def double(x): return x*2\n",
    "def half(x)->None: return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_compose(a, b, *fs):\n",
    "    test_eq_type(compose_tfms(a, tfms=map(Transform,fs)), b)\n",
    "\n",
    "test_compose(1,   Int(1),   to_int)\n",
    "test_compose(1,   Float(1), to_int,to_float)\n",
    "test_compose(1,   Float(2), to_int,to_float,double)\n",
    "test_compose(2.0, 2.0,      to_int,double,half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x:float)->Float: return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [A(), Transform(math.sqrt)]\n",
    "t = compose_tfms(3., tfms=tfms)\n",
    "test_eq_type(t, Float(2.))\n",
    "test_eq(compose_tfms(t, tfms=tfms, is_enc=False), 1.)\n",
    "test_eq(compose_tfms(4., tfms=tfms, reverse=True), 3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [A(as_item=False), Transform(math.sqrt, as_item=False)]\n",
    "test_eq(compose_tfms((9,3.), tfms=tfms), (3,2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def batch_to_samples(b, max_rows=10):\n",
    "    \"'Transposes' a batch to (at most `max_rows`) samples\"\n",
    "    if isinstance(b, Tensor): return b[:max_rows]\n",
    "    return zip(*L(batch_to_samples(b_, max_rows) for b_ in b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tensor([1,2,3])\n",
    "test_eq(batch_to_samples([t,t+1], max_rows=2), ([1,2],[2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def mk_transform(f, as_item=True):\n",
    "    \"Convert function `f` to `Transform` if it isn't already one\"\n",
    "    return f if isinstance(f,Transform) else Transform(f, as_item=as_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline():\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None, as_item=True): \n",
    "        if not funcs: funcs=[noop]\n",
    "        if isinstance(funcs, Pipeline): funcs = funcs.fs\n",
    "        self.fs = L(funcs).mapped(mk_transform).sorted(key='order')\n",
    "        self.set_as_item(as_item)\n",
    "        \n",
    "    def set_as_item(self, as_item):\n",
    "        self.as_item = as_item\n",
    "        for f in self.fs: f.as_item = as_item\n",
    "    \n",
    "    def setup(self, items=None):\n",
    "        tfms,self.fs = self.fs,[]\n",
    "        for t in tfms: self.add(t,items)\n",
    "            \n",
    "    def add(self,t, items=None):\n",
    "        getattr(t, 'setup', noop)(items)\n",
    "        self.fs.append(t)\n",
    "                \n",
    "    def __call__(self, o, filt=None): return compose_tfms(o, tfms=self.fs, filt=filt)\n",
    "    def decode  (self, o, filt=None): return compose_tfms(o, tfms=self.fs, is_enc=False, reverse=True, filt=filt)\n",
    "    def __repr__(self): return f\"Pipeline: {self.fs}\"\n",
    "    def __getitem__(self,i): return self.fs[i]\n",
    "    def decode_batch(self, b, filt=None, max_rows=10):\n",
    "        return [self.decode(b_, filt=filt) for b_ in batch_to_samples(b, max_rows=max_rows)]\n",
    "\n",
    "    # TODO: move show_batch here of TfmDS?\n",
    "    def show(self, o, ctx=None, filt=None, **kwargs):\n",
    "        for f in reversed(self.fs):\n",
    "            res = self._show(o, ctx)\n",
    "            if res: return res\n",
    "            o = f.decode(o, filt=filt)\n",
    "        return self._show(o, ctx)\n",
    "\n",
    "    def _show(self, o, ctx, **kwargs):\n",
    "        o1 = [o] if self.as_item else o\n",
    "        if not all(hasattr(o_, 'show') for o_ in o1): return\n",
    "        for o_ in o1: ctx = o_.show(ctx=ctx, **kwargs)\n",
    "        return ctx or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `o`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `o`\",\n",
    "         show=\"Show `o`, a single item from a tuple, decoding as needed\",\n",
    "         add=\"Add transform `t`\",\n",
    "         decode_batch=\"`decode` all sample in a the batch `b`\",\n",
    "         set_as_item=\"Set value of `as_item` for all transforms\",\n",
    "         setup=\"Call each tfm's `setup` in order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple wrapper for `compose_tfm`. Handles adding transforms one at a time and calling setup on each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)\n",
    "pipe.set_as_item(False)\n",
    "test_eq(pipe((1,)), (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntFloatTfm(Transform):\n",
    "    def encodes(self, x)->Int: return x\n",
    "    def decodes(self, x)->Float: return x\n",
    "\n",
    "int_tfm=IntFloatTfm()\n",
    "\n",
    "def neg(x): return -x\n",
    "neg_tfm = Transform(neg, neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([neg_tfm, int_tfm])\n",
    "\n",
    "start = 2.0\n",
    "t = pipe(start)\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2')\n",
    "\n",
    "pipe.set_as_item(False)\n",
    "test_stdout(lambda:pipe.show(pipe((1,2))), '-1\\n-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([int_tfm,neg_tfm])\n",
    "t = pipe(start)\n",
    "test_eq(t, -2)\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, x)->int: return x\n",
    "    def decodes(self, x)->Float: return x\n",
    "    \n",
    "pipe = Pipeline([neg_tfm, A()])\n",
    "t = pipe(start)\n",
    "test_eq_type(t, -2)\n",
    "test_eq_type(pipe.decode(t), Float(start))\n",
    "test_stdout(lambda:pipe.show(t), '-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = (1,2)\n",
    "pipe.set_as_item(False)\n",
    "t = pipe(s2)\n",
    "test_eq_type(t, (-1,-2))\n",
    "test_eq_type(pipe.decode(t), (Float(1.),Float(2.)))\n",
    "test_stdout(lambda:pipe.show(t), '-1.0\\n-2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check filtering is properly applied\n",
    "add1 = B()\n",
    "add1.filt = 1\n",
    "pipe = Pipeline([neg_tfm, A(), add1])\n",
    "test_eq(pipe(start), -2)\n",
    "test_eq(pipe(start, filt=1), -1)\n",
    "test_eq(pipe(start, filt=0), -2)\n",
    "test_eq(pipe(start), -2)\n",
    "for t in [None, 0, 1]: test_eq(pipe.decode(pipe(start, filt=t), filt=t), start)\n",
    "for t in [None, 0, 1]: test_stdout(lambda: pipe.show(pipe(start, filt=t), filt=t), \"-2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: method examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`o`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `o`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`o`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `decode` of all `tfms` on `o`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode_batch</code>\" class=\"doc_header\"><code>Pipeline.decode_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode_batch</code>(**`b`**, **`filt`**=*`None`*, **`max_rows`**=*`10`*)\n",
       "\n",
       "`decode` all sample in a the batch `b`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.set_as_item(False)\n",
    "t = tensor([1,2,3])\n",
    "test_eq(pipe.decode_batch([t,t+1], filt=1, max_rows=2), [(0,-1),(-1,-2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.setup</code>\" class=\"doc_header\"><code>Pipeline.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.setup</code>(**`items`**=*`None`*)\n",
       "\n",
       "Call each tfm's `setup` in order"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the setup, the `Pipeline` starts with no transform and adds them one at a time, so that during its setup, each transfrom get the items processed up to its point and not after. Depending on the attribute `add_before_setup`, the transform is added after the setup (default behaivor) so it's not called on the items used for the setup, or before (in which case it's called on the values used for setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test is below with TfmdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdList():\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    def __init__(self, items, tfms, do_setup=True, as_item=True):\n",
    "        self.items = L(items)\n",
    "        self._mk_pipeline(tfms.tfms if isinstance(tfms,TfmdList) else tfms, do_setup=do_setup, as_item=as_item)\n",
    "\n",
    "    def _mk_pipeline(self, tfms, do_setup, as_item):\n",
    "        if isinstance(tfms,Pipeline): self.tfms = tfms\n",
    "        else:\n",
    "            self.tfms = Pipeline(tfms, as_item=as_item)\n",
    "            if do_setup: self.setup()\n",
    "        \n",
    "    def __getitem__(self, i): return self.get(i)\n",
    "    def get(self, i, filt=None):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        if is_iter(i): return L(self._get(it, filt=filt) for it in its)\n",
    "        return self._get(its, filt=filt)\n",
    "        \n",
    "    def _get(self, it, filt=None): return self.tfms(it, filt=filt)\n",
    "    \n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tfms, do_setup=False)\n",
    "    def decode_at(self, idx, filt=None): return self.decode(self.get(idx,filt=filt), filt=filt)\n",
    "    def show_at(self, idx, filt=None, **kwargs): return self.show(self.get(idx,filt=filt), filt=filt, **kwargs)\n",
    "    \n",
    "    # Standard dunder magics\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms.fs}\"\n",
    "    \n",
    "    # Delegating to `self.tfms`\n",
    "    def show(self, o, **kwargs): self.tfms.show(o, **kwargs)\n",
    "    def setup(self): self.tfms.setup(self)\n",
    "    def decode(self, x, **kwargs): return self.tfms.decode(x, **kwargs)\n",
    "    def __call__(self, x, **kwargs): return self.tfms.__call__(x, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(TfmdList,\n",
    "         setup=\"Transform setup with self\",\n",
    "         decode=\"From `Pipeline\",\n",
    "         show=\"From `Pipeline\",\n",
    "         decode_at=\"Decoded item at `idx`\",\n",
    "         show_at=\"Show item at `idx`\",\n",
    "         subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` can either be a `Pipeline` or a list of transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#3) [1.0,2.0,3.0]\n",
       "tfms - [True ({'object': 'neg'}, {'object': 'neg'}), True ({'object': 'decodes'}, {'object': 'encodes'})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = TfmdList([1.,2.,3.], [neg_tfm, int_tfm])\n",
    "t = tl[1]\n",
    "test_eq_type(t, Int(-2))\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq_type(tl.decode(t), Float(2.0))\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1,-3])\n",
    "test_eq(map(type, p2), (Int,Int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def __init__(self, subset_idx=None): self.subset_idx = subset_idx\n",
    "    def encodes(self, o)->int: return self.o2i[o]\n",
    "    def decodes(self, o)->Str: return self.vocab[o]\n",
    "    def setup(self, items): \n",
    "        if self.subset_idx is not None: items = items.subset(self.subset_idx)\n",
    "        self.vocab,self.o2i = uniqueify(L(items), sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o)->Str: return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "# Check that tfms are sorted by `order`\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - [True ({}, {'object': '_lbl'}), True ({'object': 'decodes'}, {'object': 'encodes'})]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(tl, (1,0,0,0,1))\n",
    "t = L(tl)\n",
    "test_eq(t, [1,0,0,0,1])\n",
    "test_eq(tl[-1], 1)\n",
    "test_eq(tl[0,1], (1,0))\n",
    "test_eq([tl.decode(o) for o in t], ('dog','cat','cat','cat','dog'))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class B(Transform):\n",
    "    def __init__(self):   self.a = 2\n",
    "    def encodes(self, x): return x+self.a\n",
    "    def decodes(self, x): return x-self.a\n",
    "    def setup(self, items): self.a = tensor(items).float().mean().item()\n",
    "\n",
    "tl1 = TfmdList([1,2,3,4], B())\n",
    "test_eq(tl1.tfms[0].a, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "tl1 = TfmdList([1.,2.,3.,4.], [neg_tfm, A(), add1])\n",
    "test_eq(tl1[2], -3)\n",
    "test_eq(tl1.get(2, filt=1), -2)\n",
    "test_eq(tl1.get(2, filt=0), -3)\n",
    "test_eq(tl1.get([2,2], filt=1), [-2,-2])\n",
    "for t in [None, 0, 1]: test_eq(tl1.decode(tl1.get(1, filt=t), filt=t), 2)\n",
    "for t in [None, 0, 1]: test_eq(tl1.decode_at(1, filt=t), 2)\n",
    "for t in [None, 0, 1]: test_stdout(lambda: tl1.show_at(1, filt=t), \"-2.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.get</code>\" class=\"doc_header\"><code>TfmdList.get</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.get</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_at</code>\" class=\"doc_header\"><code>TfmdList.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_at</code>(**`idx`**, **`filt`**=*`None`*)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),tl.decode(tl[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: tl.show_at(1), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.subset</code>\" class=\"doc_header\"><code>TfmdList.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.subset</code>(**`idxs`**)\n",
       "\n",
       "New [`TfmdList`](/pipeline.html#TfmdList) that only includes items at `idxs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDS -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` is a list of objects that can be:\n",
    "- one transform\n",
    "- a list of transforms\n",
    "- a `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdDS(TfmdList):\n",
    "    def __init__(self, items, type_tfms=None, ds_tfms=None, do_setup=True):\n",
    "        self.items = L(items)\n",
    "        self.tls = [TfmdList(items, t, do_setup=do_setup) for t in L(type_tfms)]\n",
    "        self._mk_pipeline(ds_tfms, do_setup=do_setup, as_item=False)\n",
    "\n",
    "    def _get(self, it, filt=None):\n",
    "        o = tuple(tl._get(it, filt=filt) for tl in self.tls)\n",
    "        return self.tfms(o, filt=filt)\n",
    "    \n",
    "    def decode(self, o, filt=None):\n",
    "        o = self.tfms.decode(o, filt=filt)\n",
    "        return tuple(it.decode(o_, filt=filt) for o_,it in zip(o,self.tls))\n",
    "\n",
    "    def show(self, o, ctx=None, filt=None, **kwargs):\n",
    "#         res = self.tfms.show(o, ctx=None, filt=None, **kwargs)\n",
    "#         if res: return\n",
    "#         set_trace()\n",
    "        o = super().decode(o, filt=filt, **kwargs)\n",
    "        for o_,it in zip(o,self.tls): ctx = it.show(o_, ctx=ctx, filt=filt, **kwargs)\n",
    "        return ctx\n",
    "    \n",
    "    def setup(self): self.tfms.setup(self)\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tls, self.tfms, do_setup=False)\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: tls - {self.tls}\\nds tfms - {self.tfms}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "add_docs(TfmdDS,\n",
    "         \"A `Dataset` created from raw `items` by calling each element of `tfms` on them\",\n",
    "         get=\"Call all `tfms` on `items[i]` then all `tuple_tfms` on the result\",\n",
    "         decode=\"Compose `decode` of all `tuple_tfms` then all `tfms` on `i`\",\n",
    "         show=\"Show item `o` in `ctx`\",\n",
    "         subset=\"New `TfmdDS` that only includes items at `idxs`\",\n",
    "         setup=\"Go through the transforms in order and call their potential setup on `items`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [[neg_tfm,int_tfm]])\n",
    "test_eq(*tds[0], -1)\n",
    "test_eq(tds[0,1,2], [(-1,),(-2,),(-3,)])\n",
    "test_eq(tds.decode_at(0), (1,))\n",
    "test_stdout(lambda:tds.show_at(1), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform):\n",
    "    def encodes(self, o)->float: return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setup(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, 1.1618950366973877),\n",
       " (-2, 0.3872983455657959),\n",
       " (-3, -0.3872983455657959),\n",
       " (-4, -1.1618950366973877)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "nrm = A()\n",
    "tds = TfmdDS(items, [[neg_tfm,int_tfm], [neg_tfm,nrm]])\n",
    "\n",
    "x,y = zip(*tds)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, (-1,-2,-3,-4,))\n",
    "test_eq(nrm.m, -2.5)\n",
    "test_stdout(lambda:tds.show_at(1), '-2')\n",
    "# test_eq(tds.m, tds.type_tfms[1].fs[1].m)\n",
    "# test_eq(tds.s, tds.type_tfms[1].fs[1].s)\n",
    "#Attributes are set to all parents progressively\n",
    "# test_eq(tds.tls[1].m, tds.type_tfms[1].fs[1].m)\n",
    "# test_eq(tds.tls[1].s, tds.type_tfms[1].fs[1].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "class B(Transform):\n",
    "    def encodes(self, x)->int: return x+1\n",
    "    def decodes(self, x)->Int: return x-1\n",
    "add1 = B()\n",
    "add1.filt = 1\n",
    "\n",
    "tds = TfmdDS(items, [neg_tfm, [neg_tfm,int_tfm,add1]])\n",
    "test_eq(tds[1], [-2,-2])\n",
    "test_eq(tds.get(1, filt=1), [-2,-1])\n",
    "test_eq(tds.get(1, filt=0), [-2,-2])\n",
    "test_eq(tds.get([1,1], filt=1), [[-2,-1], [-2,-1]])\n",
    "for t in [None, 0, 1]: test_eq(tds.decode(tds.get(1, filt=t), filt=t), [2,2])\n",
    "for t in [None, 0, 1]: test_eq(tds.decode_at(1, filt=t), [2,2])\n",
    "for t in [None, 0, 1]: test_stdout(lambda: tds.show_at(1, filt=t), \"-2\")\n",
    "\n",
    "ss = tds.subset([1,2])\n",
    "test_eq(ss[0], tds[1])\n",
    "test_eq(ss[1], tds[2])\n",
    "test_eq(len(ss), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add examples to method docs, or move them from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.get</code>\" class=\"doc_header\"><code>TfmdList.get</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.get</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Call all `tfms` on `items[i]` then all `tuple_tfms` on the result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.decode</code>\" class=\"doc_header\"><code>TfmdDS.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.decode</code>(**`o`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `decode` of all `tuple_tfms` then all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_at</code>\" class=\"doc_header\"><code>TfmdList.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_at</code>(**`idx`**, **`filt`**=*`None`*)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.show</code>\" class=\"doc_header\"><code>TfmdDS.show</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.show</code>(**`o`**, **`ctx`**=*`None`*, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item `o` in `ctx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.setup</code>\" class=\"doc_header\"><code>TfmdDS.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.setup</code>()\n",
       "\n",
       "Go through the transforms in order and call their potential setup on `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.subset</code>\" class=\"doc_header\"><code>TfmdDS.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02a_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.subset</code>(**`idxs`**)\n",
       "\n",
       "New [`TfmdDS`](/pipeline.html#TfmdDS) that only includes items at `idxs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 02_transforms.ipynb.\n",
      "Converted 02a_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_vision_augment.ipynb.\n",
      "Converted 09_data_block.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
