{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.transform import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` is created with an `encodes` and potentially `decodes` function. \n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items.\n",
    "- `Tuplify` is a special `Trannsform` that takes a list of list of transforms or a list of `Pipeline`s, then aapplies them to the element it receives to return a tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_func(t, name, *args, **kwargs):\n",
    "    \"Get the `t.name` (potentially partial-ized with `args` and `kwargs`) or `noop` if not defined\"\n",
    "    f = getattr(t, name, noop)\n",
    "    return f if not (args or kwargs) else partial(f, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works for any kind of `t` supporting `getattr`, so a class or a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(get_func(operator, 'neg', 2)(), -2)\n",
    "test_eq(get_func(operator.neg, '__call__')(2), -2)\n",
    "test_eq(get_func(list, 'foobar')([2]), [2])\n",
    "t = get_func(torch, 'zeros', dtype=torch.int64)(5)\n",
    "test_eq(t.dtype, torch.int64)\n",
    "a = [2,1]\n",
    "get_func(list, 'sort')(a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Func -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tranforms, are built with multiple-dispatch: a given function can have several methods depending on the type of the object received. This is done directly with the `multimethod` module and type-annotation in `Transofrm`, but you can also use the following class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Func():\n",
    "    \"Basic wrapper around a `name` with `args` and `kwargs` to call on a given type\"\n",
    "    def __init__(self, name, *args, **kwargs): self.name,self.args,self.kwargs = name,args,kwargs\n",
    "    def __repr__(self): return f'sig: {self.name}({self.args}, {self.kwargs})'\n",
    "    def _get(self, t): return get_func(t, self.name, *self.args, **self.kwargs)\n",
    "    def __call__(self,t): return L(t).mapped(self._get) if is_listy(t) else self._get(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can call the `Func` object on any module name or type, even a list of types. It will return the corresponding function (with a default to `noop` if nothing is found) or list of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(Func('sqrt')(math), math.sqrt)\n",
    "test_eq(Func('sqrt')(torch), torch.sqrt)\n",
    "\n",
    "@patch\n",
    "def powx(x:math, a): return math.pow(x,a)\n",
    "@patch\n",
    "def powx(x:torch, a): return torch.pow(x,a)\n",
    "tst = Func('powx',a=2)([math, torch])\n",
    "test_eq([f.func for f in tst], [math.powx, torch.powx])\n",
    "for t in tst: test_eq(t.keywords, {'a': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _Sig():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return Func(k, *args, **kwargs)\n",
    "        return _inner\n",
    "\n",
    "Sig = _Sig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Sig</code>\" class=\"doc_header\"><code>Sig</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Sig</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Sig, name=\"Sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Sig` is just sugar-syntax to create a `Func` object more easily with the syntax `Sig.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Sig.sqrt()\n",
    "test_eq(f(math), math.sqrt)\n",
    "test_eq(f(torch), torch.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SelfFunc():\n",
    "    \"Search for `name` attribute and call it with `args` and `kwargs` on any object it's passed.\"\n",
    "    def __init__(self, nm, *args, **kwargs): self.nm,self.args,self.kwargs = nm,args,kwargs\n",
    "    def __repr__(self): return f'self: {self.nm}({self.args}, {self.kwargs})'\n",
    "    def __call__(self, o):\n",
    "        if not is_listy(o): return getattr(o,self.nm)(*self.args, **self.kwargs)\n",
    "        else: return [getattr(o_,self.nm)(*self.args, **self.kwargs) for o_ in o]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between `Func` and `SelfFunc` is that `Func` will generate a function when you call it on a type. On the other hand, `SelfFunc` is already a function and each time you call it on an object it looks for the `name` attribute and call it on `args` and `kwargs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = SelfFunc('sqrt')\n",
    "x = torch.tensor([4.])\n",
    "test_eq(tst(x), torch.tensor([2.]))\n",
    "assert isinstance(tst(x), Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class _SelfFunc():\n",
    "    def __getattr__(self,k):\n",
    "        def _inner(*args, **kwargs): return SelfFunc(k, *args, **kwargs)\n",
    "        return _inner\n",
    "    \n",
    "Self = _SelfFunc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Self</code>\" class=\"doc_header\"><code>Self</code><a href=\"https://github.com/fastai/fastai_docs/tree/master/dev/__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Self</code>(**\\*`args`**, **\\*\\*`kwargs`**)\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Self, name=\"Self\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Self` is just syntax sugar to create a `SelfFunc` object more easily with the syntax `Self.name(*args, **kwargs)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Self.sqrt()\n",
    "x = torch.tensor([4.])\n",
    "test_eq(f(x), torch.tensor([2.]))\n",
    "assert isinstance(f(x), Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Int(int):\n",
    "    def show(self, ctx=None, **kwargs): return show_title(str(self), ctx=ctx)\n",
    "class Float(float):\n",
    "    def show(self, ctx=None, **kwargs): return show_title(str(self), ctx=ctx)\n",
    "class Str(str):\n",
    "    def show(self, ctx=None, **kwargs): return show_title(self, ctx=ctx)\n",
    "\n",
    "def to_int  (x)->Int  : return x\n",
    "def to_float(x)->Float: return x\n",
    "def to_none (x)->None : return x\n",
    "def double(x): return x*2\n",
    "def half  (x): return x/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def compose_tfms(x, tfms, func_nm=None, reverse=False, **kwargs):\n",
    "    \"Apply all `func_nm` attribute of `tfms` on `x`, maybe in `reverse` order\"\n",
    "    if reverse: tfms = reversed(tfms)\n",
    "    r = NoneType\n",
    "    for f in tfms:\n",
    "        if func_nm: f = getattr(f,func_nm,noop)\n",
    "        r = anno_ret(f) or r\n",
    "        x = f(x, **kwargs)\n",
    "        if r!=NoneType: x=r(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compose all tfm types with return anno (do casting and ret type inside tfm?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq_type(compose_tfms(1, [to_int]), Int(1))\n",
    "test_eq_type(compose_tfms(1, [to_int,to_float]), Float(1))\n",
    "test_eq_type(compose_tfms(1, [to_int,to_float,double]), Float(2))\n",
    "test_eq_type(compose_tfms(2.0, [to_int,double,half]), Int(2))\n",
    "test_eq_type(compose_tfms(2.0, [to_int,to_none,double,half]), 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(TupleTransform):\n",
    "    def encodes(self, x:float): return x+1\n",
    "    def decodes(self, x): return x-1\n",
    "    \n",
    "tfms = [_AddOne(), TupleTransform(math.sqrt)]\n",
    "t = compose_tfms(3., tfms)\n",
    "test_eq(t, 2.)\n",
    "test_eq(compose_tfms(t, tfms, 'decodes'), 1.)\n",
    "test_eq(compose_tfms(4., tfms, reverse=True), 3.)\n",
    "test_eq(compose_tfms((9,3.), tfms), (3,2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline():\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup with types\"\n",
    "    def __init__(self, funcs=None): \n",
    "        if isinstance(funcs, Pipeline): funcs = funcs.fs\n",
    "        self.fs = []\n",
    "        for i,f in enumerate(L(funcs).sorted(key='order')):\n",
    "            if not isinstance(f,BasicTransform): f = TupleTransform(f)\n",
    "            self.fs.append(f)\n",
    "    \n",
    "    def __repr__(self): return f\"Pipeline: {self.fs}\"\n",
    "    \n",
    "    def setup(self, items=None):\n",
    "        tfms,self.fs = self.fs,[]\n",
    "        for t in tfms:\n",
    "            if t.add_before_setup:     self.fs.append(t)\n",
    "            if hasattr(t, 'setup'):    t.setup(items)\n",
    "            if not t.add_before_setup: self.fs.append(t)\n",
    "                \n",
    "    def __call__(self, o, filt=None): return compose_tfms(o, self.fs, filt=filt)\n",
    "    def decode  (self, i, filt=None): return compose_tfms(i, self.fs, func_nm='decode', reverse=True, filt=filt)\n",
    "    \n",
    "    def show(self, o, ctx=None, filt=None, **kwargs):\n",
    "        for f in reversed(self.fs):\n",
    "            if hasattr(o, 'show'): return o.show(ctx)\n",
    "            o = f.decode(o, filt=filt)\n",
    "        if hasattr(o, 'show'): return o.show(ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `o`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `i`\",\n",
    "         show=\"Show item `o`\",\n",
    "         setup=\"Go through the transforms in order and call their potential setup on `items`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of transforms are often applied in a particular order, and decoded by applying in the reverse order. `Pipeline` provides this functionality, and also ensures during its initialization that each transform get the proper functions according to the type of the previous transform. If any transform provides a type with a return annotation, this type is passed along to the next tranforms (until being overwritten by a new return annotation). Such a type can be useful when transforms filter depending on a given type (usually for data augmentation) or to provide a show method.\n",
    "\n",
    "Here's some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipeline is noop\n",
    "pipe = Pipeline()\n",
    "test_eq(pipe(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntFloatTfm(TupleTransform):\n",
    "    def encodes(self, x)->Int: return x\n",
    "    def decodes(self, x)->Float: return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_tfm=IntFloatTfm()\n",
    "def neg(x): return -x\n",
    "neg_tfm = TupleTransform(neg, neg)\n",
    "    \n",
    "pipe = Pipeline([neg_tfm, int_tfm])\n",
    "start = 2.0\n",
    "t = pipe(start)\n",
    "test_eq(t, -2)\n",
    "test_eq(type(t), Int)\n",
    "test_eq(pipe.decode(t), start)\n",
    "test_stdout(lambda:pipe.show(t), '-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check opposite order\n",
    "pipe = Pipeline([int_tfm,neg_tfm])\n",
    "t = pipe(start)\n",
    "test_eq(t, -2)\n",
    "test_stdout(lambda:pipe.show(t), '2.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddOne(Transform):\n",
    "    def encodes(self, x): return x+1\n",
    "    def decodes(self, x): return x-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- decode predictions\n",
    "- handle batches (always tensors)\n",
    "- pass final type on to dl\n",
    "- wrap with most recent return anno, to avoid eg aug reverting to plain tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\n-2\n-1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-3a5bcab89ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_tfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint_tfm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/fastai_docs/dev/local/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_ne\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/git/fastai_docs/dev/local/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\n-2\n-1"
     ]
    }
   ],
   "source": [
    "#Check filtering is properly applied\n",
    "add1 = _AddOne()\n",
    "add1.filt = 1\n",
    "pipe = Pipeline([neg_tfm, int_tfm, add1])\n",
    "test_eq(pipe(start), -2)\n",
    "test_eq(pipe(start, filt=1), -1)\n",
    "test_eq(pipe(start, filt=0), -2)\n",
    "for t in [None, 0, 1]: test_eq(pipe.decode(pipe(start, filt=t), filt=t), start)\n",
    "for t in [None, 0, 1]: test_stdout(lambda: pipe.show(pipe(start, filt=t), filt=t), \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check type is properly changed at dispatch\n",
    "class _AddOne(Transform):\n",
    "    def encodes(self, x:int)->String: return x+1\n",
    "    def encodes(self, x:float):       return x*2\n",
    "    def decodes(self, x:int):   return x-1\n",
    "    def decodes(self, x:float): return x/2\n",
    "\n",
    "pipe = Pipeline(_AddOne(), t=int)\n",
    "test_eq(pipe.final_t, String)\n",
    "pipe = Pipeline(_AddOne(), t=float)\n",
    "test_eq(pipe.final_t, float)\n",
    "pipe = Pipeline(_AddOne(), t=[int,float])\n",
    "test_eq(pipe.final_t, [String,float])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`o`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `o`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `decode` of all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.new</code>\" class=\"doc_header\"><code>Pipeline.new</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.new</code>(**`t`**=*`None`*)\n",
       "\n",
       "Create a new [`Pipeline`](/data.pipeline.html#Pipeline)with the same `tfms` and a new initial `t`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.setup</code>\" class=\"doc_header\"><code>Pipeline.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.setup</code>(**`items`**=*`None`*)\n",
       "\n",
       "Go through the transforms in order and call their potential setup on `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the setup, the `Pipeline` starts with no transform and adds them one at a time, so that during its setup, each transfrom get the items processed up to its point and not after. Depending on the attribute `add_before_setup`, the transform is added after the setup (default behaivor) so it's not called on the items used for the setup, or before (in which case it's called on the values used for setup)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test is below with TfmdList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmedList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_samples(b, max_rows=10):\n",
    "    if isinstance(b, Tensor): return b[:max_rows]\n",
    "    return zip(*L(get_samples(b_, max_rows) if not isinstance(b,Tensor) else b_[:max_rows] for b_ in b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdList(GetAttr):\n",
    "    \"A `Pipeline` of `tfms` applied to a collection of `items`\"\n",
    "    _xtra = 'decode __call__ show'.split()\n",
    "    \n",
    "    def __init__(self, items, tfms, do_setup=True, parent=None):\n",
    "        self.items,self.parent = L(items),parent\n",
    "        self.default = self.tfms = Pipeline(tfms)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def __getitem__(self, i, filt=None):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        if is_iter(i):\n",
    "            if not is_iter(filt): filt = L(filt for _ in i)\n",
    "            return L(self.tfms(it, filt=f) for it,f in zip(its,filt))\n",
    "        return self.tfms(its, filt=filt)\n",
    "    \n",
    "    def setup(self): self.tfms.setup(self)\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tfms, do_setup=False, parent=self)\n",
    "    def decode_at(self, idx, filt=None): \n",
    "        return self.decode(self.__getitem__(idx,filt=filt), filt=filt)\n",
    "    def show_at(self, idx, filt=None, **kwargs): \n",
    "        return self.show(self.__getitem__(idx,filt=filt), filt=filt, **kwargs)\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfms}\"\n",
    "     \n",
    "    _docs = dict(setup=\"Transform setup with self\",\n",
    "                 decode_at=\"Decoded item at `idx`\",\n",
    "                 show_at=\"Show item at `idx`\",\n",
    "                 subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` can either be a `Pipeline` or a list of transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#3) [1,2,3]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f6816f55c18>, <__main__.floatTfm object at 0x7f6816f55b38>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = TfmdList([1,2,3], [neg_tfm, float_tfm])\n",
    "t = tl[1]\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq(tl.decode(t), 2)\n",
    "test_stdout(lambda: tl.show_at(2), '3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1.,-3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - Pipeline over [<__main__.Transform object at 0x7f6816f587f0>, <__main__._Cat object at 0x7f6816f58588>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _Cat(Transform):\n",
    "    order = 1\n",
    "    def __init__(self, subset_idx=None): self.subset_idx = subset_idx\n",
    "    def encodes(self, o): return self.o2i[o]\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setup(self, items): \n",
    "        if self.subset_idx is not None: items = items.subset(self.subset_idx)\n",
    "        self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "\n",
    "def _lbl(o) -> String: return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq([1,0,0,0,1], tl)\n",
    "test_eq(1, tl[-1])\n",
    "test_eq([1,0], tl[0,1])\n",
    "t = list(tl)\n",
    "test_eq([1,0,0,0,1], t)\n",
    "test_eq(['dog','cat','cat','cat','dog'], map(tl.decode,t))\n",
    "test_stdout(lambda:tl.show_at(0), \"dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcat = _Cat([0,1,2])\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test of add_before_setup\n",
    "class _AddSome(Transform):\n",
    "    def __init__(self):   self.a = 2\n",
    "    def encodes(self, x): return x+self.a\n",
    "    def decodes(self, x): return x-self.a\n",
    "    def setup(self, items): self.a = tensor(items).float().mean().item()\n",
    "        \n",
    "tl1 = TfmdList([1,2,3,4], _AddSome())\n",
    "test_eq(tl1.tfms.fs[0].a, 2.5) #Setup on the raw items, mean is 2.5\n",
    "\n",
    "_AddSome.add_before_setup = True\n",
    "tl1 = TfmdList([1,2,3,4], _AddSome())\n",
    "test_eq(tl1.tfms.fs[0].a, 4.5) #Setup on the tfmed items, mean is 4.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "tl1 = TfmdList([1,2,3,4], [neg_tfm, float_tfm, _FiltAddOne()])\n",
    "test_eq(tl1[2], -3)\n",
    "test_eq(tl1.__getitem__(2, filt=1), -2)\n",
    "test_eq(tl1.__getitem__(2, filt=0), -3)\n",
    "test_eq(tl1.__getitem__([2,2], filt=[0,1]), [-3,-2])\n",
    "for t in [None, 0, 1]: test_eq(tl1.decode(tl1.__getitem__(1, filt=t), filt=t), 2)\n",
    "for t in [None, 0, 1]: test_eq(tl1.decode_at(1, filt=t), 2)\n",
    "for t in [None, 0, 1]: test_stdout(lambda: tl1.show_at(1, filt=t), \"2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.__getitem__</code>\" class=\"doc_header\"><code>TfmdList.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.__getitem__</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_at</code>\" class=\"doc_header\"><code>TfmdList.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_at</code>(**`idx`**, **`filt`**=*`None`*)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),tl.decode(tl[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: tl.show_at(1), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.subset</code>\" class=\"doc_header\"><code>TfmdList.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.subset</code>(**`idxs`**)\n",
       "\n",
       "New [`TfmdList`](/data.pipeline.html#TfmdList) that only includes items at `idxs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDS -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def _maybe_flat(t): return t[0] if len(t) == 1 else tuple(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmdDS(TfmdList):\n",
    "    def __init__(self, items, type_tfms=None, ds_tfms=None, do_setup=True):\n",
    "        if type_tfms is None: type_tfms = [None]\n",
    "        self.items = items\n",
    "        self.tfmd_its = [TfmdList(items, t, do_setup=do_setup, parent=self) for t in type_tfms]\n",
    "        self.__post_init__(items, ds_tfms, do_setup)\n",
    "    \n",
    "    def __post_init__(self, items, ds_tfms, do_setup):\n",
    "        #To avoid dupe code with DataSource\n",
    "        self.type_tfms = [it.tfms for it in self.tfmd_its]\n",
    "        self.ds_tfms = Pipeline(ds_tfms, t=[t_.final_t for t_ in self.type_tfms])\n",
    "        if do_setup: self.setup()\n",
    "        \n",
    "    def __getitem__(self, i, filt=None):\n",
    "        its = _maybe_flat([it.__getitem__(i, filt=filt) for it in self.tfmd_its])\n",
    "        if is_iter(i): \n",
    "            if len(self.tfmd_its) > 1: its = zip(*L(its))\n",
    "            if not is_iter(filt): filt = L(filt for _ in i)\n",
    "            return L(self.ds_tfms(it, filt=f) for it,f in zip(its,filt))\n",
    "        return self.ds_tfms(its, filt=filt)\n",
    "    \n",
    "    def decode(self, o, filt=None):\n",
    "        o = self.ds_tfms.decode(o, filt=filt)\n",
    "        if not is_listy(o): o = [o]\n",
    "        return _maybe_flat([it.decode(o_, filt=filt) for o_,it in zip(o,self.tfmd_its)])\n",
    "    \n",
    "    def decode_batch(self, b, filt=None): return [self.decode(b_, filt=filt) for b_ in get_samples(b)]\n",
    "    \n",
    "    def show(self, o, ctx=None, filt=None, **kwargs):\n",
    "        if self.ds_tfms.t_show is not None: return self.ds_tfms.show(o, ctx=ctx, filt=filt, **kwargs)\n",
    "        o = self.ds_tfms.decode(o, filt=filt)\n",
    "        if not is_listy(o): o = [o]\n",
    "        for o_,it in zip(o,self.tfmd_its): ctx = it.show(o_, ctx=ctx, filt=filt, **kwargs)\n",
    "        return ctx\n",
    "    \n",
    "    def setup(self): self.ds_tfms.setup(self)\n",
    "        \n",
    "    def subset(self, idxs): \n",
    "        return self.__class__(self.items[idxs], self.type_tfms, self.ds_tfms, do_setup=False)\n",
    "    \n",
    "    def __repr__(self): \n",
    "        return f\"{self.__class__.__name__}: {self.items}\\ntype tfms - {self.type_tfms}\\nds tfms - {self.ds_tfms}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "add_docs(TfmdDS,\n",
    "         \"A `Dataset` created from raw `items` by calling each element of `tfms` on them\",\n",
    "         __getitem__=\"Call all `tfms` on `items[i]` then all `tuple_tfms` on the result\",\n",
    "         decode=\"Compose `decode` of all `tuple_tfms` then all `tfms` on `i`\",\n",
    "         decode_batch=\"`decode` all sample in a the batch `b`\",\n",
    "         show=\"Show item `o` in `ctx`\",\n",
    "         setup=\"Go through the transforms in order and call their potential setup on `items`\",\n",
    "         subset=\"New `TfmdDS` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tfms` is a list of objects that can be:\n",
    "- one transform\n",
    "- a list of transforms\n",
    "- a `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export \n",
    "def setattr_parent(o, k, v):\n",
    "    if getattr(o, 'parent', False): setattr_parent(o.parent, k, v)\n",
    "    if getattr(o, 'dsrc', False): setattr_parent(o.dsrc, k, v)\n",
    "    setattr(o, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TNorm(Transform):\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def setup(self, items):\n",
    "        its = tensor(items).float()\n",
    "        self.m,self.s = its.mean(),its.std()\n",
    "        setattr_parent(items, 'm', self.m)\n",
    "        setattr_parent(items, 's', self.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "#If you pass only a list with one list of tfms/Pipeline, TfmdDS behaves like TfmOver\n",
    "tds = TfmdDS(items, [neg_tfm])\n",
    "test_eq(tds[0], -1)\n",
    "test_eq(tds[[0,1,2]], [-1,-2,-3])\n",
    "test_eq(tds.decode_at(0), 1)\n",
    "test_stdout(lambda:tds.show_at(1), '2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [neg_tfm, [neg_tfm,_TNorm()]])\n",
    "x,y = zip(*tds)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, [-1,-2,-3,-4])\n",
    "test_stdout(lambda:tds.show_at(1), '2\\ntensor(2.)')\n",
    "test_eq(tds.m, tds.type_tfms[1].fs[1].m)\n",
    "test_eq(tds.s, tds.type_tfms[1].fs[1].s)\n",
    "#Attributes are set to all parents progressively\n",
    "test_eq(tds.tfmd_its[1].m, tds.type_tfms[1].fs[1].m)\n",
    "test_eq(tds.tfmd_its[1].s, tds.type_tfms[1].fs[1].s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test if show at the tuple level interrupts decoding\n",
    "class DoubleString():\n",
    "    @staticmethod\n",
    "    def show(o, ctx=None, **kwargs): print(o[0],o[1])\n",
    "\n",
    "class _DummyTfm(Transform):\n",
    "    def encodes(self, x,y)->DoubleString: return [x,y]\n",
    "\n",
    "items = [1,2,3,4]\n",
    "tds = TfmdDS(items, [neg_tfm, neg_tfm], _DummyTfm())\n",
    "test_stdout(lambda: tds.show_at(0), \"-1 -1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check filtering is properly applied\n",
    "tds = TfmdDS(items, [neg_tfm, [neg_tfm,_FiltAddOne()]])\n",
    "test_eq(tds[1], [-2,-2])\n",
    "test_eq(tds.__getitem__(1, filt=1), [-2,-1])\n",
    "test_eq(tds.__getitem__(1, filt=0), [-2,-2])\n",
    "test_eq(tds.__getitem__([1,1], filt=[0,1]), [[-2,-2], [-2,-1]])\n",
    "for t in [None, 0, 1]: test_eq(tds.decode(tds.__getitem__(1, filt=t), filt=t), [2,2])\n",
    "for t in [None, 0, 1]: test_eq(tds.decode_at(1, filt=t), [2,2])\n",
    "for t in [None, 0, 1]: test_stdout(lambda: tds.show_at(1, filt=t), \"2\\n2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [(#2) [-2,-2],(#2) [-2,-1]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tds.__getitem__([1,1], filt=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.__getitem__</code>\" class=\"doc_header\"><code>TfmdDS.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.__getitem__</code>(**`i`**, **`filt`**=*`None`*)\n",
       "\n",
       "Call all `tfms` on `items[i]` then all `tuple_tfms` on the result"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.decode</code>\" class=\"doc_header\"><code>TfmdDS.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.decode</code>(**`o`**, **`filt`**=*`None`*)\n",
       "\n",
       "Compose `decode` of all `tuple_tfms` then all `tfms` on `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.decode_at</code>\" class=\"doc_header\"><code>TfmdList.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.decode_at</code>(**`idx`**, **`filt`**=*`None`*)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.show</code>\" class=\"doc_header\"><code>TfmdDS.show</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.show</code>(**`o`**, **`ctx`**=*`None`*, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item `o` in `ctx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.setup</code>\" class=\"doc_header\"><code>TfmdDS.setup</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.setup</code>()\n",
       "\n",
       "Go through the transforms in order and call their potential setup on `items`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdDS.subset</code>\" class=\"doc_header\"><code>TfmdDS.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdDS--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDS.subset</code>(**`idxs`**)\n",
       "\n",
       "New [`TfmdDS`](/data.pipeline.html#TfmdDS) that only includes items at `idxs`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDS.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial-meta.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 08_vision_augment.ipynb.\n",
      "Converted 09_data_block.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 11_optimizer.ipynb.\n",
      "Converted 12_learner.ipynb.\n",
      "Converted 13_callback_schedule.ipynb.\n",
      "Converted 14_callback_hook.ipynb.\n",
      "Converted 15_callback_progress.ipynb.\n",
      "Converted 16_callback_tracker.ipynb.\n",
      "Converted 17_callback_fp16.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
