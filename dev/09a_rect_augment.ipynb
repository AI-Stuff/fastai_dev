{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp vision.rect_augment\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rectangular computer vision augmentation\n",
    "\n",
    "> Transforms to apply data augmentation to rectangular images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.transform import *\n",
    "from local.data.pipeline import *\n",
    "from local.data.source import *\n",
    "from local.data.core import *\n",
    "from local.vision.core import *\n",
    "from local.vision.augment import *\n",
    "from local.data.external import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SortARSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- resize large images\n",
    "- sort by size (size group of size n=1000//bs\\*bs) and AR\n",
    "- shufflish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(357, 500)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.PETS)\n",
    "items = get_image_files(path/'images')\n",
    "labeller = RegexLabeller(pat = r'/([^/]+)_\\d+.jpg$')\n",
    "split_idx = RandomSplitter()(items)\n",
    "tfms = [PILImage.create, [labeller, Categorize()]]\n",
    "\n",
    "tfms = [[PILImage.create], #, ImageResizer(128), ImageToByteTensor(), ByteToFloatTensor()],\n",
    "        [labeller, Categorize()]]\n",
    "tds = TfmdDS(items, tfms)\n",
    "\n",
    "# pets = DataSource(items, tfms, filts=split_idx, ds_tfms=ds_img_tfms)\n",
    "\n",
    "im = tds[0][0]; im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class SortARSampler(BatchSampler):\n",
    "    def __init__(self, ds, items=None, bs=32, grp_sz=1000, shuffle=False, drop_last=False):\n",
    "        if not items: items=ds.items\n",
    "        self.shapes = [Image.open(it).shape for it in items]\n",
    "        self.sizes = [h*w for h,w in self.shapes]\n",
    "        self.ars = [h/w for h,w in self.shapes]\n",
    "        self.ds,self.grp_sz,self.bs,self.shuffle,self.drop_last = ds,round_multiple(grp_sz,bs),bs,shuffle,drop_last\n",
    "        self.grp_sz = round_multiple(grp_sz,bs)\n",
    "        \n",
    "        # reverse argsort of sizes\n",
    "        idxs = [i for i,o in sorted(enumerate(self.sizes), key=itemgetter(1), reverse=True)]\n",
    "        # create approx equal sized groups no larger than `grp_sz`\n",
    "        grps = [idxs[i:i+self.grp_sz] for i in range(0, len(idxs), self.grp_sz)]\n",
    "        # sort within groups by aspect ratio\n",
    "        self.grps = [sorted(g, key=lambda o:self.ars[o]) for g in grps]\n",
    "\n",
    "    def __iter__(self):\n",
    "        grps = self.grps\n",
    "        if self.shuffle: grps = [shufflish(o) for o in grps]\n",
    "        grps = [g[i:i+self.bs] for g in grps for i in range(0, len(g), self.bs)]\n",
    "        if self.drop_last and len(grps[-1])!=self.bs: del(grps[-1])\n",
    "        # Shuffle all but first (so can have largest first)\n",
    "        if self.shuffle: grps = random.sample(grps[1:], len(grps)-1) + [grps[0]]\n",
    "        return iter(grps)\n",
    "\n",
    "    def __len__(self): return (len(self.ds) if self.drop_last else (len(self.ds)+self.bs-1)) // self.bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = SortARSampler(tds, shuffle=False)\n",
    "test_eq(len(samp), (len(tds)-1)//32+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = iter(samp)\n",
    "first = next(itr)\n",
    "i = 1\n",
    "for last in itr: i += 1\n",
    "test_eq(len(samp), i)\n",
    "first = [tds[i][0] for i in first]\n",
    "last  = [tds[i][0] for i in last]\n",
    "#big images are first, smaller images last\n",
    "assert np.mean([im.n_px for im in last])*5 < np.mean([im.n_px for im in first])\n",
    "#Higher aspect ratios are first\n",
    "assert np.mean([im.aspect for im in last])*2 < np.mean([im.aspect for im in first])\n",
    "#In a batch with similar aspect ratio\n",
    "assert np.std([im.aspect for im in first]) < 0.1\n",
    "assert np.std([im.aspect for im in last]) < 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = SortARSampler(tds, shuffle=True)\n",
    "itr = iter(samp)\n",
    "first = next(itr)\n",
    "for last in itr: pass\n",
    "first = [tds[i][0] for i in first]\n",
    "last  = [tds[i][0] for i in last]\n",
    "#In a batch with similar aspect ratio\n",
    "assert np.std([im.aspect for im in first]) < 0.1\n",
    "assert np.std([im.aspect for im in last]) < 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResizeCollate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = SortARSampler(tds, shuffle=False)\n",
    "b = L(tds[i] for i in next(iter(samp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeCollate(DefaultCollate):\n",
    "    def __init__(self, tfms=None, max_sz=512*512): \n",
    "        super().__init__(tfms)\n",
    "        self.max_sz,self.resize = max_sz, Resize(1, as_item=False)\n",
    "        \n",
    "    def __call__(self, samples):\n",
    "        sz = min(self.max_sz, max(L(o[0].shape[0]*o[0].shape[1] for o in samples)))\n",
    "        ars = L(o[0].aspect for o in samples)\n",
    "        med,sz1 = np.median(ars),math.sqrt(sz)\n",
    "        calc_sz = int(sz1/med+0.5),int(sz1*med+0.5)\n",
    "        return super().__call__(self.resize(o,size=calc_sz) for o in samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_func = ResizeCollate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = collate_func(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([32, 3, 771, 340]), torch.Size([32])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[batch[0].shape, batch[1].shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[local.data.transform.TensorImage, torch.Tensor]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[type(batch[0]), type(batch[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_script.ipynb.\n",
      "Converted 02_transforms.ipynb.\n",
      "Converted 03_pipeline.ipynb.\n",
      "Converted 04_data_external.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 09a_rect_augment.ipynb.\n",
      "Converted 10_data_block.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
