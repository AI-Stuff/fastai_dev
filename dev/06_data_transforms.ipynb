{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.core import *\n",
    "from local.data.load import *\n",
    "from local.data.external import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [/home/ubuntu/.fastai/data/mnist_tiny/train/3,/home/ubuntu/.fastai/data/mnist_tiny/train/7]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [/home/ubuntu/.fastai/data/mnist_tiny/train/3/9932.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/7189.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/8498.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/8888.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/9004.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/7692.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/7556.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/8762.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/9182.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/7666.png...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`, only in `folders`, if specified.\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "         path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "         path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "         path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(items),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(items[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RegexLabeller(pat):\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    pat = re.compile(pat)\n",
    "    def _inner(o, **kwargs):\n",
    "        res = pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{pat}\" in \"{o}\"'\n",
    "        return res.group(1)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp = re.compile(f'{re.escape(os.path.sep)}(\\d){re.escape(os.path.sep)}')\n",
    "f = RegexLabeller(regexp)\n",
    "test_eq(parent_label(items[0]), '3')\n",
    "[f(o) for o in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False):\n",
    "        if is_categorical_dtype(col): items = L(col.cat.categories, use_list=True)\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsrc):\n",
    "        if self.vocab is None and dsrc is not None: self.vocab = CategoryMap(dsrc, add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return TensorCategory(self.vocab.o2i[o])\n",
    "    def decodes(self, o): return Category(self.vocab[o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Category(str, ShowTitle): \n",
    "    _show_args = {'label': 'category'}\n",
    "    create = Categorize\n",
    "    def __init__(self, vocab=None, add_na=False): self.create = Categorize(vocab=vocab, add_na=add_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Category.create()\n",
    "tds = DataSource(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Category.create(add_na=True)\n",
    "tds = DataSource(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "        \n",
    "    def setups(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsrc: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory([self.vocab.o2i  [o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory ([self.vocab[o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    create = MultiCategorize\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], tensor([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot1(x, c):\n",
    "    \"One-hot encode `x` with `c` classes.\"\n",
    "    res = torch.zeros(c, dtype=torch.bool)\n",
    "    res[L(x, use_list=None)] = 1.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order=2\n",
    "    def __init__(self, c=None): self.c = c\n",
    "\n",
    "    def setups(self, dsrc):\n",
    "        if self.c is None: self.c = len(L(getattr(dsrc, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).bool())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([True, False, True]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([True, False, False])])\n",
    "test_eq(tds[3], [tensor([False, False, False])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test with passing the vocab\n",
    "tds = DataSource([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([True, False, False])])\n",
    "test_eq(tds[3], [tensor([False, False, False])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab): self.vocab = vocab\n",
    "    def encodes(self, o): return TensorCategory(tensor(o).bool())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EncodedMultiCategory(MultiCategory):\n",
    "    create = EncodedMultiCategorize\n",
    "    def __init__(self, vocab): self.create = EncodedMultiCategorize(vocab)\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, *args, **kwargs): raise Exception(\"You need to use an instance of the type `EncodedMultiCategory` created with a vocab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([True, False, True]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_c(dbunch):\n",
    "    if getattr(dbunch, 'c', False): return dbunch.c\n",
    "    vocab = getattr(dbunch, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `DataSource`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [/home/ubuntu/.fastai/data/mnist_tiny/train/3/9932.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/7189.png,/home/ubuntu/.fastai/data/mnist_tiny/train/3/8498.png],\n",
       " (#3) [/home/ubuntu/.fastai/data/mnist_tiny/valid/3/7692.png,/home/ubuntu/.fastai/data/mnist_tiny/valid/3/7484.png,/home/ubuntu/.fastai/data/mnist_tiny/valid/3/9157.png])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = DataSource(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABlCAYAAAAms095AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABH1JREFUeJztmz1IZFcUx39n/Cg0iAimMcWKrogRg5126SJkC0HxWxCNSgQFsbW1CApiZFNsFhFJpakU1G1Cigh+pRE/YhBELFYRVDIQkVHvFuatutFEXee88Xl+MAxv3sw7Z378ue96vSPOOYzoEvK7gaeASVbAJCtgkhUwyQqYZAVMsgKBkywiP4nIWxH5S0T+FJFvfO8paH+MiMjnwIZz7lhEcoFfga+dc7/71VPgkuycW3HOHXuH/zyyfGwpeJIBROQHEfkb+AN4C0z62k/QhgsPEYkDioEvge+ccxG/eglkkgGcc6fOud+Az4Bv/ewlsJIvEY+NyQ+HiHwqIlUi8omIxInIV0A18IuvfQVpTBaRdOBn4AvOA7QFfO+c+9HXvoIkOVYJ1HARq5hkBUyyAiZZgXjlekG+y8pNJyzJCphkBUyyAiZZAZOsgElWwCQrYJIVMMkKxLTkcDhMOBymtLSU0tJSRORWj6amJhYWFlhYWPD7KwAxLjkoaC/a36rY0tISALW1tQCsrKwAkJSUBIDI9csEx8fn2y1OTk5ITk4GoLW1FYC+vr779nxbbO3CT7RX4W7F69evATg6OrpyXF9fD0BCQsK1n9va2gJgfHyc3t5eAAYHBwHIz88HoKGhITpN/weWZAVickxeXFwEYH5+HoC2trY7F5qbmwOguLgYgNTUVAC2t7cB3o/ZD4iNyX4Sk2NyXl4eAAUFBff6/NnZGTU1NVdea2lpAaKS4P/FkqxATCbZmw/flXA4DEBXVxebm5sAVFVVAdDZ2fkwzd0DS7ICMTm7uCuHh4cAVFdXA/DmzZv353Z3dwFIT0+PRunL2OzCTwKRZG8+XVRU9K9zXV1dADQ3NwOQk5MTjRbAkuwvgUiyx8jICHC+ijc1NQXA2toaAGlpaQDMzs4CkJ2d/dDlb0xyoCRf5uzsDICBgQEAenp6ADg4OACgv78fgI6OjocqacOFnwQ2yR8yPT0NXEzzQqHzfHk3zaysj/7tjiXZT55Mkj0mJ89/nPrixQsAcnNzAVhdXf3YS1uS/eTJJdmbdZSVlQEXyV5fXwfg2bNn9720JdlPnpzkUChEKBSioqKCiooKIpEIkUiEiYkJJiYmolMzKlc1rhCTi/YaZGRkAODdkzY2NqJWy5KswJNLsrdhxvu3lLflKzMzM2o1LckKPOokn56eArC8vHzlubKykvj467/a2NgYADs7OwA8f/4cgPb29qj1aUlW4FEneX9/H4DCwsIrrw8PDzM6OgpASkoKADMzMwC8fPnyynvr6uoAiIuLi1qflmQFHvXahde7t7W2u7sbgL29vffba72x2ZtVeMfeNq5Xr14BkJiY+LHt2NqFnzzqJH+It8llaGiI4eFh4GLGUV5eDkBjYyMAJSUlD13ekuwngUqyz1iS/cQkK2CSFTDJCphkBbTXLm68AwcZS7ICJlkBk6yASVbAJCtgkhUwyQqYZAVMsgImWQGTrIBJVsAkK2CSFTDJCphkBUyyAiZZAZOsgElWwCQrYJIVMMkKvANmhUS8mVNiSQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Cuda(Transform):\n",
    "    \"Move batch to `device` (defaults to `default_device()`)\"\n",
    "    def __init__(self,device=None):\n",
    "        self.device=default_device() if device is None else device\n",
    "        super().__init__(split_idx=None, as_item=False)\n",
    "    def encodes(self, b): return to_device(b, self.device)\n",
    "    def decodes(self, b): return to_cpu(b)\n",
    "\n",
    "    _docs=dict(encodes=\"Move batch to `device`\", decodes=\"Return batch to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cuda.encodes\" class=\"doc_header\"><code>Cuda.encodes</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.encodes</code>()\n",
       "\n",
       "Move batch to [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.encodes, name='Cuda.encodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, like all `Transform`s, `encodes` is called by `tfm()` and `decodes` is called by `tfm.decode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = Cuda()\n",
    "t = tfm((tensor(1),))\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.cuda.LongTensor' if default_device().type=='cuda' else 'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cuda.decodes\" class=\"doc_header\"><code>Cuda.decodes</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L9\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.decodes</code>()\n",
       "\n",
       "Return batch to CPU"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.decodes, name='Cuda.decodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tfm.decode(t)\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): \n",
    "    def encodes(self, x): return x \n",
    "    def decodes(self, x): return Int(x) \n",
    "    \n",
    "start = torch.arange(0,50)\n",
    "tds = DataSource(start, [A()])\n",
    "tdl = TfmdDL(tds, after_batch=Cuda, bs=4)\n",
    "test_eq(tdl.device, default_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ByteToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ByteToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 20 #Need to run after CUDA if on the GPU\n",
    "    def __init__(self, div=True, div_mask=False, split_idx=None, as_item=True):\n",
    "        super().__init__(split_idx=split_idx,as_item=as_item)\n",
    "        self.div,self.div_mask = div,div_mask\n",
    "\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(255.) if self.div else o.float()\n",
    "    def encodes(self, o:TensorMask ): return o.div_(255.).long() if self.div_mask else o.long()\n",
    "    def decodes(self, o:TensorImage): return o.clamp(0., 1.) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = ByteToFloatTensor(as_item=False)\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    order=99\n",
    "    def __init__(self, mean, std, dim=1, ndim=4, cuda=True):\n",
    "        self.mean,self.std = broadcast_vec(dim, ndim, mean, std, cuda=cuda)\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [Cuda(), ByteToFloatTensor(), Normalize(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.after_batch.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.FloatTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.mean()/255.<1\n",
    "assert 0<xd.std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from local.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y), figsize=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = torch.add(x,0),torch.add(y,0) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(4,4)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the above check a proper test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_utils.ipynb.\n",
      "Converted 01b_dispatch.ipynb.\n",
      "Converted 01c_transform.ipynb.\n",
      "Converted 02_script.ipynb.\n",
      "Converted 03_torch_core.ipynb.\n",
      "Converted 03a_layers.ipynb.\n",
      "Converted 04_dataloader.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_transforms.ipynb.\n",
      "Converted 07_data_block.ipynb.\n",
      "Converted 08_vision_core.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 10_pets_tutorial.ipynb.\n",
      "Converted 11_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 14a_callback_data.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 15a_vision_models_unet.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 21_vision_learner.ipynb.\n",
      "Converted 22_tutorial_imagenette.ipynb.\n",
      "Converted 23_tutorial_transfer_learning.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_text_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 37_text_learner.ipynb.\n",
      "Converted 38_tutorial_ulmfit.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 42_tabular_rapids.ipynb.\n",
      "Converted 50_data_block_examples.ipynb.\n",
      "Converted 60_medical_imaging.ipynb.\n",
      "Converted 65_medical_text.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_notebook_test.ipynb.\n",
      "Converted 95_index.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted 97_utils_test.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
