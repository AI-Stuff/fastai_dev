{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.test import *\n",
    "from local.basics import *\n",
    "from local.callback.progress import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp callback.wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb\n",
    "\n",
    "> Integration with [wandb](https://www.wandb.com/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import wandb\n",
    "from local.callback.tracker import TrackerCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WandbCallback(TrackerCallback):\n",
    "    \"Saves model topology, losses & metrics\"\n",
    "    # Record if watch has been called previously (even in another instance)\n",
    "    _watch_called = False\n",
    "\n",
    "    def __init__(self, log=\"gradients\", save_model=True, monitor='valid_loss', comp=None, log_preds=True,\n",
    "                 valid_dl=None, n_preds=36, seed=12345):\n",
    "        # Check if wandb.init has been called\n",
    "        if wandb.run is None:\n",
    "            raise ValueError(\n",
    "                'You must call wandb.init() before WandbCallback()')\n",
    "            \n",
    "        super().__init__(monitor=monitor, comp=comp)\n",
    "        store_attr(self, 'save_model,log,log_preds,valid_dl,n_preds,seed')\n",
    "        self.model_path = Path(wandb.run.dir)/'bestmodel.pth'\n",
    "        self.best = None\n",
    "\n",
    "    def begin_fit(self):\n",
    "        \"Call watch method to log model topology, gradients & weights\"\n",
    "        super().begin_fit()\n",
    "        if not WandbCallback._watch_called:\n",
    "            WandbCallback._watch_called = True\n",
    "            # Logs model topology and optionally gradients and weights\n",
    "            wandb.watch(self.learn.model, log=self.log)\n",
    "            \n",
    "        if self.log_preds and not self.valid_dl:\n",
    "            wandbRandom = random.Random(self.seed)  # For repeatability\n",
    "            self.n_preds = min(self.n_preds, len(self.dbunch.valid_ds))\n",
    "            idxs = wandbRandom.sample(range(len(self.dbunch.valid_ds)), self.n_preds)\n",
    "            \n",
    "            items = [self.dbunch.valid_ds.items[i] for i in idxs]\n",
    "            test_tls = [tl._new(items, split_idx=1) for tl in self.dbunch.valid_ds.tls]\n",
    "            self.valid_dl = self.dbunch.valid_dl.new(DataSource(tls=test_tls), bs=self.n_preds)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        \"Log training loss, validation loss and custom metrics & log prediction samples & save model\"\n",
    "        if self.save_model:\n",
    "            super().after_epoch()\n",
    "            if self.new_best:\n",
    "                with self.model_path.open('wb') as model_file:\n",
    "                    self.learn.save(model_file)\n",
    "    \n",
    "        # Log sample predictions\n",
    "        if self.log_preds is not None:\n",
    "            pred_log = []\n",
    "            b = self.valid_dl.one_batch()\n",
    "            self.learn.one_batch(0, b)\n",
    "            preds = getattr(self.loss_func, 'activation', noop)(self.pred)\n",
    "            out = getattr(self.loss_func, 'decodes', noop)(preds)\n",
    "            b_out = b[:self.valid_dl.n_inp] + (tuple(out) if is_listy(out) else (out,))\n",
    "            \n",
    "            x,y,its    = self.valid_dl._pre_show_batch(b, max_n=self.n_preds)\n",
    "            x1,y1,outs = self.valid_dl._pre_show_batch(b_out, max_n=self.n_preds)\n",
    "           \n",
    "            for (x,y),(_,o) in zip(its,outs):\n",
    "                # scalar -> likely to be a category\n",
    "                if isinstance(x, TensorImage): x = x.permute(1,2,0)\n",
    "                if isinstance(o, (Category, MultiCategory)):\n",
    "                    pred_log.append(wandb.Image(x, caption=f'Ground Truth: {y}\\nPrediction: {o}'))\n",
    "                # most vision datasets have a \"show\" function we can use\n",
    "                elif hasattr(x, \"show\"):\n",
    "                    # log input data\n",
    "                    pred_log.append(wandb.Image(x, caption='Input data', grouping=3))\n",
    "                    # log label and prediction\n",
    "                    for im, capt in ((o, \"Prediction\"),\n",
    "                                     (y, \"Ground Truth\")):\n",
    "                        # Resize plot to image resolution\n",
    "                        # from https://stackoverflow.com/a/13714915\n",
    "                        my_dpi = 100\n",
    "                        fig = plt.figure(frameon=False, dpi=my_dpi)\n",
    "                        h, w = x.shape[:2]\n",
    "                        fig.set_size_inches(w / my_dpi, h / my_dpi)\n",
    "                        ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "                        ax.set_axis_off()\n",
    "                        fig.add_axes(ax)\n",
    "                        # Superimpose label or prediction to input image\n",
    "                        ax = x.show(ctx=ax)\n",
    "                        ax = im.show(ctx=ax)\n",
    "                        pred_log.append(wandb.Image(fig, caption=capt))\n",
    "                        plt.close(fig)\n",
    "                # likely to be an image\n",
    "                #elif isinstance(y, (TensorMask, TensorPoint,TensorImage) and (\n",
    "                #    (len(y.shape) == 2) or\n",
    "                #    (len(y.shape) == 3 and y.shape[0] in [1, 3, 4])):\n",
    "                ##    pred_log.extend([\n",
    "                #        wandb.Image(x, caption='Input data', grouping=3),\n",
    "                #        wandb.Image(pred[0], caption='Prediction'),\n",
    "                #        wandb.Image(y, caption='Ground Truth')\n",
    "                #    ])\n",
    "                # we just log input data\n",
    "                else: pred_log.append(wandb.Image(x, caption='Input data'))\n",
    "\n",
    "            wandb.log({\"Prediction Samples\": pred_log}, commit=False)\n",
    "\n",
    "        # Log losses & metrics\n",
    "        # Adapted from fast.ai \"CSVLogger\"\n",
    "        logs = {\n",
    "            name: stat\n",
    "            for name, stat in list(\n",
    "                zip(self.recorder.metric_names, self.recorder.log))\n",
    "        }\n",
    "        wandb.log(logs)\n",
    "\n",
    "    def on_train_end(self, **kwargs):\n",
    "        \"Load the best model.\"\n",
    "        if self.save_model:\n",
    "            # Adapted from fast.ai \"SaveModelCallback\"\n",
    "            if self.model_path.is_file():\n",
    "                with self.model_path.open('rb') as model_file:\n",
    "                    self.learn.load(model_file)\n",
    "                    print(f'Loaded best saved model from {self.model_path}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally logs weights, gradients, sample predictions and best trained model.\n",
    "\n",
    "Args:\n",
    "- log (str): \"gradients\", \"parameters\", \"all\", or None. Losses & metrics are always logged.\n",
    "- save_model (bool): save model at the end of each epoch. It will also load best model at the end of training.\n",
    "- monitor (str): metric to monitor for saving best model. None uses default TrackerCallback monitor value.\n",
    "- mode (str): \"auto\", \"min\" or \"max\" to compare \"monitor\" values and define best model.\n",
    "- input_type (str): \"images\" or None. Used to display sample predictions.\n",
    "- valid_ds (list): data used for sample predictions if input_type is set.\n",
    "- n_preds (int): number of predictions to make if input_type is set and validation_data is None.\n",
    "- seed (int): initialize random generator for sample predictions if input_type is set and validation_data is None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_utils.ipynb.\n",
      "Converted 01b_dispatch.ipynb.\n",
      "Converted 01c_transform.ipynb.\n",
      "Converted 02_script.ipynb.\n",
      "Converted 03_torch_core.ipynb.\n",
      "Converted 03a_layers.ipynb.\n",
      "Converted 04_dataloader.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_transforms.ipynb.\n",
      "Converted 07_data_block.ipynb.\n",
      "Converted 08_vision_core.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 09a_vision_data.ipynb.\n",
      "Converted 10_pets_tutorial.ipynb.\n",
      "Converted 11_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 14a_callback_data.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 15a_vision_models_unet.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision_learner.ipynb.\n",
      "Converted 22_tutorial_imagenette.ipynb.\n",
      "Converted 23_tutorial_transfer_learning.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_text_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 37_text_learner.ipynb.\n",
      "Converted 38_tutorial_ulmfit.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 42_tabular_rapids.ipynb.\n",
      "Converted 50_data_block_examples.ipynb.\n",
      "Converted 60_medical_imaging.ipynb.\n",
      "Converted 65_medical_text.ipynb.\n",
      "Converted 70_callback_wandb.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_notebook_test.ipynb.\n",
      "Converted 95_index.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted 97_utils_test.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import *\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
