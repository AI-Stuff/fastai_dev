{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.layers import *\n",
    "from local.data.all import *\n",
    "from local.notebook.showdoc import show_doc\n",
    "from local.optimizer import *\n",
    "from local.learner import *\n",
    "from local.metrics import *\n",
    "from local.text.core import *\n",
    "from local.text.data import *\n",
    "from local.text.models.core import *\n",
    "from local.text.models.awdlstm import *\n",
    "from local.callback.rnn import *\n",
    "from local.callback.all import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integration test on Wikitext-2\n",
    "\n",
    "> Training a Language Model on WT2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.WIKITEXT_TINY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset comes with all the wrticles concatenated. We split them to be able to shuffle at the beginning of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def istitle(line):\n",
    "    return len(re.findall(r'^ = [^=]* = $', line)) != 0\n",
    "\n",
    "def read_file(filename):\n",
    "    articles = L()\n",
    "    with open(filename, encoding='utf8') as f:\n",
    "        lines = f.readlines()\n",
    "    current_article = ''\n",
    "    for i,line in enumerate(lines):\n",
    "        current_article += line.replace('<unk>', UNK)\n",
    "        if i < len(lines)-2 and lines[i+1] == ' \\n' and istitle(lines[i+2]):\n",
    "            articles.append(current_article.split(' '))\n",
    "            current_article = ''\n",
    "    articles.append(current_article.split(' '))\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we put our list of tokenized texts together in an `LM_Dataset`. It will return tuples of sequences of `seq_len`, with the second sequence between the first one shifted by one on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_txt = read_file(path/'train.txt')\n",
    "val_txt = read_file(path/'valid.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter([p for t in trn_txt for p in t])\n",
    "vocab = make_vocab(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [list(range(len(val_txt), len(val_txt)+len(trn_txt))), list(range(len(val_txt)))]\n",
    "tfm = Numericalize(make_vocab(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(val_txt+trn_txt, [tfm], filts=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 104,72\n",
    "train_dl = LMDataLoader(dsrc.train, bs=bs,   seq_len=sl, after_batch=[Cuda()], shuffle=True)\n",
    "valid_dl = LMDataLoader(dsrc.valid, bs=2*bs, seq_len=sl, after_batch=[Cuda()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n = Zygoballus sexpunctatus = \\n \\n Zygoballus sexpunctatus is a species of jumping spider which occurs in the southeastern United States where it can be found in a variety of grassy habitats . Adult spiders measure between 3 and 4 @.@ 5 mm in length . The cephalothorax and abdomen are bronze to black in color , with reddish brown or yellowish legs . The male has distinctive enlarged chelicerae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>leading up to the airing of \" August \" in another interview , Roberto Orci elaborated that \" xxunk will be one of the things that they will be xxunk struggling with , actually . That was a fun one , because that one was one where you 're finally getting to pay off things you 've been setting up for a year . You finally get to open the toy box</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>would not be returning as Cobra Commander in the sequel . \\n In June 2011 , Dwayne Johnson was cast as Roadblock , D.J. Cotrona and RZA were cast as Flint and Blind Master respectively , while Ã‰lodie Yung was in talks for the role of Jinx . In July 2011 , Adrianne Palicki was confirmed for the lead female role of Lady Jaye , and Ray Stevenson was confirmed to portray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you forever if you do things like this . \" Taylor believed the HNC to be an essential part of the government , because as an American , he believed civilian legitimacy was a must . For him , the HNC was a necessary step in a progression towards an elected civilian legislature , which he regarded as critical for national and military morale . The historian Mark xxunk regarded Taylor 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>promising in many respects , than any the present age has been called upon to encourage . We have not found it to be quite all that we wished in this xxunk it would have been very extraordinary if we had , for our wishes went far beyond reasonable expectations . But we have found it of a nature to present to common xxunk the poetical power with which the author 's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>. \\n \\n = = = Water quality = = = \\n \\n The clear @-@ cutting of forests in the 19th century adversely affected the ecology of the Plunketts Creek watershed and its water quality . xxunk industries on the creek and its tributaries then included a coal mine and tannery ( which are long since departed ) . In the autumn of 1897 , three men working with hides at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Carter , Andrew Goldberg and Elaine xxunk . It is an hour @-@ long special with three musical numbers . Ron MacFarlane , Seth MacFarlane 's father , served as the episode 's narrator . This is also the first \" Road to \" episode to be composed by Ron Jones . \\n Two of the musical numbers , \" All I Really Want for Christmas \" and \" Christmastime is Killing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>xxunk ' notes , low pitched and harsh , occurring at low and high levels of intensity . The narrow @-@ band call is used in situations where the bird signals the presence of a predator and xxunk information about its own location , while the broad @-@ band alarm is used to attract attention , and can initiate mobbing behaviour . These xxunk calls vary between individuals , and laboratory tests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rosebery also began to befriend those politicians such as Lord xxunk who xxunk with her husband , while others such as Lord Granville and Lord Hartington she identified as aloof . She dismissed Lord Spencer with \" I can never look on him as a great motive power , besides he does not mention Archie [ Rosebery ] to me . \" This was the same Lord Spencer who had advised the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>singles chart , and charted for a total of thirteen weeks . \\n Throughout xxunk and Europe , the song peaked outside the top @-@ twenty in most countries . \" Loverboy \" debuted at its peak position of number seven on the Australian Singles Chart , during the week of July 29 , 2001 . The following week , the song began its decline , and experienced a total chart trajectory</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbch = DataBunch(train_dl, valid_dl)\n",
    "dbch.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = awd_lstm_lm_config.copy()\n",
    "config.update({'input_p': 0.6, 'output_p': 0.4, 'weight_p': 0.5, 'embed_p': 0.1, 'hidden_p': 0.2})\n",
    "model = get_language_model(AWD_LSTM, len(vocab), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_func = partial(Adam, wd=0.1, eps=1e-7)\n",
    "cb_funcs = [partial(MixedPrecision, clip=0.1), partial(RNNTrainer, alpha=3, beta=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(model, dbch, loss_func=CrossEntropyLossFlat(), opt_func=opt_func, cb_funcs=cb_funcs, metrics=[accuracy, Perplexity()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>perplexity</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.238688</td>\n",
       "      <td>6.339022</td>\n",
       "      <td>0.135431</td>\n",
       "      <td>566.242310</td>\n",
       "      <td>00:59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(1, 5e-3, moms=(0.8,0.7,0.8), div=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
