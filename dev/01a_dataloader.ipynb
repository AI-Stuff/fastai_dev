{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twoepochs(d): return ' '.join(''.join(o) for _ in range(2) for o in d)\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    _methods = 'collate_fn indexes batches reset wif sampler'.split()\n",
    "    @kwargs(_methods)\n",
    "    def __init__(self, items=None, bs=None, drop_last=False, shuffle=False, indexed=None, **kwargs):\n",
    "        if indexed is None: indexed = items is not None and hasattr(items,'__getitem__')\n",
    "        self.items,self.bs,self.drop_last,self.shuffle,self.indexed = items,bs,drop_last,shuffle,indexed\n",
    "        self.seed,self.rng,self.nw,self.offs = None,random.Random(),1,0\n",
    "        replace_methods(self, kwargs)\n",
    "        try: self.n = len(self.items)\n",
    "        except TypeError: self.n = None\n",
    "        assert not kwargs or not (bs is None and drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.seed is not None: set_seed(self.seed)\n",
    "        self.it = iter(self.items) if self.items else None\n",
    "        idxs = (b for i,b in enumerate(self.sampler()) if i%self.nw==self.offs)\n",
    "        self.reset()\n",
    "        return map(self.collate_fn, self.batches(iter(idxs)))\n",
    "    \n",
    "    def __len__(self):\n",
    "        if self.n is None: raise TypeError\n",
    "        if self.bs is None: return self.n\n",
    "        return self.n//self.bs + (0 if self.drop_last or self.n%self.bs==0 else 1)\n",
    "    \n",
    "    def batches(self, idxs):\n",
    "        res = map(self.item, idxs)\n",
    "        return res if self.bs is None else chunked(res, self.bs, self.drop_last)\n",
    "\n",
    "    def sampler(self):\n",
    "        res = Inf.count if self.indexed else Inf.nones\n",
    "        if self.n is None: return res\n",
    "        res = list(itertools.islice(res, self.n))\n",
    "        return self.rng.sample(res,len(res)) if self.shuffle else res\n",
    "\n",
    "    reset = wif = noop   \n",
    "    def collate_fn(self, b): return (default_collate,default_convert)[self.bs is None](b)\n",
    "    def item(self, s): return next(self.it) if s is None else self.items[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batches` to return some specific finite iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LettersDS(Dataset):\n",
    "    def batches(self, idxs): return (string.ascii_lowercase[i:i+4] for i in range(0,26,4))\n",
    "\n",
    "test_eq(L(LettersDS()), 'abcd,efgh,ijkl,mnop,qrst,uvwx,yz'.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `idxs` to get indexes of samples of this batch, if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#36) [0.06818208925726543,0.8161129101047011,0.3541381449304538,0.23452748508589716,0.04810473341773647,0.7190683538386087,0.6988808013110566,0.48821459727967476,0.9236314892435064,0.5019581553066688...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDS(Dataset):\n",
    "    def batches(self, idxs): return gen(lambda o:random.random(), idxs, lt(0.95))\n",
    "\n",
    "L(RandDS())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#11) [0.2633041256099563,0.21067821178279578,0.8022175455289592,0.8412889993343979,0.19269867281749564,0.8470297360848011,0.2461200121766085,0.5689809894419389,0.5840661089416174,0.3201851958561802...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _batches(self, idxs): return gen(lambda o:random.random(), idxs, lt(0.95))\n",
    "L(Dataset(batches=_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batch` and use the default infinite sampler to get a stream of unknown length (`raise StopIteration` when you want to stop the stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#16) [0.517183380076361,0.6216792367853115,0.795131539496894,0.7222952309094344,0.13578518881114499,0.26933490932579907,0.9113684524149119,0.6457585545124523,0.28624094577564274,0.54287981489844...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDS(Dataset):\n",
    "    def item(self, s):\n",
    "        r = random.random()\n",
    "        return r if r<0.95 else stop()\n",
    "\n",
    "L(RandDS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`items` is assumed to have a `__next__` that returns a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = Dataset(letters)\n",
    "test_eq(ds1, letters)\n",
    "test_eq(len(ds1), 26)\n",
    "\n",
    "test_shuffled(L(Dataset(letters, shuffle=True)), letters)\n",
    "\n",
    "ds1 = Dataset(letters, indexed=False)\n",
    "test_eq(ds1, letters)\n",
    "test_eq(len(ds1), 26)\n",
    "\n",
    "t2 = L(tensor([0,1,2]),tensor([3,4,5]))\n",
    "ds2 = Dataset(t2)\n",
    "test_eq_type(L(ds2), t2)\n",
    "\n",
    "t3 = L(array([0,1,2]),array([3,4,5]))\n",
    "ds3 = Dataset(t3)\n",
    "test_eq_type(L(ds3), t2)\n",
    "\n",
    "ds4 = Dataset(t3, collate_fn=noops)\n",
    "test_eq_type(L(ds4), t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = Dataset(letters,4,drop_last=True)\n",
    "test_eq(twoepochs(ds1), 'abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx')\n",
    "\n",
    "ds1 = Dataset(range(12), bs=4)\n",
    "test_eq_type(L(ds1), L(tensor([0,1,2,3]),tensor([4,5,6,7]),tensor([8,9,10,11])))\n",
    "\n",
    "ds1 = Dataset([str(i) for i in range(11)], bs=4)\n",
    "test_eq_type(L(ds1), L(['0','1','2','3'],['4','5','6','7'],['8','9','10']))\n",
    "\n",
    "it = iter(Dataset(map(noop,range(20)), bs=4))\n",
    "test_eq_type([next(it) for _ in range(3)], [tensor([0,1,2,3]),tensor([4,5,6,7]),tensor([8,9,10,11])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [tensor([0.0831, 0.5347, 0.3338, 0.3114], dtype=torch.float64),tensor([0.7578, 0.6927, 0.1735, 0.5516], dtype=torch.float64),tensor([0.2478, 0.1672, 0.5012, 0.2118], dtype=torch.float64),tensor([0.8800, 0.5981, 0.8254, 0.7693], dtype=torch.float64),tensor([0.2011, 0.0635, 0.7847, 0.5918], dtype=torch.float64),tensor([0.3841, 0.6587, 0.7413, 0.8817], dtype=torch.float64),tensor([0.6461, 0.0513, 0.6019, 0.3876], dtype=torch.float64),tensor([0.4892], dtype=torch.float64),tensor([0.7487, 0.7090, 0.0338, 0.2595], dtype=torch.float64),tensor([0.8138, 0.0474, 0.2306, 0.7621], dtype=torch.float64)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandBatchDS(Dataset):\n",
    "    def item(self, s):\n",
    "        r = random.random()\n",
    "        if r>0.9: raise StopIteration\n",
    "        return r\n",
    "\n",
    "ds = RandBatchDS(bs=4)\n",
    "L(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs,ds.seed = info.num_workers,info.id,info.seed\n",
    "    ds.wif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoader(GetAttr):\n",
    "    _auto_collation,collate_fn,drop_last,dataset_kind = False,noops,False,_DatasetKind.Iterable\n",
    "    @delegates(Dataset.__init__)\n",
    "    def __init__(self, items, num_workers=0, pin_memory=False, timeout=0, tfm=None, **kwargs):\n",
    "        self.default = self.dataset = items if isinstance(items, Dataset) else Dataset(items, **kwargs) \n",
    "        self.pin_memory,self.tfm,self.worker_init_fn,self._index_sampler = pin_memory,tfm or noop,_wif,Inf.count\n",
    "        self.num_workers = 0 if num_workers < 0 else num_workers\n",
    "        self.timeout = 0 if timeout < 0 else timeout\n",
    "        self.dataset.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):  return map(self.tfm, _loaders[self.num_workers==0](self))\n",
    "    def __len__(self): return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 23, 1, 10]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(L(DataLoader(ds))) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[77, 40, 56, 23]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(L(DataLoader(ds, num_workers=4))) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS(list):\n",
    "    def __getitem__(self,i):\n",
    "        time.sleep(random.random()/20)\n",
    "        return super().__getitem__(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.82 ms, sys: 995 µs, total: 2.81 ms\n",
      "Wall time: 633 ms\n",
      "CPU times: user 11.8 ms, sys: 3.9 ms, total: 15.7 ms\n",
      "Wall time: 774 ms\n",
      "CPU times: user 12.9 ms, sys: 9.14 ms, total: 22 ms\n",
      "Wall time: 344 ms\n",
      "CPU times: user 10.6 ms, sys: 23.9 ms, total: 34.5 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "t = SleepyDS(letters)\n",
    "%time test_eq(DataLoader(t, num_workers=0), letters)\n",
    "%time test_eq(DataLoader(t, num_workers=1), letters)\n",
    "%time test_eq(DataLoader(t, num_workers=2), letters)\n",
    "%time test_shuffled(L(DataLoader(t, shuffle=True, num_workers=4)), letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(map(noop,t), num_workers=4)\n",
    "# %time test_eq(dl, sum(zip(letters,letters), ()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 ms, sys: 20.9 ms, total: 42.4 ms\n",
      "Wall time: 47.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'c',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'd',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'e',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'f',\n",
       " 'g',\n",
       " 'g',\n",
       " 'g',\n",
       " 'g',\n",
       " 'h',\n",
       " 'h',\n",
       " 'h',\n",
       " 'h',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'j',\n",
       " 'j',\n",
       " 'j',\n",
       " 'j',\n",
       " 'k',\n",
       " 'k',\n",
       " 'k',\n",
       " 'k',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'l',\n",
       " 'm',\n",
       " 'm',\n",
       " 'm',\n",
       " 'm',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " 'n',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'o',\n",
       " 'p',\n",
       " 'p',\n",
       " 'p',\n",
       " 'p',\n",
       " 'q',\n",
       " 'q',\n",
       " 'q',\n",
       " 'q',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 'r',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 's',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 't',\n",
       " 'u',\n",
       " 'u',\n",
       " 'u',\n",
       " 'u',\n",
       " 'v',\n",
       " 'v',\n",
       " 'v',\n",
       " 'v',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'w',\n",
       " 'x',\n",
       " 'x',\n",
       " 'x',\n",
       " 'x',\n",
       " 'y',\n",
       " 'y',\n",
       " 'y',\n",
       " 'y',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z',\n",
       " 'z']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time list(dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_dataloader.ipynb.\n",
      "Converted 01a_script.ipynb.\n",
      "Converted 02_transforms.ipynb.\n",
      "Converted 03_pipeline.ipynb.\n",
      "Converted 04_data_external.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 09a_rect_augment.ipynb.\n",
      "Converted 10_data_block.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_test_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 60_vision_models_xresnet.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
