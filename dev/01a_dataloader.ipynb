{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll,self.rng = coll,random.Random()\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i):\n",
    "        time.sleep(self.rng.random()/100)\n",
    "        return self.coll[i]\n",
    "\n",
    "def twoepochs(d): return ' '.join(''.join(o) for _ in range(2) for o in d)\n",
    "\n",
    "testds = SleepyDS(string.ascii_lowercase)    \n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set bs,drop_last,sampler after init\n",
    "- collate_fn,kind,sampler,auto_collate from ds\n",
    "  - auto_collate replaced by \n",
    "- figure ds type from attr, not inheritance\n",
    "- transforms and reset\n",
    "- define appropriate init params with subclass params, not bool chks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delegate_attr(k, o, to):\n",
    "    if k.startswith('_') or k==to: raise AttributeError(k)\n",
    "    try: return getattr(getattr(o,to), k)\n",
    "    except AttributeError: raise AttributeError(k) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.wif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def mk_sampler(self, **kwargs):\n",
    "#         if not batch_size or batch_sampler: assert not shuffle and sampler and not drop_last\n",
    "#         if batch_sampler: return batch_sampler\n",
    "#         if sampler: assert not shuffle, \"Can't shuffle a custom sampler\"\n",
    "#         else: sampler = (itertools.count() if self.is_iterable\n",
    "#                          else (SequentialSampler,RandomSampler)[shuffle](self))\n",
    "#         return BatchSampler(sampler, batch_size, drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, items=None, shuffle=False, indexed=False):\n",
    "        self.items,self.shuffle,self.indexed = items,shuffle,indexed\n",
    "        try: self.n = len(self.items)\n",
    "        except TypeError: self.n = None\n",
    "            \n",
    "    def samples(self, n): return iter(n)\n",
    "    def __len__(self):\n",
    "        if self.n is None: raise TypeError\n",
    "        return self.n\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"If self.items has a `len` then we sample that amount, otherwise infinite\"\n",
    "        if self.n is None:\n",
    "            assert not self.shuffle, \"Can't shuffle infinite sampler\"\n",
    "            res = itertools.count() if self.indexed else itertools.cycle([None])\n",
    "        else:\n",
    "            res = [o if self.indexed else None for o in range(self.n)]\n",
    "            if self.shuffle: random.shuffle(res)\n",
    "        return self.samples(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class BatchSampler(Sampler):\n",
    "    def __init__(self, items, bs=4, drop_last=False, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.bs,self.drop_last = bs,drop_last\n",
    "\n",
    "    def samples(self, n): \n",
    "        for o in iterutils.chunked_iter(super().samples(n), self.bs):\n",
    "            if self.drop_last and len(o)!=self.bs: return\n",
    "            yield o\n",
    "\n",
    "    def __len__(self):\n",
    "        n = super().__len__()\n",
    "        return n//self.bs + (0 if self.drop_last or n%self.bs==0 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `Sampler`'s `iter` will return a sequence of either:\n",
    "\n",
    " - Sequences: in which case they're batched and will be collated, or\n",
    " - Items: in which case they're already batches and only need optional conversion.\n",
    "\n",
    "Each item or the sequence (either outer level, or inside sample batch) is either:\n",
    "\n",
    "- `None`: in which case we use `iter`, or\n",
    "- `int`: in which case we call `__getitem__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Sampler(range(7))\n",
    "test_eq(L(s), [None]*7)\n",
    "\n",
    "s = iter(Sampler(map(noop,range(7))))\n",
    "test_eq([next(s) for _ in range(7)], [None]*7)\n",
    "\n",
    "s = iter(Sampler())\n",
    "test_eq([next(s) for _ in range(7)], [None]*7)\n",
    "\n",
    "s = Sampler(range(7), indexed=True)\n",
    "test_eq(L(s), range(7))\n",
    "\n",
    "s = iter(Sampler(indexed=True))\n",
    "test_eq([next(s) for _ in range(7)], range(7))\n",
    "\n",
    "s = Sampler(range(70), shuffle=True, indexed=True)\n",
    "t = L(s)\n",
    "test_ne(t, range(7))\n",
    "test_eq(set(t), set(range(70)))\n",
    "\n",
    "test_fail(lambda: iter(Sampler(shuffle=True, indexed=True)), contains='infinite sampler')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boltons import iterutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class BatchSampler(Sampler):\n",
    "    def __init__(self, items=None, bs=4, drop_last=False, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.bs,self.drop_last = bs,drop_last\n",
    "\n",
    "    def samples(self, n): \n",
    "        for o in iterutils.chunked_iter(super().samples(n), self.bs):\n",
    "            if self.drop_last and len(o)!=self.bs: return\n",
    "            yield o\n",
    "\n",
    "    def __len__(self):\n",
    "        n = super().__len__()\n",
    "        return n//self.bs + (0 if self.drop_last or n%self.bs==0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = BatchSampler(range(7), 2)\n",
    "test_eq(L(s), [[None, None],[None, None],[None, None],[None]])\n",
    "\n",
    "s = BatchSampler(range(7), 2, drop_last=True)\n",
    "test_eq(L(s), [[None, None],[None, None],[None, None]])\n",
    "\n",
    "s = BatchSampler(range(6), 2)\n",
    "test_eq(L(s), [[None, None],[None, None],[None, None]])\n",
    "\n",
    "s = BatchSampler(range(6), 2, drop_last=True)\n",
    "test_eq(L(s), [[None, None],[None, None],[None, None]])\n",
    "\n",
    "s = BatchSampler(range(7),3)\n",
    "test_eq(L(s), [[None,None,None],[None,None,None],[None]])\n",
    "\n",
    "s = BatchSampler(range(7),3, drop_last=True)\n",
    "test_eq(L(s), [[None,None,None],[None,None,None]])\n",
    "\n",
    "s = BatchSampler(range(7), 2, indexed=True)\n",
    "test_eq(L(s), [[0,1],[2,3],[4,5],[6]])\n",
    "\n",
    "s = BatchSampler(range(7), 2, drop_last=True, indexed=True)\n",
    "test_eq(L(s), [[0,1],[2,3],[4,5]])\n",
    "\n",
    "it = iter(BatchSampler(indexed=True))\n",
    "test_eq([next(it) for _ in range(4)],\n",
    "        [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def true(*args, **kwargs):\n",
    "    \"Predicate: always `True`\"\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def try_map(func, seq, cond=true):\n",
    "    \"Maps `func` to `seq`, stopping if not `cond()` or on `StopIteration`\"\n",
    "    for s in seq:\n",
    "        try: r = func(s)\n",
    "        except StopIteration as e: return\n",
    "        if not cond(r): return\n",
    "        yield r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDataset():\n",
    "    _methods = 'collate_fn indexes batches reset wif'\n",
    "    @kwargs(_methods, keep=True)\n",
    "    def __init__(self, items=None, shuffle=False, indexed=False, **kwargs):\n",
    "        self.items,self.shuffle,self.indexed,self.rng = items,shuffle,indexed,random.Random()\n",
    "        for k in [k for k in kwargs if k in self._methods.split()]:\n",
    "            setattr(self, k, types.MethodType(kwargs.pop(k),self))\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.sampler = self.mk_sampler()\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        self.it = iter(self.items) if self.items else None\n",
    "        self.reset()\n",
    "        return map(self.collate_fn, self.batches())\n",
    "    \n",
    "    def __len__(self): return len(self.sampler)\n",
    "    def mk_sampler(self): return Sampler(self.items, shuffle=self.shuffle, indexed=self.indexed)\n",
    "    def collate_fn(self, b): return default_convert(b)\n",
    "    def item(self, s): return next(self.it) if s is None else self.items[s]\n",
    "    def batches(self): yield from try_map(self.batch, self.sampler)\n",
    "    def reset(self): pass    \n",
    "    def wif(self): pass\n",
    "        \n",
    "    def batch(self, s):\n",
    "        if not is_iter(s): return self.item(s)\n",
    "        res = list(try_map(self.item, s))\n",
    "        if not res: raise StopIteration\n",
    "        return res\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, items, bs=None, **kwargs):\n",
    "        return BaseBatchDataset(items, bs=bs, **kwargs) if bs else BaseDataset(items, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class BaseBatchDataset(BaseDataset):\n",
    "    def __init__(self, items=None, bs=4, drop_last=False, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.bs,self.drop_last = bs,drop_last\n",
    "        \n",
    "    def mk_sampler(self): return BatchSampler(self.items, bs, drop_last=self.drop_last,\n",
    "                                              indexed=self.indexed, shuffle=self.shuffle)\n",
    "    def collate_fn(self, b): return default_collate(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batches` to return some specific finite iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LettersDS(BaseDataset):\n",
    "    def batches(self): return (string.ascii_lowercase[i:i+4] for i in range(0,26,4))\n",
    "\n",
    "test_eq(L(LettersDS()), 'abcd,efgh,ijkl,mnop,qrst,uvwx,yz'.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sampler` is also available here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#35) [0.23392194143610756,0.9522970042076294,0.03555128549221254,0.1656440660851256,0.5120815890417281,0.6219770225945803,0.2139617352112173,0.5957143398155679,0.6932954656280069,0.8730808433293014...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDS(BaseDataset):\n",
    "    def batches(self): return try_map(lambda o:random.random(), self.sampler, lambda o:o<=0.99)\n",
    "\n",
    "L(RandDS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batch` and use the default infinite sampler to get a stream of unknown length (`raise StopIteration` when you want to stop the stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [0.385145760363771,0.272934021041472,0.14697780429753948]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDS(BaseDataset):\n",
    "    def batch(self, s):\n",
    "        r = random.random()\n",
    "        if r>0.90: raise StopIteration\n",
    "        return r\n",
    "\n",
    "L(RandDS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`items` is assumed to have a `__next__` that returns a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = BaseDataset(testds)\n",
    "test_eq(''.join(ds1), string.ascii_lowercase)\n",
    "test_eq(len(ds1), 26)\n",
    "\n",
    "t2 = L(tensor([0,1,2]),tensor([3,4,5]))\n",
    "ds2 = BaseDataset(t2)\n",
    "test_eq_type(L(ds2), t2)\n",
    "\n",
    "t3 = L(array([0,1,2]),array([3,4,5]))\n",
    "ds3 = BaseDataset(t3)\n",
    "test_eq_type(L(ds3), t2)\n",
    "\n",
    "ds4 = BaseDataset(t3, collate_fn=noops)\n",
    "test_eq_type(L(ds4), t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: tests\n",
    "#TODO: indexed DS\n",
    "#TODO: remove BaseBatchDataset and make `create_sampler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = BaseBatchDataset(testds,drop_last=True)\n",
    "twoepochs(ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [tensor([0, 1, 2, 3]),tensor([4, 5, 6, 7]),tensor([ 8,  9, 10, 11]),tensor([12, 13, 14, 15]),tensor([16, 17, 18, 19])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = BaseBatchDataset(range(20))\n",
    "L(ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [['0', '1', '2', '3'],['4', '5', '6', '7'],['8', '9', '10', '11'],['12', '13', '14', '15'],['16', '17', '18']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = BaseBatchDataset([str(i) for i in range(19)])\n",
    "L(ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2, 3]),\n",
       " tensor([4, 5, 6, 7]),\n",
       " tensor([ 8,  9, 10, 11]),\n",
       " tensor([12, 13, 14, 15])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(BaseBatchDataset(map(noop,range(20))))\n",
    "[next(it) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [tensor([0.4051], dtype=torch.float64)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandBatchDS(BaseBatchDataset):\n",
    "    def item(self, s):\n",
    "        r = random.random()\n",
    "        if r>0.8: raise StopIteration\n",
    "        return r\n",
    "\n",
    "ds = RandBatchDS()\n",
    "L(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoader:\n",
    "    _auto_collation,collate_fn,drop_last,dataset_kind = False,noops,False,_DatasetKind.Iterable\n",
    "    def __init__(self, dataset, num_workers=0, pin_memory=False, timeout=0, tfm=noop, **kwargs):\n",
    "        self.dataset = dataset if isinstance(dataset, BaseDataset) else BaseDataset.create(dataset, **kwargs) \n",
    "        self.pin_memory,self.tfm,self.worker_init_fn = pin_memory,tfm,_wif\n",
    "        self._index_sampler = self.dataset.sampler\n",
    "        self.num_workers = 0 if num_workers < 0 else num_workers\n",
    "        self.timeout = 0 if timeout < 0 else timeout\n",
    "\n",
    "    def __iter__(self):  return map(self.tfm, _loaders[self.num_workers==0](self))\n",
    "    def __getattr__(self,k): return delegate_attr(k,self,'dataset')\n",
    "    def __len__(self): return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4): print(len(L(DataLoader(ds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "3\n",
      "15\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4): print(len(L(DataLoader(ds, num_workers=4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incomplete below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(''.join(DataLoader(ds1, num_workers=0)), string.ascii_lowercase)\n",
    "test_eq(L(DataLoader(ds2, num_workers=1)), t2)\n",
    "# n workers means n copies of the iter, in some arbitrary order\n",
    "test_eq(L(DataLoader(ds4, num_workers=2)).mapped(list).sorted(), (t3*2).mapped(list).sorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mk_collate_fn(auto_collation): return (default_convert,default_collate)[auto_collation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, items ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 sampler_cls=None, batch_sampler_cls=BatchSampler, collate_fn=default_collate):\n",
    "        super().__init__(items,collate_fn)\n",
    "        self.sampler = batch_sampler\n",
    "        self.rng,self.nw,self.offs = random.Random(),1,0\n",
    "        self._delegate_items(\"get_batches\",\"get_batch\",\"collate\")\n",
    "        if self.sampler: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(items)\n",
    "        self.sampler = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.sampler))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.items[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def wif(self) : self.sampler.sampler = copy(self.sampler.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return DataLoader(testds, num_workers=num_workers, bs=bs, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "t = twoepochs(dl)\n",
    "test_eq(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "t = twoepochs(dl)\n",
    "test_ne(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class _NextFetcher:\n",
    "#     def __init__(self, dataset): self.dataset_iter = iter(dataset)\n",
    "#     def fetch(self, possibly_batched_index): return next(self.dataset_iter)\n",
    "# def create_fetcher(kind, dataset, auto_collation, collate_fn, drop_last): return _NextFetcher(dataset)\n",
    "# _DatasetKind.create_fetcher = create_fetcher\n",
    "\n",
    "#     def _delegate_items(self, *attrs):\n",
    "#         for attr in attrs:\n",
    "#             if hasattr(self.items,attr): setattr(self, attr, getattr(self.items, attr))\n",
    "# \n",
    "#     def batch(self, s):\n",
    "#         if self.done:\n",
    "#             self.done=False\n",
    "#             raise StopIteration\n",
    "#         res = []\n",
    "#         try:\n",
    "#             for _ in range(self.bs): res.append(self.item(s))\n",
    "#         except StopIteration:\n",
    "#             if res==[]: raise StopIteration\n",
    "#             self.done=True\n",
    "#         return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDS(GetAttr):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds):\n",
    "        self.default = self.ds = ds\n",
    "        ds.wrapper = self\n",
    "        self._delegate_ds(\"reset\")\n",
    "\n",
    "    def _delegate_ds(self, attr):\n",
    "        if hasattr(self.ds,attr): setattr(self, attr, getattr(self.ds, attr))\n",
    "            \n",
    "    def reset(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchDS(BaseDS, IterableDataset):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 collate_fn=default_collate, sampler_cls=None, batch_sampler_cls=BatchSampler):\n",
    "        self.default,self.ds,self.samp,self.collate_fn = ds,ds,batch_sampler,collate_fn\n",
    "        self.rng,self.nw,self.offs,self.is_iterable = random.Random(),1,0,True\n",
    "        for o in (\"get_batches\",\"get_batch\",\"collate\"): self._delegate_ds(o)\n",
    "        if self.samp: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(ds)\n",
    "        self.samp = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.samp))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.ds[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def collate(self, idxs): return self.collate_fn(self.get_batches(idxs))\n",
    "    def __len__(self): return len(self.samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.samp.sampler = copy(ds.samp.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll=coll\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i): time.sleep(0.02); return self.coll[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list(string.ascii_lowercase)\n",
    "def twoepochs(d): print(' '.join(''.join(o) for _ in range(2) for o in d))\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dataloader(ds, bs=1, num_workers=0, collate_fn=default_collate, **kwargs):\n",
    "    if not isinstance(ds, IterableDataset): ds = BatchDS(ds, bs, **kwargs)\n",
    "    return DataLoader(ds, num_workers=num_workers, batch_size=None,\n",
    "                      worker_init_fn=_wif, collate_fn=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return dataloader(SleepyDS(string.ascii_lowercase), bs, num_workers, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdxl ubiy znwj ecra spkh mtfq vo gdxl ubiy znwj ecra spkh mtfq vo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 21.1 ms, sys: 46.4 ms, total: 67.5 ms\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4)\n",
    "%time twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 5.71 ms, sys: 0 ns, total: 5.71 ms\n",
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "%time twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, drop_last=True)\n",
    "twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lahp kzyn rgmb sfdt xvco ueij wq svid tckw phjz raeu gfqy mlnb xo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "ds = SleepyDS(string.ascii_lowercase)\n",
    "dl = get_dl(bs=4, num_workers=4, sampler=SequentialSampler(ds))\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypojsdrz hkvwnilc xqmbfgtu ae ypojsdrz hkvwnilc xqmbfgtu ae\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(num_workers=4, batch_sampler=BatchSampler(RandomSampler(ds), 8, False))\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "def rev_collate(s): return default_collate(list(reversed(s)))\n",
    "dl = get_dl(bs=4, num_workers=4, collate_fn=rev_collate)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/ abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/\n"
     ]
    }
   ],
   "source": [
    "class SleepyDS2(SleepyDS):\n",
    "    def get_batch(self, b): return \"\".join([self[j] for j in b]) + '/'\n",
    "\n",
    "dl = dataloader(SleepyDS2(string.ascii_lowercase), bs=4, num_workers=4)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
