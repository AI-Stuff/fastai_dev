{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll,self.rng = coll,random.Random()\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i):\n",
    "        time.sleep(self.rng.random()/100)\n",
    "        return self.coll[i]\n",
    "\n",
    "def twoepochs(d): return ' '.join(''.join(o) for _ in range(2) for o in d)\n",
    "\n",
    "testds = SleepyDS(string.ascii_lowercase)    \n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set bs,drop_last,sampler after init\n",
    "- collate_fn,kind,sampler,auto_collate from ds\n",
    "  - auto_collate replaced by \n",
    "- figure ds type from attr, not inheritance\n",
    "- transforms and reset\n",
    "- define appropriate init params with subclass params, not bool chks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delegate_attr(k, o, to):\n",
    "    if k.startswith('_') or k==to: raise AttributeError(k)\n",
    "    try: return getattr(getattr(o,to), k)\n",
    "    except AttributeError: raise AttributeError(k) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.wif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def mk_sampler(self, **kwargs):\n",
    "#         if not batch_size or batch_sampler: assert not shuffle and sampler and not drop_last\n",
    "#         if batch_sampler: return batch_sampler\n",
    "#         if sampler: assert not shuffle, \"Can't shuffle a custom sampler\"\n",
    "#         else: sampler = (itertools.count() if self.is_iterable\n",
    "#                          else (SequentialSampler,RandomSampler)[shuffle](self))\n",
    "#         return BatchSampler(sampler, batch_size, drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self, items, drop_last=False): self.items,self.drop_last = items,drop_last\n",
    "    def sample(self,b): return None\n",
    "    def __len__(self): return len(self.items) - (1 if self.drop_last else 0)\n",
    "    def __iter__(self):\n",
    "        try: n = range_of(self)\n",
    "        except: n = itertools.count()\n",
    "        return map(self.sample, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDataset():\n",
    "    _methods = 'collate_fn indexes batches reset wif'\n",
    "    @kwargs(_methods, keep=True)\n",
    "    def __init__(self, items=None, **kwargs):\n",
    "        self.items = items\n",
    "        for k in [k for k in kwargs if k in self._methods.split()]:\n",
    "            setattr(self, k, types.MethodType(kwargs.pop(k),self))\n",
    "        self.rng,self.sampler = random.Random(),self.mk_sampler(**kwargs)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        self.reset()\n",
    "        return map(self.collate_fn, self.batches())\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, items, **kwargs): return IndexedDataset(items, **kwargs)\n",
    "    \n",
    "    def __len__(self): return len(self.sampler)\n",
    "    def mk_sampler(self, **kwargs): return Sampler(self.items, **kwargs)\n",
    "    def collate_fn(self, b): return default_convert(b)\n",
    "    def batch(self, s):\n",
    "        if not is_iter(s): return self.item(s)\n",
    "        res = []\n",
    "        try:\n",
    "            for s_ in s: res.append(self.item(s_))\n",
    "        except StopIteration as e:\n",
    "            if res: self.done=True\n",
    "            else: raise e\n",
    "        return res\n",
    "\n",
    "    def item(self, s): return next(self.it)\n",
    "    def wif(self): pass\n",
    "    def reset(self):\n",
    "        self.done=False\n",
    "        if self.items: self.it = iter(self.items)\n",
    "\n",
    "    def batches(self):\n",
    "        try:\n",
    "            for s in self.sampler:\n",
    "                yield self.batch(s)\n",
    "                if self.done: raise StopIteration\n",
    "        except StopIteration:\n",
    "            self.done=False\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batches` to return some specific finite iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LettersDS(BaseDataset):\n",
    "    def batches(self): return (string.ascii_lowercase[i:i+4] for i in range(0,26,4))\n",
    "\n",
    "test_eq(L(LettersDS()), 'abcd,efgh,ijkl,mnop,qrst,uvwx,yz'.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batch` and use the default infinite sampler to get a stream of unknown length (`raise StopIteration` when you want to stop the stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#246) [0.4234170261400705,0.047414301940740144,0.8286873938234129,0.04176993365912274,0.03795914841374515,0.24209004391775046,0.17844070604387674,0.04797346720169737,0.03241544200208779,0.13923316033964017...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDS(BaseDataset):\n",
    "    def batch(self, s):\n",
    "        r = random.random()\n",
    "        if r>0.99: raise StopIteration\n",
    "        return r\n",
    "\n",
    "L(RandDS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`items` is assumed to have a `__next__` that returns a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = BaseDataset(testds)\n",
    "test_eq(''.join(ds1), string.ascii_lowercase)\n",
    "test_eq(len(ds1), 26)\n",
    "\n",
    "t2 = L(tensor([0,1,2]),tensor([3,4,5]))\n",
    "ds2 = BaseDataset(t2)\n",
    "test_eq(list(ds2), t2)\n",
    "\n",
    "t3 = L(array([0,1,2]),array([3,4,5]))\n",
    "ds3 = BaseDataset(t3)\n",
    "test_eq_type(L(ds3), t2)\n",
    "\n",
    "ds4 = BaseDataset(t3, collate_fn=noops)\n",
    "test_eq_type(L(ds4), t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@delegates()\n",
    "class BatchIterSampler(Sampler):\n",
    "    def __init__(self, items, bs, **kwargs):\n",
    "        super().__init__(items, **kwargs)\n",
    "        self.bs=bs\n",
    "    def sample(self,b): return [None]*self.bs\n",
    "    def __len__(self): return (len(self.items)-1)//self.bs + (0 if self.drop_last else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#4) [[None, None],[None, None],[None, None],[None, None]], 4)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = BatchIterSampler([1,2,3,4,5,6,7],2)\n",
    "L(s),len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4) [[None, None],[None, None],[None, None],[None, None]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = BatchIterSampler(map(noop,range(8)),2)\n",
    "it = iter(s)\n",
    "test_fail(lambda:len(s))\n",
    "L(next(it) for i in range(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseBatchDataset(BaseDataset):\n",
    "    def __init__(self, items=None, bs=4, **kwargs): super().__init__(items, bs=bs, **kwargs)\n",
    "    def mk_sampler(self, bs, **kwargs): return BatchIterSampler(self.items, bs, **kwargs)\n",
    "    def collate_fn(self, b): return default_collate(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = BaseBatchDataset(testds,drop_last=True)\n",
    "twoepochs(ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [tensor([0, 1, 2, 3]),tensor([4, 5, 6, 7]),tensor([ 8,  9, 10, 11]),tensor([12, 13, 14, 15]),tensor([16, 17, 18, 19])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = BaseBatchDataset(range(20))\n",
    "L(ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#5) [['0', '1', '2', '3'],['4', '5', '6', '7'],['8', '9', '10', '11'],['12', '13', '14', '15'],['16', '17', '18', '19']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds1 = BaseBatchDataset([str(i) for i in range(20)])\n",
    "L(ds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [tensor([0.2554, 0.4523, 0.5147, 0.5368], dtype=torch.float64),tensor([0.0519], dtype=torch.float64)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandBatchDS(BaseBatchDataset):\n",
    "    def item(self, s):\n",
    "        r = random.random()\n",
    "        if r>0.9: raise StopIteration\n",
    "        return r\n",
    "\n",
    "ds = RandBatchDS()\n",
    "L(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoader:\n",
    "    _auto_collation,collate_fn,drop_last,dataset_kind = False,noops,False,_DatasetKind.Iterable\n",
    "    def __init__(self, dataset, num_workers=0, pin_memory=False, timeout=0, tfm=noop, **kwargs):\n",
    "        self.dataset = dataset if isinstance(dataset, BaseDataset) else BaseDataset.create(dataset, **kwargs) \n",
    "        self.pin_memory,self.tfm,self.worker_init_fn = pin_memory,tfm,_wif\n",
    "        self._index_sampler = self.dataset.sampler\n",
    "        self.num_workers = 0 if num_workers < 0 else num_workers\n",
    "        self.timeout = 0 if timeout < 0 else timeout\n",
    "\n",
    "    def __iter__(self):  return map(self.tfm, _loaders[self.num_workers==0](self))\n",
    "    def __getattr__(self,k): return delegate_attr(k,self,'dataset')\n",
    "    def __len__(self): return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#4) [tensor([0.7587, 0.7087, 0.0985, 0.7834], dtype=torch.float64),tensor([0.7923, 0.6998, 0.4943, 0.6190], dtype=torch.float64),tensor([0.6839, 0.6491, 0.2545, 0.2768], dtype=torch.float64),tensor([0.4087, 0.2419, 0.4599], dtype=torch.float64)]\n",
      "(#3) [tensor([0.1546, 0.8043, 0.7304, 0.1451], dtype=torch.float64),tensor([0.3036, 0.5096, 0.4649, 0.5221], dtype=torch.float64),tensor([0.6010], dtype=torch.float64)]\n",
      "(#1) [tensor([0.6590], dtype=torch.float64)]\n",
      "(#2) [tensor([0.0174, 0.3323, 0.8283, 0.0660], dtype=torch.float64),tensor([0.1942, 0.2704, 0.5890], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4): print(L(DataLoader(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(#12) [tensor([0.3528, 0.1082, 0.4106, 0.7953], dtype=torch.float64),tensor([0.6206, 0.6652, 0.0623, 0.0666], dtype=torch.float64),tensor([0.8420, 0.3056, 0.5540, 0.3665], dtype=torch.float64),tensor([0.2523, 0.7311, 0.6612, 0.6554], dtype=torch.float64),tensor([0.7499, 0.8144], dtype=torch.float64),tensor([0.8189, 0.0061, 0.1110, 0.6277], dtype=torch.float64),tensor([0.3307, 0.7486], dtype=torch.float64),tensor([0.4993, 0.3224, 0.3576, 0.5865], dtype=torch.float64),tensor([0.6720, 0.3018, 0.6998, 0.4193], dtype=torch.float64),tensor([0.4031, 0.7388], dtype=torch.float64)...]\n",
      "(#15) [tensor([0.1093, 0.2307, 0.4622, 0.1012], dtype=torch.float64),tensor([0.7648, 0.0663, 0.3023, 0.0639], dtype=torch.float64),tensor([0.5816, 0.8246, 0.8726, 0.2368], dtype=torch.float64),tensor([0.7233, 0.7650, 0.0440, 0.4029], dtype=torch.float64),tensor([0.7295, 0.3058, 0.8589, 0.6006], dtype=torch.float64),tensor([0.0587, 0.2197, 0.1190, 0.0081], dtype=torch.float64),tensor([0.1781, 0.5315, 0.6847, 0.0188], dtype=torch.float64),tensor([0.2403, 0.5696, 0.2598, 0.3934], dtype=torch.float64),tensor([0.8675, 0.5628, 0.6527, 0.3493], dtype=torch.float64),tensor([0.1782, 0.8326], dtype=torch.float64)...]\n",
      "(#13) [tensor([0.5434, 0.3811, 0.8810, 0.8257], dtype=torch.float64),tensor([0.8578, 0.3696, 0.0290, 0.0915], dtype=torch.float64),tensor([0.4588], dtype=torch.float64),tensor([0.5240, 0.8401, 0.0226, 0.1645], dtype=torch.float64),tensor([0.2582, 0.8316, 0.1538, 0.7540], dtype=torch.float64),tensor([0.6758, 0.2530, 0.1009, 0.7021], dtype=torch.float64),tensor([0.6624, 0.3685, 0.2394, 0.4663], dtype=torch.float64),tensor([0.6522, 0.0341, 0.2598, 0.5610], dtype=torch.float64),tensor([0.3219, 0.7762, 0.2889, 0.7872], dtype=torch.float64),tensor([0.0828, 0.0265, 0.0422], dtype=torch.float64)...]\n",
      "(#3) [tensor([0.1636, 0.8562, 0.4447, 0.8731], dtype=torch.float64),tensor([0.8747], dtype=torch.float64),tensor([0.8433], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4): print(L(DataLoader(ds, num_workers=4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incomplete below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(''.join(DataLoader(ds1, num_workers=0)), string.ascii_lowercase)\n",
    "test_eq(L(DataLoader(ds2, num_workers=1)), t2)\n",
    "# n workers means n copies of the iter, in some arbitrary order\n",
    "test_eq(L(DataLoader(ds4, num_workers=2)).mapped(list).sorted(), (t3*2).mapped(list).sorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mk_collate_fn(auto_collation): return (default_convert,default_collate)[auto_collation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, items ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 sampler_cls=None, batch_sampler_cls=BatchSampler, collate_fn=default_collate):\n",
    "        super().__init__(items,collate_fn)\n",
    "        self.sampler = batch_sampler\n",
    "        self.rng,self.nw,self.offs = random.Random(),1,0\n",
    "        self._delegate_items(\"get_batches\",\"get_batch\",\"collate\")\n",
    "        if self.sampler: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(items)\n",
    "        self.sampler = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.sampler))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.items[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def wif(self) : self.sampler.sampler = copy(self.sampler.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return DataLoader(testds, num_workers=num_workers, bs=bs, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "t = twoepochs(dl)\n",
    "test_eq(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "t = twoepochs(dl)\n",
    "test_ne(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class _NextFetcher:\n",
    "#     def __init__(self, dataset): self.dataset_iter = iter(dataset)\n",
    "#     def fetch(self, possibly_batched_index): return next(self.dataset_iter)\n",
    "# def create_fetcher(kind, dataset, auto_collation, collate_fn, drop_last): return _NextFetcher(dataset)\n",
    "# _DatasetKind.create_fetcher = create_fetcher\n",
    "\n",
    "#     def _delegate_items(self, *attrs):\n",
    "#         for attr in attrs:\n",
    "#             if hasattr(self.items,attr): setattr(self, attr, getattr(self.items, attr))\n",
    "# \n",
    "#     def batch(self, s):\n",
    "#         if self.done:\n",
    "#             self.done=False\n",
    "#             raise StopIteration\n",
    "#         res = []\n",
    "#         try:\n",
    "#             for _ in range(self.bs): res.append(self.item(s))\n",
    "#         except StopIteration:\n",
    "#             if res==[]: raise StopIteration\n",
    "#             self.done=True\n",
    "#         return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDS(GetAttr):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds):\n",
    "        self.default = self.ds = ds\n",
    "        ds.wrapper = self\n",
    "        self._delegate_ds(\"reset\")\n",
    "\n",
    "    def _delegate_ds(self, attr):\n",
    "        if hasattr(self.ds,attr): setattr(self, attr, getattr(self.ds, attr))\n",
    "            \n",
    "    def reset(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchDS(BaseDS, IterableDataset):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 collate_fn=default_collate, sampler_cls=None, batch_sampler_cls=BatchSampler):\n",
    "        self.default,self.ds,self.samp,self.collate_fn = ds,ds,batch_sampler,collate_fn\n",
    "        self.rng,self.nw,self.offs,self.is_iterable = random.Random(),1,0,True\n",
    "        for o in (\"get_batches\",\"get_batch\",\"collate\"): self._delegate_ds(o)\n",
    "        if self.samp: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(ds)\n",
    "        self.samp = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.samp))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.ds[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def collate(self, idxs): return self.collate_fn(self.get_batches(idxs))\n",
    "    def __len__(self): return len(self.samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.samp.sampler = copy(ds.samp.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll=coll\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i): time.sleep(0.02); return self.coll[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list(string.ascii_lowercase)\n",
    "def twoepochs(d): print(' '.join(''.join(o) for _ in range(2) for o in d))\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dataloader(ds, bs=1, num_workers=0, collate_fn=default_collate, **kwargs):\n",
    "    if not isinstance(ds, IterableDataset): ds = BatchDS(ds, bs, **kwargs)\n",
    "    return DataLoader(ds, num_workers=num_workers, batch_size=None,\n",
    "                      worker_init_fn=_wif, collate_fn=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return dataloader(SleepyDS(string.ascii_lowercase), bs, num_workers, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdxl ubiy znwj ecra spkh mtfq vo gdxl ubiy znwj ecra spkh mtfq vo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 21.1 ms, sys: 46.4 ms, total: 67.5 ms\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4)\n",
    "%time twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 5.71 ms, sys: 0 ns, total: 5.71 ms\n",
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "%time twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, drop_last=True)\n",
    "twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lahp kzyn rgmb sfdt xvco ueij wq svid tckw phjz raeu gfqy mlnb xo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "ds = SleepyDS(string.ascii_lowercase)\n",
    "dl = get_dl(bs=4, num_workers=4, sampler=SequentialSampler(ds))\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypojsdrz hkvwnilc xqmbfgtu ae ypojsdrz hkvwnilc xqmbfgtu ae\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(num_workers=4, batch_sampler=BatchSampler(RandomSampler(ds), 8, False))\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "def rev_collate(s): return default_collate(list(reversed(s)))\n",
    "dl = get_dl(bs=4, num_workers=4, collate_fn=rev_collate)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/ abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/\n"
     ]
    }
   ],
   "source": [
    "class SleepyDS2(SleepyDS):\n",
    "    def get_batch(self, b): return \"\".join([self[j] for j in b]) + '/'\n",
    "\n",
    "dl = dataloader(SleepyDS2(string.ascii_lowercase), bs=4, num_workers=4)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
