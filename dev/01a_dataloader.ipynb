{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll,self.rng = coll,random.Random()\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i):\n",
    "        time.sleep(self.rng.random()/100)\n",
    "        return self.coll[i]\n",
    "\n",
    "def twoepochs(d): return ' '.join(''.join(o) for _ in range(2) for o in d)\n",
    "\n",
    "testds = SleepyDS(string.ascii_lowercase)    \n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set bs,drop_last,sampler after init\n",
    "- collate_fn,kind,sampler,auto_collate from ds\n",
    "  - auto_collate replaced by \n",
    "- figure ds type from attr, not inheritance\n",
    "- transforms and reset\n",
    "- define appropriate init params with subclass params, not bool chks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.wif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunked(it, cs, drop_last=False):\n",
    "    if not isinstance(it, Iterator): it = iter(it)\n",
    "    while True:\n",
    "        res = list(itertools.islice(it, cs))\n",
    "        if not res or (len(res)<cs and drop_last): return\n",
    "        yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L.range(10)\n",
    "test_eq(chunked(t,3),      [[0,1,2], [3,4,5], [6,7,8], [9]])\n",
    "test_eq(chunked(t,3,True), [[0,1,2], [3,4,5], [6,7,8],    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDataset():\n",
    "    _methods = 'collate_fn indexes batches reset wif'\n",
    "    @kwargs(_methods, keep=True)\n",
    "    def __init__(self, items=None, bs=None, drop_last=False, shuffle=False, indexed=False, sampler=None, **kwargs):\n",
    "        self.items,self.bs,self.drop_last,self.shuffle = items,bs,drop_last,shuffle\n",
    "        self.indexed,self.sampler,self.rng = indexed,sampler,random.Random()\n",
    "        try: self.n = len(self.items)\n",
    "        except TypeError: self.n = None\n",
    "        for k in copy(kwargs): setattr(self, k, types.MethodType(kwargs.pop(k),self))\n",
    "        assert not kwargs\n",
    "        assert not (bs is None and drop_last)\n",
    "        assert not self.shuffle or (self.n is not None and self.sampler is None)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        self.it = iter(self.items) if self.items else None\n",
    "        self.reset()\n",
    "        return map(self.collate_fn, self.batches())\n",
    "    \n",
    "    def __len__(self):\n",
    "        n = stop(TypeError) if self.n is None else self.n\n",
    "        if self.bs is None: return n\n",
    "        return n//self.bs + (0 if self.drop_last or n%self.bs==0 else 1)\n",
    "    \n",
    "    def batches(self):\n",
    "        res = map(self.item, self.mk_sampler())\n",
    "        return res if self.bs is None else chunked(res, self.bs, self.drop_last)\n",
    "\n",
    "    def mk_sampler(self):\n",
    "        if self.sampler: return self.sampler\n",
    "        res = Inf.count if self.indexed else Inf.nones\n",
    "        if self.n is not None:\n",
    "            res = list(itertools.islice(res, self.n))\n",
    "            if self.shuffle: random.shuffle(res)\n",
    "        return iter(res)\n",
    "\n",
    "    reset = wif = noop   \n",
    "    def collate_fn(self, b): return (default_collate,default_convert)[self.bs is None](b)\n",
    "    def item(self, s): return next(self.it) if s is None else self.items[s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batches` to return some specific finite iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LettersDS(BaseDataset):\n",
    "    def batches(self): return (string.ascii_lowercase[i:i+4] for i in range(0,26,4))\n",
    "\n",
    "test_eq(L(LettersDS()), 'abcd,efgh,ijkl,mnop,qrst,uvwx,yz'.split(','))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mk_sampler` is also available here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [0.20387192762369488,0.3985282381412417,0.18992398700195434,0.9378714396248389,0.18563209824033744,0.4227552895863914,0.3886418127933633,0.5823938265157906,0.10078752761895038,0.526057197290042]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDS(BaseDataset):\n",
    "    def batches(self): return gen(lambda o:random.random(), self.mk_sampler(), lt(0.95))\n",
    "\n",
    "L(RandDS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override `batch` and use the default infinite sampler to get a stream of unknown length (`raise StopIteration` when you want to stop the stream)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#17) [0.8874313343998564,0.19782911066294018,0.6102335054945686,0.5107968334575369,0.5834613827928582,0.01478423856315303,0.020841334904318942,0.35038440472148213,0.2677479971018841,0.9255407362024884...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandDS(BaseDataset):\n",
    "    def item(self, s):\n",
    "        r = random.random()\n",
    "        return r if r<0.95 else stop()\n",
    "\n",
    "L(RandDS())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`items` is assumed to have a `__next__` that returns a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = BaseDataset(testds)\n",
    "test_eq(''.join(ds1), string.ascii_lowercase)\n",
    "test_eq(len(ds1), 26)\n",
    "\n",
    "t2 = L(tensor([0,1,2]),tensor([3,4,5]))\n",
    "ds2 = BaseDataset(t2)\n",
    "test_eq_type(L(ds2), t2)\n",
    "\n",
    "t3 = L(array([0,1,2]),array([3,4,5]))\n",
    "ds3 = BaseDataset(t3)\n",
    "test_eq_type(L(ds3), t2)\n",
    "\n",
    "ds4 = BaseDataset(t3, collate_fn=noops)\n",
    "test_eq_type(L(ds4), t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = BaseDataset(testds,bs=4,drop_last=True)\n",
    "test_eq(twoepochs(ds1), 'abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx')\n",
    "\n",
    "ds1 = BaseDataset(range(12), bs=4)\n",
    "test_eq_type(L(ds1), L(tensor([0,1,2,3]),tensor([4,5,6,7]),tensor([8,9,10,11])))\n",
    "\n",
    "ds1 = BaseDataset([str(i) for i in range(11)], bs=4)\n",
    "test_eq_type(L(ds1), L(['0','1','2','3'],['4','5','6','7'],['8','9','10']))\n",
    "\n",
    "it = iter(BaseDataset(map(noop,range(20)), bs=4))\n",
    "test_eq_type([next(it) for _ in range(3)], [tensor([0,1,2,3]),tensor([4,5,6,7]),tensor([8,9,10,11])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#18) [tensor([0.2928], dtype=torch.float64),tensor([0.1940, 0.2347], dtype=torch.float64),tensor([0.2381, 0.3685, 0.2362, 0.4815], dtype=torch.float64),tensor([0.2945], dtype=torch.float64),tensor([0.5506, 0.5095, 0.8379, 0.2772], dtype=torch.float64),tensor([0.0525, 0.3875, 0.3879, 0.5744], dtype=torch.float64),tensor([0.1093, 0.2447, 0.5660, 0.3921], dtype=torch.float64),tensor([0.5968, 0.5351, 0.1871, 0.3360], dtype=torch.float64),tensor([0.5119, 0.6163, 0.5396, 0.7278], dtype=torch.float64),tensor([0.7152, 0.5996, 0.6750, 0.6917], dtype=torch.float64)...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class RandBatchDS(BaseDataset):\n",
    "    def item(self, s):\n",
    "        r = random.random()\n",
    "        if r>0.9: raise StopIteration\n",
    "        return r\n",
    "\n",
    "ds = RandBatchDS(bs=4)\n",
    "L(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delegate_attr(k, o, to):\n",
    "    if k.startswith('_') or k==to: raise AttributeError(k)\n",
    "    try: return getattr(getattr(o,to), k)\n",
    "    except AttributeError: raise AttributeError(k) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoader:\n",
    "    _auto_collation,collate_fn,drop_last,dataset_kind = False,noops,False,_DatasetKind.Iterable\n",
    "    def __init__(self, dataset, num_workers=0, pin_memory=False, timeout=0, tfm=noop, **kwargs):\n",
    "        self.dataset = dataset if isinstance(dataset, BaseDataset) else BaseDataset(dataset, **kwargs) \n",
    "        self.pin_memory,self.tfm,self.worker_init_fn,self._index_sampler = pin_memory,tfm,_wif,Inf.count\n",
    "        self.num_workers = 0 if num_workers < 0 else num_workers\n",
    "        self.timeout = 0 if timeout < 0 else timeout\n",
    "\n",
    "    def __iter__(self):  return map(self.tfm, _loaders[self.num_workers==0](self))\n",
    "    def __getattr__(self,k): return delegate_attr(k,self,'dataset')\n",
    "    def __len__(self): return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "0\n",
      "17\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4): print(len(L(DataLoader(ds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "17\n",
      "46\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for _ in range(4): print(len(L(DataLoader(ds, num_workers=4))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incomplete below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(''.join(DataLoader(ds1, num_workers=0)), string.ascii_lowercase)\n",
    "test_eq(L(DataLoader(ds2, num_workers=1)), t2)\n",
    "# n workers means n copies of the iter, in some arbitrary order\n",
    "test_eq(L(DataLoader(ds4, num_workers=2)).mapped(list).sorted(), (t3*2).mapped(list).sorted())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mk_collate_fn(auto_collation): return (default_convert,default_collate)[auto_collation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, items ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 sampler_cls=None, batch_sampler_cls=BatchSampler, collate_fn=default_collate):\n",
    "        super().__init__(items,collate_fn)\n",
    "        self.sampler = batch_sampler\n",
    "        self.rng,self.nw,self.offs = random.Random(),1,0\n",
    "        self._delegate_items(\"get_batches\",\"get_batch\",\"collate\")\n",
    "        if self.sampler: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(items)\n",
    "        self.sampler = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.sampler))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.items[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def wif(self) : self.sampler.sampler = copy(self.sampler.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return DataLoader(testds, num_workers=num_workers, bs=bs, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "t = twoepochs(dl)\n",
    "test_eq(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "t = twoepochs(dl)\n",
    "test_ne(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class _NextFetcher:\n",
    "#     def __init__(self, dataset): self.dataset_iter = iter(dataset)\n",
    "#     def fetch(self, possibly_batched_index): return next(self.dataset_iter)\n",
    "# def create_fetcher(kind, dataset, auto_collation, collate_fn, drop_last): return _NextFetcher(dataset)\n",
    "# _DatasetKind.create_fetcher = create_fetcher\n",
    "\n",
    "#     def _delegate_items(self, *attrs):\n",
    "#         for attr in attrs:\n",
    "#             if hasattr(self.items,attr): setattr(self, attr, getattr(self.items, attr))\n",
    "# \n",
    "#     def batch(self, s):\n",
    "#         if self.done:\n",
    "#             self.done=False\n",
    "#             raise StopIteration\n",
    "#         res = []\n",
    "#         try:\n",
    "#             for _ in range(self.bs): res.append(self.item(s))\n",
    "#         except StopIteration:\n",
    "#             if res==[]: raise StopIteration\n",
    "#             self.done=True\n",
    "#         return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDS(GetAttr):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds):\n",
    "        self.default = self.ds = ds\n",
    "        ds.wrapper = self\n",
    "        self._delegate_ds(\"reset\")\n",
    "\n",
    "    def _delegate_ds(self, attr):\n",
    "        if hasattr(self.ds,attr): setattr(self, attr, getattr(self.ds, attr))\n",
    "            \n",
    "    def reset(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchDS(BaseDS, IterableDataset):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 collate_fn=default_collate, sampler_cls=None, batch_sampler_cls=BatchSampler):\n",
    "        self.default,self.ds,self.samp,self.collate_fn = ds,ds,batch_sampler,collate_fn\n",
    "        self.rng,self.nw,self.offs,self.is_iterable = random.Random(),1,0,True\n",
    "        for o in (\"get_batches\",\"get_batch\",\"collate\"): self._delegate_ds(o)\n",
    "        if self.samp: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(ds)\n",
    "        self.samp = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.samp))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.ds[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def collate(self, idxs): return self.collate_fn(self.get_batches(idxs))\n",
    "    def __len__(self): return len(self.samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.samp.sampler = copy(ds.samp.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll=coll\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i): time.sleep(0.02); return self.coll[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list(string.ascii_lowercase)\n",
    "def twoepochs(d): print(' '.join(''.join(o) for _ in range(2) for o in d))\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dataloader(ds, bs=1, num_workers=0, collate_fn=default_collate, **kwargs):\n",
    "    if not isinstance(ds, IterableDataset): ds = BatchDS(ds, bs, **kwargs)\n",
    "    return DataLoader(ds, num_workers=num_workers, batch_size=None,\n",
    "                      worker_init_fn=_wif, collate_fn=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return dataloader(SleepyDS(string.ascii_lowercase), bs, num_workers, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdxl ubiy znwj ecra spkh mtfq vo gdxl ubiy znwj ecra spkh mtfq vo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 21.1 ms, sys: 46.4 ms, total: 67.5 ms\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4)\n",
    "%time twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 5.71 ms, sys: 0 ns, total: 5.71 ms\n",
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "%time twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, drop_last=True)\n",
    "twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lahp kzyn rgmb sfdt xvco ueij wq svid tckw phjz raeu gfqy mlnb xo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "ds = SleepyDS(string.ascii_lowercase)\n",
    "dl = get_dl(bs=4, num_workers=4, sampler=SequentialSampler(ds))\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypojsdrz hkvwnilc xqmbfgtu ae ypojsdrz hkvwnilc xqmbfgtu ae\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(num_workers=4, batch_sampler=BatchSampler(RandomSampler(ds), 8, False))\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "def rev_collate(s): return default_collate(list(reversed(s)))\n",
    "dl = get_dl(bs=4, num_workers=4, collate_fn=rev_collate)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/ abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/\n"
     ]
    }
   ],
   "source": [
    "class SleepyDS2(SleepyDS):\n",
    "    def get_batch(self, b): return \"\".join([self[j] for j in b]) + '/'\n",
    "\n",
    "dl = dataloader(SleepyDS2(string.ascii_lowercase), bs=4, num_workers=4)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
