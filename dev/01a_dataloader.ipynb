{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data.dataloader import _MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter,_DatasetKind\n",
    "_loaders = (_MultiProcessingDataLoaderIter,_SingleProcessDataLoaderIter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll,self.rng = coll,random.Random()\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i):\n",
    "        time.sleep(self.rng.random()/100)\n",
    "        return self.coll[i]\n",
    "\n",
    "def twoepochs(d): return ' '.join(''.join(o) for _ in range(2) for o in d)\n",
    "\n",
    "testds = SleepyDS(string.ascii_lowercase)    \n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class _NextFetcher:\n",
    "#     def __init__(self, dataset): self.dataset_iter = iter(dataset)\n",
    "#     def fetch(self, possibly_batched_index): return next(self.dataset_iter)\n",
    "# def create_fetcher(kind, dataset, auto_collation, collate_fn, drop_last): return _NextFetcher(dataset)\n",
    "# _DatasetKind.create_fetcher = create_fetcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- set bs,drop_last,sampler after init\n",
    "- collate_fn,kind,sampler,auto_collate from ds\n",
    "- figure ds type from attr, not inheritance\n",
    "- transforms\n",
    "- reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delegate_attr(k, o, to):\n",
    "    if k.startswith('_') or k==to: raise AttributeError(k)\n",
    "    try: return getattr(getattr(o,to), k)\n",
    "    except AttributeError: raise AttributeError(k) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.wif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     def _delegate_items(self, *attrs):\n",
    "#         for attr in attrs:\n",
    "#             if hasattr(self.items,attr): setattr(self, attr, getattr(self.items, attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    @kwargs('collate_fn indexes batches reset wif')\n",
    "    def __init__(self, items=None, **kwargs):\n",
    "        if items is not None and hasattr(items,'__dict__'): items.wrapper = self\n",
    "        self.items = items\n",
    "        self.rng,self.sampler = random.Random(),itertools.count()\n",
    "        for k,v in kwargs.items(): setattr(self,k,types.MethodType(v,self))\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        self.reset()\n",
    "        for b in self.batches(self.indexes()):\n",
    "            yield b if isinstance(b,Tensor) else self.collate_fn(b)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, items, **kwargs): return IndexedDataset(items, **kwargs)\n",
    "    \n",
    "    def __getattr__(self,k): return delegate_attr(k,self,'items')\n",
    "    def collate_fn(self, b): return default_collate(b)\n",
    "    def indexes(self): return None\n",
    "    def batches(self, idxs): return self.items\n",
    "    def __len__(self): return len(self.sampler)\n",
    "    def reset(self): pass\n",
    "    def wif(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1 = Dataset(testds)\n",
    "test_eq(''.join(ds1), string.ascii_lowercase)\n",
    "\n",
    "t2 = [tensor([0,1,2]),tensor([3,4,5])]\n",
    "ds2 = Dataset(t2)\n",
    "test_eq(list(ds2), t2)\n",
    "\n",
    "t3 = [[0,1,2],[3,4,5]]\n",
    "ds3 = Dataset(t3)\n",
    "test_eq_type(list(ds3), t2)\n",
    "\n",
    "ds4 = Dataset(t3, collate_fn=noops)\n",
    "test_eq(list(ds4), t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class DataLoader:\n",
    "    _auto_collation,collate_fn,drop_last,dataset_kind = False,noops,False,_DatasetKind.Iterable\n",
    "    def __init__(self, dataset, num_workers=0, pin_memory=False, timeout=0, tfm=noop, **kwargs):\n",
    "        self.dataset = dataset if isinstance(dataset, Dataset) else Dataset.create(dataset, **kwargs) \n",
    "        self.pin_memory,self.tfm,self.worker_init_fn = pin_memory,tfm,_wif\n",
    "        self._index_sampler = self.dataset.sampler\n",
    "        self.num_workers = 0 if num_workers < 0 else num_workers\n",
    "        self.timeout = 0 if timeout < 0 else timeout\n",
    "\n",
    "    def __iter__(self):  return map(self.tfm, _loaders[self.num_workers==0](self))\n",
    "    def __getattr__(self,k): return delegate_attr(k,self,'dataset')\n",
    "    def __len__(self): return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(''.join(DataLoader(ds1, num_workers=0)), string.ascii_lowercase)\n",
    "test_eq(list(DataLoader(ds2, num_workers=1)), t2)\n",
    "# n workers means n copies of the iter, in some arbitrary order\n",
    "test_eq(list(sorted(DataLoader(ds4, num_workers=2))), list(sorted(t3*2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_sampler(dataset):\n",
    "    if not batch_size or batch_sampler: assert not shuffle and sampler and not drop_last\n",
    "    if batch_sampler: return batch_sampler\n",
    "    if sampler: assert not shuffle, \"Can't shuffle a custom sampler\"\n",
    "    else: sampler = (_InfiniteConstantSampler() if dataset.is_iterable\n",
    "                     else (SequentialSampler,RandomSampler)[shuffle](dataset))\n",
    "    return BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "def set_collate_fn(self):\n",
    "    self.collate_fn = return _utils.collate.default_collate if self._auto_collation else _utils.collate.default_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class IndexedDataset(Dataset):\n",
    "    def __init__(self, items ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 sampler_cls=None, batch_sampler_cls=BatchSampler, collate_fn=default_collate):\n",
    "        super().__init__(items,collate_fn)\n",
    "        self.sampler = batch_sampler\n",
    "        self.rng,self.nw,self.offs = random.Random(),1,0\n",
    "        self._delegate_items(\"get_batches\",\"get_batch\",\"collate\")\n",
    "        if self.sampler: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(items)\n",
    "        self.sampler = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.sampler))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.items[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def wif(self) : self.sampler.sampler = copy(self.sampler.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return DataLoader(testds, num_workers=num_workers, bs=bs, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "t = twoepochs(dl)\n",
    "test_eq(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vaqd nyfi meob jgps hwtu rzkc lx vaqd nyfi meob jgps hwtu rzkc lx'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "t = twoepochs(dl)\n",
    "test_ne(t, 'abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz')\n",
    "test_eq(len(set(t)), 27)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BaseDS(GetAttr):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds):\n",
    "        self.default = self.ds = ds\n",
    "        ds.wrapper = self\n",
    "        self._delegate_ds(\"reset\")\n",
    "\n",
    "    def _delegate_ds(self, attr):\n",
    "        if hasattr(self.ds,attr): setattr(self, attr, getattr(self.ds, attr))\n",
    "            \n",
    "    def reset(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class BatchDS(BaseDS, IterableDataset):\n",
    "    _xtra = ['show', 'decode', 'show_at', 'decode_at', 'decode_batch']\n",
    "    def __init__(self, ds ,bs=1, shuffle=False, sampler=None, batch_sampler=None, drop_last=False,\n",
    "                 collate_fn=default_collate, sampler_cls=None, batch_sampler_cls=BatchSampler):\n",
    "        self.default,self.ds,self.samp,self.collate_fn = ds,ds,batch_sampler,collate_fn\n",
    "        self.rng,self.nw,self.offs,self.is_iterable = random.Random(),1,0,True\n",
    "        for o in (\"get_batches\",\"get_batch\",\"collate\"): self._delegate_ds(o)\n",
    "        if self.samp: return\n",
    "        if not sampler: sampler = ifnone(sampler_cls, (SequentialSampler,RandomSampler)[shuffle])(ds)\n",
    "        self.samp = batch_sampler_cls(sampler, bs, drop_last)\n",
    "\n",
    "    def __iter__(self):\n",
    "        torch.manual_seed(self.rng.randint(0,sys.maxsize))\n",
    "        samps = list(enumerate(self.samp))\n",
    "        idxs = (b for i,b in samps if i%self.nw==self.offs)\n",
    "        return self.get_batches(idxs)\n",
    "    \n",
    "    def get_batch(self, b): return [self.ds[j] for j in b]\n",
    "    def get_batches(self, idxs): return map(self.get_batch, idxs)\n",
    "    def collate(self, idxs): return self.collate_fn(self.get_batches(idxs))\n",
    "    def __len__(self): return len(self.samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _wif(worker_id):\n",
    "    info = get_worker_info()\n",
    "    ds = info.dataset\n",
    "    ds.nw,ds.offs = info.num_workers,info.id\n",
    "    ds.samp.sampler = copy(ds.samp.sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepyDS():\n",
    "    def __init__(self,coll): self.coll=coll\n",
    "    def __len__(self): return len(self.coll)\n",
    "    def __getitem__(self,i): time.sleep(0.02); return self.coll[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = list(string.ascii_lowercase)\n",
    "def twoepochs(d): print(' '.join(''.join(o) for _ in range(2) for o in d))\n",
    "bs = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dataloader(ds, bs=1, num_workers=0, collate_fn=default_collate, **kwargs):\n",
    "    if not isinstance(ds, IterableDataset): ds = BatchDS(ds, bs, **kwargs)\n",
    "    return DataLoader(ds, num_workers=num_workers, batch_size=None,\n",
    "                      worker_init_fn=_wif, collate_fn=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dl(bs=1, collate_fn=default_collate, num_workers=0, **kwargs):\n",
    "    return dataloader(SleepyDS(string.ascii_lowercase), bs, num_workers, collate_fn=collate_fn, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gdxl ubiy znwj ecra spkh mtfq vo gdxl ubiy znwj ecra spkh mtfq vo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 21.1 ms, sys: 46.4 ms, total: 67.5 ms\n",
      "Wall time: 396 ms\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4)\n",
    "%time twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n",
      "CPU times: user 5.71 ms, sys: 0 ns, total: 5.71 ms\n",
      "Wall time: 1.05 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0)\n",
    "%time twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx abcd efgh ijkl mnop qrst uvwx\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=4, drop_last=True)\n",
    "twoepochs(dl)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lahp kzyn rgmb sfdt xvco ueij wq svid tckw phjz raeu gfqy mlnb xo\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(bs=4, num_workers=0, shuffle=True)\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "ds = SleepyDS(string.ascii_lowercase)\n",
    "dl = get_dl(bs=4, num_workers=4, sampler=SequentialSampler(ds))\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypojsdrz hkvwnilc xqmbfgtu ae ypojsdrz hkvwnilc xqmbfgtu ae\n"
     ]
    }
   ],
   "source": [
    "dl = get_dl(num_workers=4, batch_sampler=BatchSampler(RandomSampler(ds), 8, False))\n",
    "twoepochs(dl)\n",
    "test_eq(len(set(sum(dl,[]))), 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd efgh ijkl mnop qrst uvwx yz abcd efgh ijkl mnop qrst uvwx yz\n"
     ]
    }
   ],
   "source": [
    "def rev_collate(s): return default_collate(list(reversed(s)))\n",
    "dl = get_dl(bs=4, num_workers=4, collate_fn=rev_collate)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/ abcd/ efgh/ ijkl/ mnop/ qrst/ uvwx/ yz/\n"
     ]
    }
   ],
   "source": [
    "class SleepyDS2(SleepyDS):\n",
    "    def get_batch(self, b): return \"\".join([self[j] for j in b]) + '/'\n",
    "\n",
    "dl = dataloader(SleepyDS2(string.ascii_lowercase), bs=4, num_workers=4)\n",
    "twoepochs(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
